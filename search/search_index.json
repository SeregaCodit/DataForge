{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"DataForge","text":"<p>DataForge is a high-performance CLI tool designed to automate the preparation and management of machine learning datasets. It helps you transform raw data (like videos and unsorted images) into clean, balanced, and ready-to-train datasets with minimal effort.</p> <p>Read the full documentation here</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Parallel Processing: Uses multiprocessing to handle thousands of files quickly.</li> <li>Vectorized Calculations: Employs NumPy for ultra-fast image comparison and hashing.</li> <li>Smart Caching: Incremental caching (MD5-based) allows working with large datasets on NAS or local storage without re-calculating existing data.</li> <li>Flexible Configuration: Built with Pydantic v2 for safe settings via <code>config.json</code> or CLI arguments.</li> </ul>"},{"location":"#available-commands","title":"Available Commands","text":"<ul> <li><code>move</code> \u2014 Move files from source to target directory based on specific patterns.</li> <li><code>slice</code> \u2014 Convert video files into sequences of images. Use <code>--remove</code> to delete the source video after a successful slice.</li> <li><code>delete</code> \u2014 Safely remove files matching specific patterns.</li> <li><code>dedup</code> \u2014 Find and remove visual duplicates using dHash.<ul> <li>Threshold: Similarity limit (0-100%).</li> <li>Core Size: Higher values (e.g., 32) detect small changes; lower values (e.g., 8) ignore noise.</li> </ul> </li> <li><code>clean-annotations</code> \u2014 Automatically find and delete \"orphan\" annotation files (XML/TXT) that do not have a corresponding image.</li> <li><code>convert-annotations</code> \u2014 Convert dataset labels between formats (e.g., Pascal VOC to YOLO).</li> <li><code>stats</code> \u2014 Advanced Dataset Analytics &amp; Health Check This command performs a deep-dive into your dataset to identify biases and feature correlations before you start training.<ul> <li>Analytics Highlights:<ul> <li>Class Distribution: Visualizes object counts to detect imbalances.</li> <li>Spatial Density Heatmaps: Identifies \"positional bias\" for each class using 3x3 grids.</li> <li>Correlation Analysis: Global and per-class matrices showing relationships between features.</li> <li>Dataset Manifold (UMAP): 2D projection to identify \"representation gaps\" and object clusters.</li> <li>Quality Metrics: Analysis of object areas, aspect ratios, brightness, contrast, and blur.</li> <li>Outlier Detection: Automatically marks extreme data points using the IQR method.</li> </ul> </li> <li>Outputs: Technical console summary, high-resolution PNG plots, and unified PDF reports.</li> </ul> </li> </ul> <p>Usage Example:</p> <pre><code>python data_forge.py stats --src ./data/train --target_format yolo --report_path ./reports/v1\n</code></pre>"},{"location":"#automation-intervals","title":"Automation &amp; Intervals","text":"<p>By default, commands run once. To monitor a folder and process files as they appear, use these flags: * <code>-r</code>: Run the command in a continuous cycle. * <code>-s</code>: Set the delay (in seconds) between cycles.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/SeregaCodit/DataForge.git\ncd DataForge\n</code></pre> <ol> <li>Setup environment:</li> </ol> <pre><code>python -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n</code></pre> <ol> <li>Check usage:</li> </ol> <pre><code>python data_forge.py --help             # See all available commands\npython data_forge.py {command} --help   # See arguments for a specific command\n</code></pre>"},{"location":"#workflow-optimization","title":"Workflow Optimization","text":"<p>For multiple tasks, you can modify <code>start_all_tasks.sh</code> and run them in the background:</p> <pre><code>bash start_all_tasks.sh\n</code></pre> <p>To stop all running DataForge processes:</p> <pre><code>pkill -f data_forge.py\n</code></pre>"},{"location":"#configuration-priority","title":"Configuration Priority","text":"<p>You can manage default settings in <code>config.json</code>. DataForge follows this priority: CLI Arguments &gt; config.json &gt; Internal Defaults.</p>"},{"location":"api/base_converter/","title":"Base Converter","text":"<p>               Bases: <code>ABC</code></p> <p>Base converter class. Based on the source and destination formats, defines reader and writer classes for     processing data, defines default source and destination annotation file suffixes</p> Source code in <code>tools/annotation_converter/converter/base.py</code> <pre><code>class BaseConverter(ABC):\n    \"\"\"\n    Base converter class. Based on the source and destination formats, defines reader and writer classes for\n        processing data, defines default source and destination annotation file suffixes\n\n    \"\"\"\n    def __init__(\n            self,\n            source_format: str,\n            dest_format: str,\n            log_level: str = LevelMapping.debug,\n            log_path: Optional[Path] = None,\n            **kwargs\n    ):\n        \"\"\"\n        Initialize the converter class.\n\n        Args:\n            source_format (str): The format of source annotation (e.g., 'yolo').\n            dest_format (str): The format of output annotations (e.g., 'voc').\n            log_level: (str): The lowest logging level print to (e.g., 'debug').\n            **kwargs (dict): Additional parameters like 'img_path' or 'labels_path'.\n        \"\"\"\n        self.reader_mapping = {\n            \".xml\": XMLReader,\n            \".txt\": TXTReader\n        }\n\n        self.writer_mapping = {\n            \".txt\": YoloWriter,\n            \".xml\": XMLWriter\n        }\n\n        self.suffix_mapping = {\n            \"voc\": \".xml\",\n            \"yolo\": \".txt\"\n        }\n\n        self.source_suffix = self.suffix_mapping.get(source_format)\n        self.dest_suffix = self.suffix_mapping.get(dest_format)\n        self.reader = self.reader_mapping[self.source_suffix]()\n        self.writer = self.writer_mapping[self.dest_suffix]()\n\n        self.logger = LoggerConfigurator.setup(\n            name=self.__class__.__name__,\n            log_level=log_level,\n            log_path=Path(log_path) / f\"{self.__class__.__name__}.log\" if log_path else None\n        )\n\n\n    @abstractmethod\n    def convert(self, file_paths: Tuple[Path], target_path: Path, n_jobs: int = 1) -&gt; None:\n        \"\"\"\n        Abstract method to convert source annotation file to destination annotation file by running custom workers in\n            subclasses\n\n        Args:\n            file_paths (Tuple[Path]): List of paths to the annotation files.\n            target_path (Path): Directory where converted files will be stored.\n            n_jobs (int): Number of parallel workers to use. Defaults to 1.\n        \"\"\"\n        pass\n\n    @property\n    def reader(self) -&gt; BaseReader:\n        \"\"\"BaseReader: returns a reader for the annotation file.\"\"\"\n        return self._reader\n\n    @reader.setter\n    def reader(self, reader: BaseReader) -&gt; None:\n        \"\"\"\n        Sets a reader for the annotation filetype.\n\n        Args:\n            reader (BaseReader): Reader for the annotation filetype.\n        \"\"\"\n        self._reader = reader\n\n    @property\n    def writer(self) -&gt; BaseWriter:\n        \"\"\"BaseWriter: returns a writer for the annotation filetype.\"\"\"\n        return self._writer\n\n    @writer.setter\n    def writer(self, writer: BaseWriter) -&gt; None:\n        \"\"\"\n        Sets a writer for the annotation filetype.\n\n        Args:\n            writer (BaseWriter): Writer for the annotation filetype.\n        \"\"\"\n        self._writer = writer\n</code></pre>"},{"location":"api/base_converter/#tools.annotation_converter.converter.base.BaseConverter.reader","title":"<code>reader</code>  <code>property</code> <code>writable</code>","text":"<p>BaseReader: returns a reader for the annotation file.</p>"},{"location":"api/base_converter/#tools.annotation_converter.converter.base.BaseConverter.writer","title":"<code>writer</code>  <code>property</code> <code>writable</code>","text":"<p>BaseWriter: returns a writer for the annotation filetype.</p>"},{"location":"api/base_converter/#tools.annotation_converter.converter.base.BaseConverter.__init__","title":"<code>__init__(source_format, dest_format, log_level=LevelMapping.debug, log_path=None, **kwargs)</code>","text":"<p>Initialize the converter class.</p> <p>Parameters:</p> Name Type Description Default <code>source_format</code> <code>str</code> <p>The format of source annotation (e.g., 'yolo').</p> required <code>dest_format</code> <code>str</code> <p>The format of output annotations (e.g., 'voc').</p> required <code>log_level</code> <code>str</code> <p>(str): The lowest logging level print to (e.g., 'debug').</p> <code>debug</code> <code>**kwargs</code> <code>dict</code> <p>Additional parameters like 'img_path' or 'labels_path'.</p> <code>{}</code> Source code in <code>tools/annotation_converter/converter/base.py</code> <pre><code>def __init__(\n        self,\n        source_format: str,\n        dest_format: str,\n        log_level: str = LevelMapping.debug,\n        log_path: Optional[Path] = None,\n        **kwargs\n):\n    \"\"\"\n    Initialize the converter class.\n\n    Args:\n        source_format (str): The format of source annotation (e.g., 'yolo').\n        dest_format (str): The format of output annotations (e.g., 'voc').\n        log_level: (str): The lowest logging level print to (e.g., 'debug').\n        **kwargs (dict): Additional parameters like 'img_path' or 'labels_path'.\n    \"\"\"\n    self.reader_mapping = {\n        \".xml\": XMLReader,\n        \".txt\": TXTReader\n    }\n\n    self.writer_mapping = {\n        \".txt\": YoloWriter,\n        \".xml\": XMLWriter\n    }\n\n    self.suffix_mapping = {\n        \"voc\": \".xml\",\n        \"yolo\": \".txt\"\n    }\n\n    self.source_suffix = self.suffix_mapping.get(source_format)\n    self.dest_suffix = self.suffix_mapping.get(dest_format)\n    self.reader = self.reader_mapping[self.source_suffix]()\n    self.writer = self.writer_mapping[self.dest_suffix]()\n\n    self.logger = LoggerConfigurator.setup(\n        name=self.__class__.__name__,\n        log_level=log_level,\n        log_path=Path(log_path) / f\"{self.__class__.__name__}.log\" if log_path else None\n    )\n</code></pre>"},{"location":"api/base_converter/#tools.annotation_converter.converter.base.BaseConverter.convert","title":"<code>convert(file_paths, target_path, n_jobs=1)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to convert source annotation file to destination annotation file by running custom workers in     subclasses</p> <p>Parameters:</p> Name Type Description Default <code>file_paths</code> <code>Tuple[Path]</code> <p>List of paths to the annotation files.</p> required <code>target_path</code> <code>Path</code> <p>Directory where converted files will be stored.</p> required <code>n_jobs</code> <code>int</code> <p>Number of parallel workers to use. Defaults to 1.</p> <code>1</code> Source code in <code>tools/annotation_converter/converter/base.py</code> <pre><code>@abstractmethod\ndef convert(self, file_paths: Tuple[Path], target_path: Path, n_jobs: int = 1) -&gt; None:\n    \"\"\"\n    Abstract method to convert source annotation file to destination annotation file by running custom workers in\n        subclasses\n\n    Args:\n        file_paths (Tuple[Path]): List of paths to the annotation files.\n        target_path (Path): Directory where converted files will be stored.\n        n_jobs (int): Number of parallel workers to use. Defaults to 1.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/base_hasher/","title":"Base Hasher","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for image hashing strategies in DataForge.</p> <p>This class provides the core logic for generating image hashes in parallel, managing incremental caching, and performing fast duplicate detection using vectorized NumPy operations.</p> <p>Attributes:</p> Name Type Description <code>settings</code> <code>AppSettings</code> <p>Global configuration for paths and parameters.</p> <code>logger</code> <code>Logger</code> <p>Logger instance for hashing operations.</p> <code>hash_type</code> <code>str</code> <p>The name of the hashing algorithm (e.g., 'dhash').</p> <code>core_size</code> <code>int</code> <p>The resolution used for image resizing.</p> <code>threshold</code> <code>int</code> <p>The distance threshold in bits for duplicate detection.</p> <code>cache_io</code> <code>CacheIO</code> <p>Tool for saving and loading hash data from disk.</p> <code>n_jobs</code> <code>int</code> <p>Number of parallel processes for hash computation.</p> Source code in <code>tools/comparer/img_comparer/hasher/base_hasher.py</code> <pre><code>class BaseHasher(ABC):\n    \"\"\"\n    Abstract base class for image hashing strategies in DataForge.\n\n    This class provides the core logic for generating image hashes in parallel,\n    managing incremental caching, and performing fast duplicate detection using\n    vectorized NumPy operations.\n\n    Attributes:\n        settings (AppSettings): Global configuration for paths and parameters.\n        logger (logging.Logger): Logger instance for hashing operations.\n        hash_type (str): The name of the hashing algorithm (e.g., 'dhash').\n        core_size (int): The resolution used for image resizing.\n        threshold (int): The distance threshold in bits for duplicate detection.\n        cache_io (CacheIO): Tool for saving and loading hash data from disk.\n        n_jobs (int): Number of parallel processes for hash computation.\n    \"\"\"\n    def __init__(\n        self,\n        settings: AppSettings,\n        cache_io: Optional[CacheIO] = None\n    ):\n        \"\"\"\n        Initializes the hasher with project settings and cache handler.\n\n        Args:\n            settings (AppSettings): Configuration containing defaults and CLI arguments.\n            cache_io (Optional[CacheIO]): Instance for cache persistence.\n                If None, a new CacheIO instance is created.\n        \"\"\"\n        self.settings = settings\n        self.logger = LoggerConfigurator.setup(\n            name=self.__class__.__name__,\n            log_path=Path(self.settings.log_path) / f\"{self.__class__.__name__}.log\" if self.settings.log_path else None,\n            log_level=self.settings.log_level\n        )\n\n        self.hash_type = self.settings.method\n        self.core_size = self.settings.core_size\n        self.threshold = self.settings.hash_threshold\n        self.cache_io = cache_io or CacheIO(self.settings)\n        self.n_jobs = self.settings.n_jobs\n\n\n    @staticmethod\n    @abstractmethod\n    def compute_hash(image_path: Path, core_size: int) -&gt; np.ndarray:\n        \"\"\"\n        Abstract method to calculate a hash for a single image.\n\n        Args:\n            image_path (Path): Path to the image file.\n            core_size (int): Resolution for resizing before hashing.\n\n        Returns:\n            np.ndarray: A 1D boolean array representing the image hash.\n        \"\"\"\n        pass\n\n\n    def validate_hash_map(\n            self,\n            image_paths: Tuple[Path],\n            hash_map: Dict[Path, np.ndarray]\n    ) -&gt; Tuple[bool, Dict[Path, np.ndarray]]:\n        \"\"\"\n        Synchronizes the loaded cache with the current files in the directory.\n\n        It removes hashes for files that no longer exist and triggers\n        re-calculation for new files found on the disk.\n\n        Args:\n            image_paths (Tuple[Path]): Current list of image paths from the folder.\n            hash_map (Dict[Path, np.ndarray]): The hash map loaded from cache.\n\n        Returns:\n            Tuple[bool, Dict[Path, np.ndarray]]: A tuple containing a sync\n                status (True if matches 1:1) and the updated hash map.\n        \"\"\"\n        paths_set = set(image_paths)\n        cached_set = set(hash_map.keys())\n        missing_paths = tuple(paths_set - cached_set)\n        obsolete_paths = cached_set - paths_set\n\n        if not missing_paths and not obsolete_paths:\n            self.logger.info(f\"Cache matches disk 1:1 ({len(hash_map)} items).\")\n            return True, hash_map\n\n        valid_cache = {path: hash_data for path, hash_data in hash_map.items() if path in paths_set}\n\n        if missing_paths:\n            self.logger.info(f\"Syncing cache: calculating {len(missing_paths)} new images...\")\n            new_hashes = self.update_hashes(missing_paths)\n\n            for path, hash_data in zip(missing_paths, new_hashes):\n                if hash_data is not None:\n                    valid_cache[path] = hash_data\n\n        return False, valid_cache\n\n\n    def update_hashes(self, image_paths: Tuple[Path, ...]) -&gt; list:\n        \"\"\"\n        Computes hashes for a list of images using multiple CPU cores.\n\n        Args:\n            image_paths (Tuple[Path, ...]): List of images that need new hashes.\n\n        Returns:\n            list: A list of generated NumPy arrays (hashes).\n        \"\"\"\n        hash_func = partial(self.__class__.compute_hash, core_size=self.core_size)\n\n        with ProcessPoolExecutor(max_workers=self.n_jobs) as executor:\n            hashes = list(executor.map(hash_func, image_paths))\n\n        return hashes\n\n\n    @staticmethod\n    def _df_to_hash_map(df: pd.DataFrame) -&gt; Dict[Path, np.ndarray]:\n        \"\"\"Internal helper: Converts Parquet DataFrame back to Hashing format.\"\"\"\n        if df.empty:\n            return {}\n        data = {\n            Path(row['path']): np.array(row['hash'], dtype=bool)\n            for _, row in df.iterrows()\n        }\n        return data\n\n\n    def get_hashmap(self, image_paths: Tuple[Path]) -&gt; Dict[Path, np.ndarray]:\n        \"\"\"\n        Orchestrates the process of obtaining hashes for the entire directory.\n\n        It attempts to load data from cache, validates it against the current\n        files, and computes any missing hashes in parallel.\n\n        Args:\n            image_paths (Tuple[Path]): All image paths to be processed.\n\n        Returns:\n            Dict[Path, np.ndarray]: A complete dictionary of paths and their hashes.\n        \"\"\"\n        if not image_paths:\n            return {}\n\n        image_count = len(image_paths)\n        filename = self.cache_io.generate_cache_filename(\n            image_paths[0].parent.resolve(),\n            cache_name=self.settings.cache_name,\n            hash_type=self.hash_type,\n            core_size=self.core_size,\n\n        )\n\n        cache_file_name = self.settings.cache_file_path / filename\n        cache_file_name.parent.mkdir(parents=True, exist_ok=True)\n        df = self.cache_io.load(cache_file_name)\n\n        hash_map  = self._df_to_hash_map(df)\n\n        if hash_map:\n            is_valid, valid_hash_map = self.validate_hash_map(image_paths, hash_map)\n            if is_valid:\n                return hash_map\n            else:\n                self.cache_io.save(valid_hash_map, cache_file_name)\n                self.logger.info(f\"Hash map updated: {len(valid_hash_map)} total valid hashes.\")\n                return valid_hash_map\n\n        self.logger.info(f\"Building hashmap in parallel using {self.n_jobs} workers for {image_count} images...\")\n\n        hashes = self.update_hashes(image_paths)\n        hash_map = {\n            path: h for path, h in zip(image_paths, hashes)\n            if h is not None\n        }\n\n        self.logger.info(f\"Successfully hashed {len(hash_map)} out of {image_count} images\")\n        self.cache_io.save(hash_map, cache_file_name)\n        return hash_map\n\n\n    def find_duplicates(self, hashmap: Dict[Path, np.ndarray]) -&gt; List[Path]:\n        \"\"\"\n        Finds similar images using vectorized Hamming distance comparison.\n\n        This method converts the hash map into a matrix and compares all\n        images against each other. It optimizes the search by skipping\n        already identified duplicates.\n\n        Args:\n            hashmap (Dict[Path, np.ndarray]): Dictionary of paths and hashes.\n\n        Returns:\n            List[Path]: A list of file paths identified as duplicates.\n\n        Raises:\n            ValueError: If hashes in the map have different lengths.\n        \"\"\"\n        if not hashmap:\n            return []\n\n        self.logger.info(f\"Vectorizing comparison for {len(hashmap)} images...\")\n        paths: List[Path] = list(hashmap.keys())\n\n        try:\n            matrix = np.array(list(hashmap.values()), dtype=bool)\n        except ValueError as e:\n            msg = \"Failed to create matrix. Some hashes have different lengths!\"\n            self.logger.error(msg)\n            raise ValueError(msg)\n\n        duplicates_indices: Set[int] = set()\n\n        for index in range(len(paths)):\n            if index in duplicates_indices:\n                continue\n\n            current_hash = matrix[index]\n            hamming_distances = np.count_nonzero(matrix != current_hash, axis=1)\n            matches = np.where(hamming_distances &lt;= self.threshold)[0]\n\n            for match_idx in matches:\n                if match_idx &gt; index:\n                    duplicates_indices.add(int(match_idx))\n\n        result = [paths[idx] for idx in duplicates_indices]\n        self.logger.info(f\"Vectorized search finished. Found {len(result)} duplicates.\")\n        return result\n\n\n    @property\n    def core_size(self) -&gt; int:\n        \"\"\"int: The resolution used for resizing images before hashing.\"\"\"\n        return self._core_size\n\n    @core_size.setter\n    def core_size(self, value: Union[Tuple[int, int], int, float, str]) -&gt; None:\n        \"\"\"\n        Sets the core size and updates the bit-based threshold accordingly.\n\n        Args:\n            value: The new size value (int, float, str, or tuple).\n\n        Raises:\n            TypeError: If the value cannot be converted to an integer.\n        \"\"\"\n        try:\n            if isinstance(value, tuple):\n                new_size = int(value[0]) if value[0] &gt; 0 else int(value[1])\n            else:\n                new_size = int(float(value))\n\n            self._core_size = new_size\n\n            if hasattr(self, '_threshold_pct'):\n                self._recalculate_threshold_bits(self._threshold_pct)\n\n        except (ValueError, TypeError, IndexError) as e:\n            msg = f\"Invalid core_size type: {type(value)}. Using default.\"\n            self.logger.error(msg)\n            raise TypeError(msg)\n\n    @property\n    def threshold(self) -&gt; int:\n        \"\"\"int: The current distance threshold measured in bits.\"\"\"\n        return self._threshold\n\n    @threshold.setter\n    def threshold(self, value: Union[float, int, str]) -&gt; None:\n        \"\"\"\n        Sets the threshold as a percentage and converts it into bits.\n\n        Args:\n            value: Minimal percentage difference to consider images as unique.\n\n        Raises:\n            ValueError: If the percentage is not between 0 and 100.\n        \"\"\"\n        try:\n            pct_value = float(value)\n        except (ValueError, TypeError) as e:\n            msg = f\"Threshold must be a number, got {type(value)}\"\n            self.logger.error(msg)\n            raise ValueError(msg)\n\n        if not (0 &lt;= pct_value &lt;= self.settings.max_percentage):\n            msg = f\"Threshold percentage out of range [0-100]: {pct_value}\"\n            self.logger.error(msg)\n            raise ValueError(msg)\n\n        self._threshold_pct = pct_value\n        self._recalculate_threshold_bits(pct_value)\n\n    def _recalculate_threshold_bits(self, percentage: float) -&gt; None:\n        \"\"\"\n        Internal helper to convert a percentage threshold into absolute bits.\n\n        Args:\n            percentage (float): The threshold percentage (0-100).\n        \"\"\"\n        hash_sqr = self.core_size * self.core_size\n        self._threshold = int(hash_sqr * (percentage / self.settings.max_percentage))\n        self.logger.debug(f\"Threshold recalculated: {percentage}% of {hash_sqr} bits = {self._threshold} bits\")\n\n    @property\n    def n_jobs(self) -&gt; int:\n        \"\"\"int: The number of parallel worker processes.\"\"\"\n        return self._n_jobs\n\n    @n_jobs.setter\n    def n_jobs(self, value: Union[int, float, str]) -&gt; None:\n        \"\"\"\n        Safely sets the number of workers based on the system's CPU count.\n\n        It ensures at least 1 worker is used and caps the value to\n        (CPU count - 1) to keep the system responsive.\n        \"\"\"\n        if not isinstance(value, int):\n            try:\n                value = int(float(value))\n            except TypeError:\n                msg = f\"n_jobs must be int, got {type(value)}\"\n                self.logger.error(msg)\n                raise TypeError(msg)\n            except ValueError:\n                msg = f\"n_jobs must be real number, got {type(value)}\"\n                self.logger.error(msg)\n                raise ValueError(msg)\n\n        # check cores and control that n_jobs can be set\n        cores = multiprocessing.cpu_count()\n\n        if value &lt;= 1:\n            self.logger.warning(f\"n_jobs must be greater than 1, got {value}\")\n            value = 1\n        elif 1 &lt; cores &lt;= value:\n            self.logger.warning(f\"n_jobs must be less than {cores}, got {value}\")\n            value = cores - 1\n        elif cores == 1 and value != 1:\n            value = 1\n\n        self._n_jobs = value\n        self.logger.info(f\"n_jobs set to {value}\")\n</code></pre>"},{"location":"api/base_hasher/#tools.comparer.img_comparer.hasher.base_hasher.BaseHasher.core_size","title":"<code>core_size</code>  <code>property</code> <code>writable</code>","text":"<p>int: The resolution used for resizing images before hashing.</p>"},{"location":"api/base_hasher/#tools.comparer.img_comparer.hasher.base_hasher.BaseHasher.n_jobs","title":"<code>n_jobs</code>  <code>property</code> <code>writable</code>","text":"<p>int: The number of parallel worker processes.</p>"},{"location":"api/base_hasher/#tools.comparer.img_comparer.hasher.base_hasher.BaseHasher.threshold","title":"<code>threshold</code>  <code>property</code> <code>writable</code>","text":"<p>int: The current distance threshold measured in bits.</p>"},{"location":"api/base_hasher/#tools.comparer.img_comparer.hasher.base_hasher.BaseHasher.__init__","title":"<code>__init__(settings, cache_io=None)</code>","text":"<p>Initializes the hasher with project settings and cache handler.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>Configuration containing defaults and CLI arguments.</p> required <code>cache_io</code> <code>Optional[CacheIO]</code> <p>Instance for cache persistence. If None, a new CacheIO instance is created.</p> <code>None</code> Source code in <code>tools/comparer/img_comparer/hasher/base_hasher.py</code> <pre><code>def __init__(\n    self,\n    settings: AppSettings,\n    cache_io: Optional[CacheIO] = None\n):\n    \"\"\"\n    Initializes the hasher with project settings and cache handler.\n\n    Args:\n        settings (AppSettings): Configuration containing defaults and CLI arguments.\n        cache_io (Optional[CacheIO]): Instance for cache persistence.\n            If None, a new CacheIO instance is created.\n    \"\"\"\n    self.settings = settings\n    self.logger = LoggerConfigurator.setup(\n        name=self.__class__.__name__,\n        log_path=Path(self.settings.log_path) / f\"{self.__class__.__name__}.log\" if self.settings.log_path else None,\n        log_level=self.settings.log_level\n    )\n\n    self.hash_type = self.settings.method\n    self.core_size = self.settings.core_size\n    self.threshold = self.settings.hash_threshold\n    self.cache_io = cache_io or CacheIO(self.settings)\n    self.n_jobs = self.settings.n_jobs\n</code></pre>"},{"location":"api/base_hasher/#tools.comparer.img_comparer.hasher.base_hasher.BaseHasher.compute_hash","title":"<code>compute_hash(image_path, core_size)</code>  <code>abstractmethod</code> <code>staticmethod</code>","text":"<p>Abstract method to calculate a hash for a single image.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>Path</code> <p>Path to the image file.</p> required <code>core_size</code> <code>int</code> <p>Resolution for resizing before hashing.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: A 1D boolean array representing the image hash.</p> Source code in <code>tools/comparer/img_comparer/hasher/base_hasher.py</code> <pre><code>@staticmethod\n@abstractmethod\ndef compute_hash(image_path: Path, core_size: int) -&gt; np.ndarray:\n    \"\"\"\n    Abstract method to calculate a hash for a single image.\n\n    Args:\n        image_path (Path): Path to the image file.\n        core_size (int): Resolution for resizing before hashing.\n\n    Returns:\n        np.ndarray: A 1D boolean array representing the image hash.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/base_hasher/#tools.comparer.img_comparer.hasher.base_hasher.BaseHasher.find_duplicates","title":"<code>find_duplicates(hashmap)</code>","text":"<p>Finds similar images using vectorized Hamming distance comparison.</p> <p>This method converts the hash map into a matrix and compares all images against each other. It optimizes the search by skipping already identified duplicates.</p> <p>Parameters:</p> Name Type Description Default <code>hashmap</code> <code>Dict[Path, ndarray]</code> <p>Dictionary of paths and hashes.</p> required <p>Returns:</p> Type Description <code>List[Path]</code> <p>List[Path]: A list of file paths identified as duplicates.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If hashes in the map have different lengths.</p> Source code in <code>tools/comparer/img_comparer/hasher/base_hasher.py</code> <pre><code>def find_duplicates(self, hashmap: Dict[Path, np.ndarray]) -&gt; List[Path]:\n    \"\"\"\n    Finds similar images using vectorized Hamming distance comparison.\n\n    This method converts the hash map into a matrix and compares all\n    images against each other. It optimizes the search by skipping\n    already identified duplicates.\n\n    Args:\n        hashmap (Dict[Path, np.ndarray]): Dictionary of paths and hashes.\n\n    Returns:\n        List[Path]: A list of file paths identified as duplicates.\n\n    Raises:\n        ValueError: If hashes in the map have different lengths.\n    \"\"\"\n    if not hashmap:\n        return []\n\n    self.logger.info(f\"Vectorizing comparison for {len(hashmap)} images...\")\n    paths: List[Path] = list(hashmap.keys())\n\n    try:\n        matrix = np.array(list(hashmap.values()), dtype=bool)\n    except ValueError as e:\n        msg = \"Failed to create matrix. Some hashes have different lengths!\"\n        self.logger.error(msg)\n        raise ValueError(msg)\n\n    duplicates_indices: Set[int] = set()\n\n    for index in range(len(paths)):\n        if index in duplicates_indices:\n            continue\n\n        current_hash = matrix[index]\n        hamming_distances = np.count_nonzero(matrix != current_hash, axis=1)\n        matches = np.where(hamming_distances &lt;= self.threshold)[0]\n\n        for match_idx in matches:\n            if match_idx &gt; index:\n                duplicates_indices.add(int(match_idx))\n\n    result = [paths[idx] for idx in duplicates_indices]\n    self.logger.info(f\"Vectorized search finished. Found {len(result)} duplicates.\")\n    return result\n</code></pre>"},{"location":"api/base_hasher/#tools.comparer.img_comparer.hasher.base_hasher.BaseHasher.get_hashmap","title":"<code>get_hashmap(image_paths)</code>","text":"<p>Orchestrates the process of obtaining hashes for the entire directory.</p> <p>It attempts to load data from cache, validates it against the current files, and computes any missing hashes in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>image_paths</code> <code>Tuple[Path]</code> <p>All image paths to be processed.</p> required <p>Returns:</p> Type Description <code>Dict[Path, ndarray]</code> <p>Dict[Path, np.ndarray]: A complete dictionary of paths and their hashes.</p> Source code in <code>tools/comparer/img_comparer/hasher/base_hasher.py</code> <pre><code>def get_hashmap(self, image_paths: Tuple[Path]) -&gt; Dict[Path, np.ndarray]:\n    \"\"\"\n    Orchestrates the process of obtaining hashes for the entire directory.\n\n    It attempts to load data from cache, validates it against the current\n    files, and computes any missing hashes in parallel.\n\n    Args:\n        image_paths (Tuple[Path]): All image paths to be processed.\n\n    Returns:\n        Dict[Path, np.ndarray]: A complete dictionary of paths and their hashes.\n    \"\"\"\n    if not image_paths:\n        return {}\n\n    image_count = len(image_paths)\n    filename = self.cache_io.generate_cache_filename(\n        image_paths[0].parent.resolve(),\n        cache_name=self.settings.cache_name,\n        hash_type=self.hash_type,\n        core_size=self.core_size,\n\n    )\n\n    cache_file_name = self.settings.cache_file_path / filename\n    cache_file_name.parent.mkdir(parents=True, exist_ok=True)\n    df = self.cache_io.load(cache_file_name)\n\n    hash_map  = self._df_to_hash_map(df)\n\n    if hash_map:\n        is_valid, valid_hash_map = self.validate_hash_map(image_paths, hash_map)\n        if is_valid:\n            return hash_map\n        else:\n            self.cache_io.save(valid_hash_map, cache_file_name)\n            self.logger.info(f\"Hash map updated: {len(valid_hash_map)} total valid hashes.\")\n            return valid_hash_map\n\n    self.logger.info(f\"Building hashmap in parallel using {self.n_jobs} workers for {image_count} images...\")\n\n    hashes = self.update_hashes(image_paths)\n    hash_map = {\n        path: h for path, h in zip(image_paths, hashes)\n        if h is not None\n    }\n\n    self.logger.info(f\"Successfully hashed {len(hash_map)} out of {image_count} images\")\n    self.cache_io.save(hash_map, cache_file_name)\n    return hash_map\n</code></pre>"},{"location":"api/base_hasher/#tools.comparer.img_comparer.hasher.base_hasher.BaseHasher.update_hashes","title":"<code>update_hashes(image_paths)</code>","text":"<p>Computes hashes for a list of images using multiple CPU cores.</p> <p>Parameters:</p> Name Type Description Default <code>image_paths</code> <code>Tuple[Path, ...]</code> <p>List of images that need new hashes.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of generated NumPy arrays (hashes).</p> Source code in <code>tools/comparer/img_comparer/hasher/base_hasher.py</code> <pre><code>def update_hashes(self, image_paths: Tuple[Path, ...]) -&gt; list:\n    \"\"\"\n    Computes hashes for a list of images using multiple CPU cores.\n\n    Args:\n        image_paths (Tuple[Path, ...]): List of images that need new hashes.\n\n    Returns:\n        list: A list of generated NumPy arrays (hashes).\n    \"\"\"\n    hash_func = partial(self.__class__.compute_hash, core_size=self.core_size)\n\n    with ProcessPoolExecutor(max_workers=self.n_jobs) as executor:\n        hashes = list(executor.map(hash_func, image_paths))\n\n    return hashes\n</code></pre>"},{"location":"api/base_hasher/#tools.comparer.img_comparer.hasher.base_hasher.BaseHasher.validate_hash_map","title":"<code>validate_hash_map(image_paths, hash_map)</code>","text":"<p>Synchronizes the loaded cache with the current files in the directory.</p> <p>It removes hashes for files that no longer exist and triggers re-calculation for new files found on the disk.</p> <p>Parameters:</p> Name Type Description Default <code>image_paths</code> <code>Tuple[Path]</code> <p>Current list of image paths from the folder.</p> required <code>hash_map</code> <code>Dict[Path, ndarray]</code> <p>The hash map loaded from cache.</p> required <p>Returns:</p> Type Description <code>Tuple[bool, Dict[Path, ndarray]]</code> <p>Tuple[bool, Dict[Path, np.ndarray]]: A tuple containing a sync status (True if matches 1:1) and the updated hash map.</p> Source code in <code>tools/comparer/img_comparer/hasher/base_hasher.py</code> <pre><code>def validate_hash_map(\n        self,\n        image_paths: Tuple[Path],\n        hash_map: Dict[Path, np.ndarray]\n) -&gt; Tuple[bool, Dict[Path, np.ndarray]]:\n    \"\"\"\n    Synchronizes the loaded cache with the current files in the directory.\n\n    It removes hashes for files that no longer exist and triggers\n    re-calculation for new files found on the disk.\n\n    Args:\n        image_paths (Tuple[Path]): Current list of image paths from the folder.\n        hash_map (Dict[Path, np.ndarray]): The hash map loaded from cache.\n\n    Returns:\n        Tuple[bool, Dict[Path, np.ndarray]]: A tuple containing a sync\n            status (True if matches 1:1) and the updated hash map.\n    \"\"\"\n    paths_set = set(image_paths)\n    cached_set = set(hash_map.keys())\n    missing_paths = tuple(paths_set - cached_set)\n    obsolete_paths = cached_set - paths_set\n\n    if not missing_paths and not obsolete_paths:\n        self.logger.info(f\"Cache matches disk 1:1 ({len(hash_map)} items).\")\n        return True, hash_map\n\n    valid_cache = {path: hash_data for path, hash_data in hash_map.items() if path in paths_set}\n\n    if missing_paths:\n        self.logger.info(f\"Syncing cache: calculating {len(missing_paths)} new images...\")\n        new_hashes = self.update_hashes(missing_paths)\n\n        for path, hash_data in zip(missing_paths, new_hashes):\n            if hash_data is not None:\n                valid_cache[path] = hash_data\n\n    return False, valid_cache\n</code></pre>"},{"location":"api/base_reader/","title":"Base reader","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for all data readers in DataForge.</p> <p>This class defines the standard interface for reading and parsing annotation files of different formats (such as XML for Pascal VOC or TXT for YOLO). Every specific reader must implement the 'read' method.</p> Source code in <code>tools/annotation_converter/reader/base.py</code> <pre><code>class BaseReader(ABC):\n    \"\"\"\n    Abstract base class for all data readers in DataForge.\n\n    This class defines the standard interface for reading and parsing\n    annotation files of different formats (such as XML for Pascal VOC\n    or TXT for YOLO). Every specific reader must implement the 'read' method.\n    \"\"\"\n    def __init__(self):\n        \"\"\" Initializes the base reader instance. \"\"\"\n        pass\n\n    @abstractmethod\n    def read(self, file_path: Path) -&gt; Dict[str, str]:\n        \"\"\"\n        Reads an annotation file and converts its content into a dictionary.\n\n        Args:\n            file_path (Path): The path to the source file to be read.\n\n        Returns:\n            dict: A dictionary containing the structured data from the file.\n\n        Raises:\n            FileNotFoundError: If the file does not exist at the specified path.\n            NotImplementedError: If the method is not implemented by a subclass.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/base_reader/#tools.annotation_converter.reader.base.BaseReader.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the base reader instance.</p> Source code in <code>tools/annotation_converter/reader/base.py</code> <pre><code>def __init__(self):\n    \"\"\" Initializes the base reader instance. \"\"\"\n    pass\n</code></pre>"},{"location":"api/base_reader/#tools.annotation_converter.reader.base.BaseReader.read","title":"<code>read(file_path)</code>  <code>abstractmethod</code>","text":"<p>Reads an annotation file and converts its content into a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>The path to the source file to be read.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict[str, str]</code> <p>A dictionary containing the structured data from the file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file does not exist at the specified path.</p> <code>NotImplementedError</code> <p>If the method is not implemented by a subclass.</p> Source code in <code>tools/annotation_converter/reader/base.py</code> <pre><code>@abstractmethod\ndef read(self, file_path: Path) -&gt; Dict[str, str]:\n    \"\"\"\n    Reads an annotation file and converts its content into a dictionary.\n\n    Args:\n        file_path (Path): The path to the source file to be read.\n\n    Returns:\n        dict: A dictionary containing the structured data from the file.\n\n    Raises:\n        FileNotFoundError: If the file does not exist at the specified path.\n        NotImplementedError: If the method is not implemented by a subclass.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/base_reporter/","title":"Base Reporter","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for dataset reporting and visualization.</p> <p>This class provides a shared interface and utility methods for creating technical reports. It handles console output formatting, shared logging, and calculation of dataset health metrics such as 'sweet spots' (statistical ranges free of outliers).</p> Source code in <code>tools/stats/dataset_reporter/base_reporter.py</code> <pre><code>class BaseDatasetReporter(ABC):\n    \"\"\"\n    Abstract base class for dataset reporting and visualization.\n\n    This class provides a shared interface and utility methods for creating\n    technical reports. It handles console output formatting, shared logging,\n    and calculation of dataset health metrics such as 'sweet spots'\n    (statistical ranges free of outliers).\n    \"\"\"\n    line: str = \"=\" * 75\n\n    def __init__(self, settings: AppSettings):\n        \"\"\"\n        Initializes the reporter with global settings and logging.\n\n        Args:\n            settings (AppSettings): Global configuration containing paths,\n                log levels, and report schemas.\n        \"\"\"\n        self.settings: AppSettings = settings\n        self.log_path: Path = settings.log_path\n        log_level = settings.log_level\n        self.schema = self.settings.img_dataset_report_schema\n        self.report_path = self.settings.report_path\n        self.report_path.mkdir(parents=True, exist_ok=True)\n\n        self.logger = LoggerConfigurator.setup(\n            name=self.__class__.__name__,\n            log_level=log_level,\n            log_path=Path(self.log_path) / f\"{self.__class__.__name__}.log\" if self.log_path else None\n        )\n\n    @abstractmethod\n    def show_console_report(self, df: pd.DataFrame, target_format: str) -&gt; None:\n        \"\"\"\n        Prints a detailed technical report to the console.\n\n        Args:\n            df (pd.DataFrame): The feature matrix of the dataset.\n            target_format (str): Annotation format identifier (e.g., 'yolo').\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def generate_visual_report(self, df: pd.DataFrame, destination: Union[Path, str, PdfPages], features: List[str]) -&gt; None:\n        \"\"\"\n        Generates visual analytics (plots, heatmaps, manifolds).\n\n        Args:\n            df (pd.DataFrame): The feature matrix of the dataset.\n            destination (Union[Path, str, PdfPages]): Output target for the visual assets.\n            features (List[str]): Numeric columns used for visual correlation and manifold analysis.\n        \"\"\"\n        pass\n\n\n    def _render_section(self, df: Union[pd.DataFrame, pd.Series], section: dict, total_objects: int) -&gt; List[str]:\n        \"\"\"\n        Formats a specific data category (numeric or binary) for the report text.\n\n        This method calculates statistical summaries (mean, median, std) for numeric\n        columns and identifies 'sweet spots' using the Interquartile Range (IQR) method.\n        For binary columns, it calculates frequency and percentage.\n\n        Args:\n            df (Union[pd.DataFrame, pd.Series]): Data slice for a specific class or dataset.\n            section (dict): Configuration dictionary defining the title, columns, and type.\n            total_objects (int): Total count used for calculating percentages in binary sections.\n\n        Returns:\n            List[str]: A list of formatted strings ready for console or text file output.\n        \"\"\"\n        title = section[\"title\"]\n        cols = [col for col in section[\"columns\"] if col in df.columns]\n\n        if not cols:\n            self.logger.warning(f\"No valid columns found for section '{title}' in the DataFrame.\")\n            return []\n\n        lines = [f\"\\n [{title}]\"]\n\n        if section[\"type\"] == \"numeric\":\n            stats = df[cols].describe().T\n            for col in cols:\n                row = stats.loc[col]\n                outlier_col = f\"outlier_{col}\"\n                outliers_count = df[outlier_col].sum()\n\n                iqr = row[\"75%\"] - row[\"25%\"]\n                min_limit = np.clip(row[\"25%\"] - 1.5 * iqr, a_min=0, a_max=None)\n                max_limit = row[\"75%\"] + 1.5 * iqr\n\n                lines.append(\n                    f\"  - {col:&lt;25}:\"\n                    f\" med {row['50%']:&gt;10.2f} |\"\n                    f\" avg {row['mean']:&gt;10.2f}, std {row['std']:&lt;10.2f} |\"\n                    f\" min {row['min']:&gt;10.2f}, max {row['max']:&gt;10.2f}  |\"\n                    f\" outliers: {int(outliers_count):&lt;4} |\"\n                    f\"{min_limit:10.2f} &lt; sweet spot &lt; {max_limit:10.2f} \"\n                )\n        elif section[\"type\"] == \"binary\":\n            sums = df[cols].sum()\n            for col in cols:\n                count = int(sums[col])\n                share = (count / total_objects) * 100\n                lines.append(f\"  - {col:&lt;25}: {count:&gt;10} ({share:&gt;6.1f}%)\")\n        else:\n            self.logger.warning(f\"Unknown section type '{section['type']}' for section '{title}'. Skipping.\")\n\n        return lines\n\n\n    @property\n    def report_path(self) -&gt; Path:\n        \"\"\"Path: The directory where generated reports are stored.\"\"\"\n        return self._report_path\n\n    @report_path.setter\n    def report_path(self, value: Union[Path, str]):\n        \"\"\"\n         Sets and validates the reporting output directory.\n\n         Args:\n             value (Union[Path, str]): Path to the report folder.\n\n         Raises:\n             TypeError: If the value is not a string or a Path object.\n         \"\"\"\n        if not isinstance(value, Path):\n            try:\n                value = Path(value)\n            except TypeError:\n                msg = f\"Invalid type for report_path: expected Path or str, got {type(value)}\"\n                self.logger.error(msg)\n                raise TypeError(msg)\n        self._report_path = value\n</code></pre>"},{"location":"api/base_reporter/#tools.stats.dataset_reporter.base_reporter.BaseDatasetReporter.report_path","title":"<code>report_path</code>  <code>property</code> <code>writable</code>","text":"<p>Path: The directory where generated reports are stored.</p>"},{"location":"api/base_reporter/#tools.stats.dataset_reporter.base_reporter.BaseDatasetReporter.__init__","title":"<code>__init__(settings)</code>","text":"<p>Initializes the reporter with global settings and logging.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>Global configuration containing paths, log levels, and report schemas.</p> required Source code in <code>tools/stats/dataset_reporter/base_reporter.py</code> <pre><code>def __init__(self, settings: AppSettings):\n    \"\"\"\n    Initializes the reporter with global settings and logging.\n\n    Args:\n        settings (AppSettings): Global configuration containing paths,\n            log levels, and report schemas.\n    \"\"\"\n    self.settings: AppSettings = settings\n    self.log_path: Path = settings.log_path\n    log_level = settings.log_level\n    self.schema = self.settings.img_dataset_report_schema\n    self.report_path = self.settings.report_path\n    self.report_path.mkdir(parents=True, exist_ok=True)\n\n    self.logger = LoggerConfigurator.setup(\n        name=self.__class__.__name__,\n        log_level=log_level,\n        log_path=Path(self.log_path) / f\"{self.__class__.__name__}.log\" if self.log_path else None\n    )\n</code></pre>"},{"location":"api/base_reporter/#tools.stats.dataset_reporter.base_reporter.BaseDatasetReporter.generate_visual_report","title":"<code>generate_visual_report(df, destination, features)</code>  <code>abstractmethod</code>","text":"<p>Generates visual analytics (plots, heatmaps, manifolds).</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The feature matrix of the dataset.</p> required <code>destination</code> <code>Union[Path, str, PdfPages]</code> <p>Output target for the visual assets.</p> required <code>features</code> <code>List[str]</code> <p>Numeric columns used for visual correlation and manifold analysis.</p> required Source code in <code>tools/stats/dataset_reporter/base_reporter.py</code> <pre><code>@abstractmethod\ndef generate_visual_report(self, df: pd.DataFrame, destination: Union[Path, str, PdfPages], features: List[str]) -&gt; None:\n    \"\"\"\n    Generates visual analytics (plots, heatmaps, manifolds).\n\n    Args:\n        df (pd.DataFrame): The feature matrix of the dataset.\n        destination (Union[Path, str, PdfPages]): Output target for the visual assets.\n        features (List[str]): Numeric columns used for visual correlation and manifold analysis.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/base_reporter/#tools.stats.dataset_reporter.base_reporter.BaseDatasetReporter.show_console_report","title":"<code>show_console_report(df, target_format)</code>  <code>abstractmethod</code>","text":"<p>Prints a detailed technical report to the console.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The feature matrix of the dataset.</p> required <code>target_format</code> <code>str</code> <p>Annotation format identifier (e.g., 'yolo').</p> required Source code in <code>tools/stats/dataset_reporter/base_reporter.py</code> <pre><code>@abstractmethod\ndef show_console_report(self, df: pd.DataFrame, target_format: str) -&gt; None:\n    \"\"\"\n    Prints a detailed technical report to the console.\n\n    Args:\n        df (pd.DataFrame): The feature matrix of the dataset.\n        target_format (str): Annotation format identifier (e.g., 'yolo').\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/base_stats/","title":"Base Stats","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for dataset feature extraction and analysis.</p> <p>This class defines the interface for reading different annotation formats (YOLO, VOC) and provides a high-performance pipeline for feature extraction. It supports incremental caching, multi-process execution, and UMAP dimensionality reduction for visual manifold analysis.</p> Source code in <code>tools/stats/base_stats.py</code> <pre><code>class BaseStats(ABC):\n    \"\"\"\n    Abstract base class for dataset feature extraction and analysis.\n\n    This class defines the interface for reading different annotation formats\n    (YOLO, VOC) and provides a high-performance pipeline for feature extraction.\n    It supports incremental caching, multi-process execution, and UMAP\n    dimensionality reduction for visual manifold analysis.\n    \"\"\"\n    TASK: str = \"stats\"\n\n    def __init__(\n            self,\n            source_format: str,\n            log_level: str = LevelMapping.debug,\n            log_path: Optional[Path] = None,\n            settings: Optional[AppSettings] = None,\n            cache_io: Optional[CacheIO] = None,\n            img_path: Optional[Union[Path, str]] = None,\n            extensions: Optional[Tuple[str, ...]] = None,\n    ):\n        \"\"\"\n        Initializes the analytical engine with specific formats and IO tools.\n\n        Args:\n            source_format (str): Annotation format identifier (e.g., 'yolo', 'voc').\n            log_level (str): Minimum logging level. Defaults to 'INFO'.\n            log_path (Optional[Path]): Directory for log files.\n            settings (Optional[AppSettings]): Application-wide settings.\n            cache_io (Optional[CacheIO]): Component for Parquet-based caching.\n            img_path (Optional[Union[Path, str]]): Path to the dataset images.\n            extensions (Optional[Tuple[str, ...]]): Valid image file extensions.\n        \"\"\"\n\n        self.reader_mapping = {\n            \".xml\": XMLReader,\n            \".txt\": TXTReader\n        }\n\n        self.suffix_mapping = {\n            \"voc\": \".xml\",\n            \"yolo\": \".txt\"\n        }\n\n        self.settings = settings\n        self.extensions = extensions\n        self.img_path = img_path\n        self.margin_threshold: int = self.settings.margin_threshold\n        self.reader = self.reader_mapping.get(source_format, None)\n        self.source_suffix = self.suffix_mapping.get(source_format)\n        self.reader = self.reader_mapping[self.source_suffix]()\n        self.cache_io = cache_io or CacheIO(self.settings)\n        self.n_jobs = self.settings.n_jobs\n        self.logger = LoggerConfigurator.setup(\n            name=self.__class__.__name__,\n            log_level=log_level,\n            log_path=Path(log_path) / f\"{self.__class__.__name__}.log\" if log_path else None\n        )\n\n    @classmethod\n    @abstractmethod\n    def _init_worker(cls, images: Dict[str, str]) -&gt; None:\n        \"\"\"\n        Initializes a static worker with shared data for multiprocessing.\n\n        Args:\n            images (Dict[str, str]): A dictionary mapping image stems to absolute paths.\n        \"\"\"\n        pass\n\n    @staticmethod\n    @abstractmethod\n    def _analyze_worker(\n            file_path: Path,\n            reader: BaseReader,\n            margin_threshold: int = 5,\n            class_mapping: Optional[Dict[str, str]] = None\n    ) -&gt; List[Dict[str, str]]:\n        \"\"\"\n        Processes a single annotation file to extract features.\n\n        Args:\n            file_path (Path): Path to the annotation file.\n            reader (BaseReader): Annotation reader instance.\n            margin_threshold (int): Pixel margin for boundary analysis.\n            class_mapping (Optional[Dict[str, str]]): Map of class IDs to names.\n\n        Returns:\n            List[Dict[str, str]]: A list of dictionaries, where each dict represents\n                features of one detected object.\n        \"\"\"\n        pass\n\n    @staticmethod\n    @abstractmethod\n    def get_umap_features(df: pd.DataFrame) -&gt; List[str]:\n        \"\"\"\n        Defines the list of numeric features to be used for UMAP projection.\n\n        Args:\n            df (pd.DataFrame): The extracted feature matrix.\n\n        Returns:\n            List[str]: List of column names for dimensionality reduction.\n        \"\"\"\n        pass\n\n    def get_features(\n            self,\n            file_paths: Tuple[Path, ...],\n            class_mapping: Optional[Dict[str, str]] = None\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Orchestrates feature extraction using incremental caching and parallel processing.\n\n        This method checks the modification time (mtime) of each file. It only\n        processes new or changed files, significantly reducing execution time\n        for large datasets.\n\n        Args:\n            file_paths (Tuple[Path, ...]): List of annotation files to process.\n            class_mapping (Optional[Dict[str, str]]): Class ID to name mapping.\n\n        Returns:\n            pd.DataFrame: A complete feature matrix including UMAP coordinates\n                and outlier flags.\n        \"\"\"\n        if not file_paths:\n            return pd.DataFrame()\n\n        cache_file = self.settings.cache_file_path / self.cache_io.generate_cache_filename(\n            source_path=file_paths[0].parent,\n            cache_name=self.settings.cache_name,\n            format=self.source_suffix,\n            task=self.TASK\n        )\n\n        df_cached = self.cache_io.load(cache_file)\n\n        if df_cached.empty:\n            df_final = pd.DataFrame()\n            files_for_task = file_paths\n        else:\n            current_files_state = [\n                {ImageStatsKeys.path: str(path.resolve()), ImageStatsKeys.mtime: path.stat().st_mtime}\n                                   for path in file_paths\n            ]\n            df_disk = pd.DataFrame(current_files_state)\n            merged = df_disk.merge(\n                df_cached[[ImageStatsKeys.path, ImageStatsKeys.mtime]].drop_duplicates(),\n                how=\"left\",\n                on=ImageStatsKeys.path,\n                suffixes=[\"\", \"_old\"]\n            )\n\n            to_update_mask = (\n                    (merged[f\"{ImageStatsKeys.mtime}_old\"].isna()) |\n                    (merged[ImageStatsKeys.mtime] != merged[f\"{ImageStatsKeys.mtime}_old\"]))\n            files_for_task = [Path(p) for p in merged.loc[to_update_mask, ImageStatsKeys.path]]\n            df_final = df_cached[df_cached[ImageStatsKeys.path].isin(df_disk[~to_update_mask][ImageStatsKeys.path])]\n\n        if files_for_task:\n            self.logger.info(f\"Incremental update: processing {len(files_for_task)} files with {self.n_jobs} workers\")\n            images = {img.stem: str(img.resolve()) for img in self.img_path.iterdir() if\n                      img.suffix.lower() in self.extensions}\n\n            worker_func = partial(\n                self._analyze_worker,\n                reader=self.reader,\n                margin_threshold=self.margin_threshold,\n                class_mapping=class_mapping)\n\n            with ProcessPoolExecutor(\n                    max_workers=self.n_jobs,\n                    initializer=self.__class__._init_worker,\n                    initargs=(images,)\n            ) as executor:\n                results = list(executor.map(worker_func, files_for_task))\n\n            new_data = [item for sublist in results for item in sublist]\n\n            if new_data:\n                df_new = pd.DataFrame(new_data)\n                mtime_map = {str(path): path.stat().st_mtime for path in files_for_task}\n                df_new[ImageStatsKeys.mtime] = df_new[ImageStatsKeys.path].map(mtime_map)\n                df_final = pd.concat([df_final, df_new], ignore_index=True)\n                df_final.reset_index(drop=True, inplace=True)\n\n                numeric_cols = []\n                for section in self.settings.img_dataset_report_schema:\n                    if section[\"type\"] == \"numeric\":\n                        numeric_cols.extend(section[\"columns\"])\n\n\n                df_final = OutlierDetector.mark_outliers(df_final, numeric_cols)\n                self.logger.info(f\"computing UMAP coordinates for the entire dataset with {self.n_jobs} workers\")\n                features = self.get_umap_features(df_final)\n                df_final = self.compute_umap_coords(df=df_final, features=features)\n            if files_for_task or (len(df_cached) != len(df_final)):\n                self.cache_io.save(df_final, cache_file)\n                self.logger.info(f\"Cache updated at {cache_file} with {len(df_final)} records\")\n\n        return df_final\n\n\n    def compute_umap_coords(self, df: pd.DataFrame, features: List[str]) -&gt; pd.DataFrame:\n        \"\"\"\n        Performs dimensionality reduction to visualize the dataset manifold.\n\n        Uses StandardScaler for normalization and UMAP to project high-dimensional\n        features into a 2D space. Results are saved as 'umap_x' and 'umap_y' columns.\n\n        Args:\n            df (pd.DataFrame): The feature matrix.\n            features (List[str]): Columns to be used for reduction.\n\n        Returns:\n            pd.DataFrame: DataFrame with added UMAP coordinates.\n        \"\"\"\n\n        x_data = df[features].fillna(0)\n        x_data = x_data.loc[:, x_data.var() &gt; 0]\n\n        if x_data.shape[1] &lt; 2:\n            return df\n\n        x_scaled = StandardScaler().fit_transform(x_data)\n        n_neighbors = int(np.clip(len(x_data) * 0.1, a_min=15, a_max=50))\n        reducer = UMAP(n_neighbors=n_neighbors, min_dist=0.1, n_components=2, n_jobs=self.n_jobs)\n        embedding = reducer.fit_transform(x_scaled)\n\n        df['umap_x'] = embedding[:, 0]\n        df['umap_y'] = embedding[:, 1]\n\n        return df\n\n    def set_class_mapping(self, file_paths: Tuple[Path]) -&gt; Dict[str, str]:\n        \"\"\"\n        Identifies and loads the class name mapping from a definition file.\n\n        Specifically looks for 'classes.txt' in the source directory (YOLO standard).\n\n        Args:\n            file_paths (Tuple[Path]): List of files in the source directory.\n\n        Returns:\n            Dict[str, str]: A dictionary mapping class IDs to human-readable names.\n        \"\"\"\n        classes_file = next((path for path in file_paths if path.name == \"classes.txt\"), None)\n        if classes_file is None:\n            self.logger.warning(\n                f\"No classes file found at {file_paths[0].parent}, class names will be taken from annotations as is\"\n            )\n\n        classes_mapping = self.reader.read(classes_file)\n        self.logger.info(f\"Class mapping loaded with {len(classes_mapping)} entries\")\n        classes_mapping = {value: key for key, value in classes_mapping.items()}\n        return classes_mapping\n</code></pre>"},{"location":"api/base_stats/#tools.stats.base_stats.BaseStats.__init__","title":"<code>__init__(source_format, log_level=LevelMapping.debug, log_path=None, settings=None, cache_io=None, img_path=None, extensions=None)</code>","text":"<p>Initializes the analytical engine with specific formats and IO tools.</p> <p>Parameters:</p> Name Type Description Default <code>source_format</code> <code>str</code> <p>Annotation format identifier (e.g., 'yolo', 'voc').</p> required <code>log_level</code> <code>str</code> <p>Minimum logging level. Defaults to 'INFO'.</p> <code>debug</code> <code>log_path</code> <code>Optional[Path]</code> <p>Directory for log files.</p> <code>None</code> <code>settings</code> <code>Optional[AppSettings]</code> <p>Application-wide settings.</p> <code>None</code> <code>cache_io</code> <code>Optional[CacheIO]</code> <p>Component for Parquet-based caching.</p> <code>None</code> <code>img_path</code> <code>Optional[Union[Path, str]]</code> <p>Path to the dataset images.</p> <code>None</code> <code>extensions</code> <code>Optional[Tuple[str, ...]]</code> <p>Valid image file extensions.</p> <code>None</code> Source code in <code>tools/stats/base_stats.py</code> <pre><code>def __init__(\n        self,\n        source_format: str,\n        log_level: str = LevelMapping.debug,\n        log_path: Optional[Path] = None,\n        settings: Optional[AppSettings] = None,\n        cache_io: Optional[CacheIO] = None,\n        img_path: Optional[Union[Path, str]] = None,\n        extensions: Optional[Tuple[str, ...]] = None,\n):\n    \"\"\"\n    Initializes the analytical engine with specific formats and IO tools.\n\n    Args:\n        source_format (str): Annotation format identifier (e.g., 'yolo', 'voc').\n        log_level (str): Minimum logging level. Defaults to 'INFO'.\n        log_path (Optional[Path]): Directory for log files.\n        settings (Optional[AppSettings]): Application-wide settings.\n        cache_io (Optional[CacheIO]): Component for Parquet-based caching.\n        img_path (Optional[Union[Path, str]]): Path to the dataset images.\n        extensions (Optional[Tuple[str, ...]]): Valid image file extensions.\n    \"\"\"\n\n    self.reader_mapping = {\n        \".xml\": XMLReader,\n        \".txt\": TXTReader\n    }\n\n    self.suffix_mapping = {\n        \"voc\": \".xml\",\n        \"yolo\": \".txt\"\n    }\n\n    self.settings = settings\n    self.extensions = extensions\n    self.img_path = img_path\n    self.margin_threshold: int = self.settings.margin_threshold\n    self.reader = self.reader_mapping.get(source_format, None)\n    self.source_suffix = self.suffix_mapping.get(source_format)\n    self.reader = self.reader_mapping[self.source_suffix]()\n    self.cache_io = cache_io or CacheIO(self.settings)\n    self.n_jobs = self.settings.n_jobs\n    self.logger = LoggerConfigurator.setup(\n        name=self.__class__.__name__,\n        log_level=log_level,\n        log_path=Path(log_path) / f\"{self.__class__.__name__}.log\" if log_path else None\n    )\n</code></pre>"},{"location":"api/base_stats/#tools.stats.base_stats.BaseStats.compute_umap_coords","title":"<code>compute_umap_coords(df, features)</code>","text":"<p>Performs dimensionality reduction to visualize the dataset manifold.</p> <p>Uses StandardScaler for normalization and UMAP to project high-dimensional features into a 2D space. Results are saved as 'umap_x' and 'umap_y' columns.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The feature matrix.</p> required <code>features</code> <code>List[str]</code> <p>Columns to be used for reduction.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with added UMAP coordinates.</p> Source code in <code>tools/stats/base_stats.py</code> <pre><code>def compute_umap_coords(self, df: pd.DataFrame, features: List[str]) -&gt; pd.DataFrame:\n    \"\"\"\n    Performs dimensionality reduction to visualize the dataset manifold.\n\n    Uses StandardScaler for normalization and UMAP to project high-dimensional\n    features into a 2D space. Results are saved as 'umap_x' and 'umap_y' columns.\n\n    Args:\n        df (pd.DataFrame): The feature matrix.\n        features (List[str]): Columns to be used for reduction.\n\n    Returns:\n        pd.DataFrame: DataFrame with added UMAP coordinates.\n    \"\"\"\n\n    x_data = df[features].fillna(0)\n    x_data = x_data.loc[:, x_data.var() &gt; 0]\n\n    if x_data.shape[1] &lt; 2:\n        return df\n\n    x_scaled = StandardScaler().fit_transform(x_data)\n    n_neighbors = int(np.clip(len(x_data) * 0.1, a_min=15, a_max=50))\n    reducer = UMAP(n_neighbors=n_neighbors, min_dist=0.1, n_components=2, n_jobs=self.n_jobs)\n    embedding = reducer.fit_transform(x_scaled)\n\n    df['umap_x'] = embedding[:, 0]\n    df['umap_y'] = embedding[:, 1]\n\n    return df\n</code></pre>"},{"location":"api/base_stats/#tools.stats.base_stats.BaseStats.get_features","title":"<code>get_features(file_paths, class_mapping=None)</code>","text":"<p>Orchestrates feature extraction using incremental caching and parallel processing.</p> <p>This method checks the modification time (mtime) of each file. It only processes new or changed files, significantly reducing execution time for large datasets.</p> <p>Parameters:</p> Name Type Description Default <code>file_paths</code> <code>Tuple[Path, ...]</code> <p>List of annotation files to process.</p> required <code>class_mapping</code> <code>Optional[Dict[str, str]]</code> <p>Class ID to name mapping.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A complete feature matrix including UMAP coordinates and outlier flags.</p> Source code in <code>tools/stats/base_stats.py</code> <pre><code>def get_features(\n        self,\n        file_paths: Tuple[Path, ...],\n        class_mapping: Optional[Dict[str, str]] = None\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Orchestrates feature extraction using incremental caching and parallel processing.\n\n    This method checks the modification time (mtime) of each file. It only\n    processes new or changed files, significantly reducing execution time\n    for large datasets.\n\n    Args:\n        file_paths (Tuple[Path, ...]): List of annotation files to process.\n        class_mapping (Optional[Dict[str, str]]): Class ID to name mapping.\n\n    Returns:\n        pd.DataFrame: A complete feature matrix including UMAP coordinates\n            and outlier flags.\n    \"\"\"\n    if not file_paths:\n        return pd.DataFrame()\n\n    cache_file = self.settings.cache_file_path / self.cache_io.generate_cache_filename(\n        source_path=file_paths[0].parent,\n        cache_name=self.settings.cache_name,\n        format=self.source_suffix,\n        task=self.TASK\n    )\n\n    df_cached = self.cache_io.load(cache_file)\n\n    if df_cached.empty:\n        df_final = pd.DataFrame()\n        files_for_task = file_paths\n    else:\n        current_files_state = [\n            {ImageStatsKeys.path: str(path.resolve()), ImageStatsKeys.mtime: path.stat().st_mtime}\n                               for path in file_paths\n        ]\n        df_disk = pd.DataFrame(current_files_state)\n        merged = df_disk.merge(\n            df_cached[[ImageStatsKeys.path, ImageStatsKeys.mtime]].drop_duplicates(),\n            how=\"left\",\n            on=ImageStatsKeys.path,\n            suffixes=[\"\", \"_old\"]\n        )\n\n        to_update_mask = (\n                (merged[f\"{ImageStatsKeys.mtime}_old\"].isna()) |\n                (merged[ImageStatsKeys.mtime] != merged[f\"{ImageStatsKeys.mtime}_old\"]))\n        files_for_task = [Path(p) for p in merged.loc[to_update_mask, ImageStatsKeys.path]]\n        df_final = df_cached[df_cached[ImageStatsKeys.path].isin(df_disk[~to_update_mask][ImageStatsKeys.path])]\n\n    if files_for_task:\n        self.logger.info(f\"Incremental update: processing {len(files_for_task)} files with {self.n_jobs} workers\")\n        images = {img.stem: str(img.resolve()) for img in self.img_path.iterdir() if\n                  img.suffix.lower() in self.extensions}\n\n        worker_func = partial(\n            self._analyze_worker,\n            reader=self.reader,\n            margin_threshold=self.margin_threshold,\n            class_mapping=class_mapping)\n\n        with ProcessPoolExecutor(\n                max_workers=self.n_jobs,\n                initializer=self.__class__._init_worker,\n                initargs=(images,)\n        ) as executor:\n            results = list(executor.map(worker_func, files_for_task))\n\n        new_data = [item for sublist in results for item in sublist]\n\n        if new_data:\n            df_new = pd.DataFrame(new_data)\n            mtime_map = {str(path): path.stat().st_mtime for path in files_for_task}\n            df_new[ImageStatsKeys.mtime] = df_new[ImageStatsKeys.path].map(mtime_map)\n            df_final = pd.concat([df_final, df_new], ignore_index=True)\n            df_final.reset_index(drop=True, inplace=True)\n\n            numeric_cols = []\n            for section in self.settings.img_dataset_report_schema:\n                if section[\"type\"] == \"numeric\":\n                    numeric_cols.extend(section[\"columns\"])\n\n\n            df_final = OutlierDetector.mark_outliers(df_final, numeric_cols)\n            self.logger.info(f\"computing UMAP coordinates for the entire dataset with {self.n_jobs} workers\")\n            features = self.get_umap_features(df_final)\n            df_final = self.compute_umap_coords(df=df_final, features=features)\n        if files_for_task or (len(df_cached) != len(df_final)):\n            self.cache_io.save(df_final, cache_file)\n            self.logger.info(f\"Cache updated at {cache_file} with {len(df_final)} records\")\n\n    return df_final\n</code></pre>"},{"location":"api/base_stats/#tools.stats.base_stats.BaseStats.get_umap_features","title":"<code>get_umap_features(df)</code>  <code>abstractmethod</code> <code>staticmethod</code>","text":"<p>Defines the list of numeric features to be used for UMAP projection.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The extracted feature matrix.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of column names for dimensionality reduction.</p> Source code in <code>tools/stats/base_stats.py</code> <pre><code>@staticmethod\n@abstractmethod\ndef get_umap_features(df: pd.DataFrame) -&gt; List[str]:\n    \"\"\"\n    Defines the list of numeric features to be used for UMAP projection.\n\n    Args:\n        df (pd.DataFrame): The extracted feature matrix.\n\n    Returns:\n        List[str]: List of column names for dimensionality reduction.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/base_stats/#tools.stats.base_stats.BaseStats.set_class_mapping","title":"<code>set_class_mapping(file_paths)</code>","text":"<p>Identifies and loads the class name mapping from a definition file.</p> <p>Specifically looks for 'classes.txt' in the source directory (YOLO standard).</p> <p>Parameters:</p> Name Type Description Default <code>file_paths</code> <code>Tuple[Path]</code> <p>List of files in the source directory.</p> required <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dict[str, str]: A dictionary mapping class IDs to human-readable names.</p> Source code in <code>tools/stats/base_stats.py</code> <pre><code>def set_class_mapping(self, file_paths: Tuple[Path]) -&gt; Dict[str, str]:\n    \"\"\"\n    Identifies and loads the class name mapping from a definition file.\n\n    Specifically looks for 'classes.txt' in the source directory (YOLO standard).\n\n    Args:\n        file_paths (Tuple[Path]): List of files in the source directory.\n\n    Returns:\n        Dict[str, str]: A dictionary mapping class IDs to human-readable names.\n    \"\"\"\n    classes_file = next((path for path in file_paths if path.name == \"classes.txt\"), None)\n    if classes_file is None:\n        self.logger.warning(\n            f\"No classes file found at {file_paths[0].parent}, class names will be taken from annotations as is\"\n        )\n\n    classes_mapping = self.reader.read(classes_file)\n    self.logger.info(f\"Class mapping loaded with {len(classes_mapping)} entries\")\n    classes_mapping = {value: key for key, value in classes_mapping.items()}\n    return classes_mapping\n</code></pre>"},{"location":"api/base_writer/","title":"Base writer","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for all data writers in DataForge.</p> <p>This class defines the standard interface for saving processed annotation data into various file formats (such as YOLO .txt or Pascal VOC .xml). Specific writer implementations must provide their own 'write' logic.</p> Source code in <code>tools/annotation_converter/writer/base.py</code> <pre><code>class BaseWriter(ABC):\n    \"\"\"\n    Abstract base class for all data writers in DataForge.\n\n    This class defines the standard interface for saving processed annotation\n    data into various file formats (such as YOLO .txt or Pascal VOC .xml).\n    Specific writer implementations must provide their own 'write' logic.\n    \"\"\"\n    def __init__(self):\n        \"\"\" Initializes the base writer instance. \"\"\"\n        pass\n\n\n    @abstractmethod\n    def write(self, data: Union[tuple, list, dict, str], file_path: Path) -&gt; None:\n        \"\"\"\n        Writes data to the specified file path.\n\n        Args:\n            data (Union[tuple, list, dict, str]): The content to be written (can be a list, dictionary, or string\n                depending on the specific writer).\n            file_path (Path): The target path where the file will be saved.\n\n        Raises:\n            IOError: If the file cannot be written to the disk.\n            NotImplementedError: If the method is not implemented by a subclass.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/base_writer/#tools.annotation_converter.writer.base.BaseWriter.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the base writer instance.</p> Source code in <code>tools/annotation_converter/writer/base.py</code> <pre><code>def __init__(self):\n    \"\"\" Initializes the base writer instance. \"\"\"\n    pass\n</code></pre>"},{"location":"api/base_writer/#tools.annotation_converter.writer.base.BaseWriter.write","title":"<code>write(data, file_path)</code>  <code>abstractmethod</code>","text":"<p>Writes data to the specified file path.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[tuple, list, dict, str]</code> <p>The content to be written (can be a list, dictionary, or string depending on the specific writer).</p> required <code>file_path</code> <code>Path</code> <p>The target path where the file will be saved.</p> required <p>Raises:</p> Type Description <code>IOError</code> <p>If the file cannot be written to the disk.</p> <code>NotImplementedError</code> <p>If the method is not implemented by a subclass.</p> Source code in <code>tools/annotation_converter/writer/base.py</code> <pre><code>@abstractmethod\ndef write(self, data: Union[tuple, list, dict, str], file_path: Path) -&gt; None:\n    \"\"\"\n    Writes data to the specified file path.\n\n    Args:\n        data (Union[tuple, list, dict, str]): The content to be written (can be a list, dictionary, or string\n            depending on the specific writer).\n        file_path (Path): The target path where the file will be saved.\n\n    Raises:\n        IOError: If the file cannot be written to the disk.\n        NotImplementedError: If the method is not implemented by a subclass.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/cache_io/","title":"CacheIO","text":"<p>Handles high-performance data persistence using Apache Parquet.</p> <p>This class provides methods to save and load complex data structures like image hash maps or pandas DataFrames. It optimizes I/O performance and ensures data integrity across different operations.</p> <p>Attributes:</p> Name Type Description <code>SUFFIX</code> <code>str</code> <p>The standard file extension for cache files (.parquet).</p> <code>settings</code> <code>AppSettings</code> <p>Global configuration instance.</p> <code>logger</code> <code>Logger</code> <p>Logger instance for tracking I/O operations.</p> Source code in <code>tools/cache.py</code> <pre><code>class CacheIO:\n    \"\"\"\n    Handles high-performance data persistence using Apache Parquet.\n\n    This class provides methods to save and load complex data structures like\n    image hash maps or pandas DataFrames. It optimizes I/O performance\n    and ensures data integrity across different operations.\n\n    Attributes:\n        SUFFIX (str): The standard file extension for cache files (.parquet).\n        settings (AppSettings): Global configuration instance.\n        logger (logging.Logger): Logger instance for tracking I/O operations.\n    \"\"\"\n    SUFFIX = \".parquet\"\n\n    def __init__(self, settings: AppSettings):\n        \"\"\"\n        Initializes CacheIO with the provided application settings.\n\n        Args:\n            settings (AppSettings): Application configuration for paths and logging.\n        \"\"\"\n        self.settings = settings\n        self.logger = LoggerConfigurator.setup(\n            name=self.__class__.__name__,\n            log_path=Path(self.settings.log_path) / f\"{self.__class__.__name__}.log\",\n            log_level=self.settings.log_level\n        )\n\n\n    def load(self: LoggerProtocol, cache_file: Path) -&gt; pd.DataFrame:\n        \"\"\"\n        Loads data from a parquet cache file into a DataFrame.\n\n        Args:\n            cache_file (Path): The path to the .parquet file.\n\n        Returns:\n            pd.DataFrame: The loaded data or an empty DataFrame if the file\n                is missing or corrupted.\n        \"\"\"\n        if not cache_file.exists():\n            self.logger.warning(f\"Cache file {cache_file} does not exist\")\n            return pd.DataFrame()\n\n        try:\n            self.logger.info(f\"Loading cache file {cache_file}\")\n            df = pd.read_parquet(cache_file)\n\n            return df\n        except Exception as e:\n            self.logger.error(f\"Cache file {cache_file.name} is corrupted: {e}. Deleting.\")\n            cache_file.unlink(missing_ok=True)\n            return pd.DataFrame()\n\n\n    def save(self: LoggerProtocol, data_map: Union[Dict[Path, np.ndarray], pd.DataFrame], cache_file: Path) -&gt; None:\n        \"\"\"\n        Saves a dictionary of hashes or a pandas DataFrame to a parquet file.\n\n        Args:\n            data_map (Union[Dict[Path, np.ndarray], pd.DataFrame]): Data to store.\n            cache_file (Path): Target path for the cache file.\n\n        Raises:\n            TypeError: If the data_map is not a dictionary or a DataFrame.\n        \"\"\"\n        empty_msg = \"data_map is empty, skipping saving cache data\"\n\n        if isinstance(data_map, dict):\n            if not data_map:\n                self.logger.warning(empty_msg)\n                return\n            data = [\n                {'path': str(p), 'hash': h.tolist()}\n                for p, h in data_map.items()\n            ]\n            df = pd.DataFrame(data)\n\n        elif isinstance(data_map, pd.DataFrame):\n            if data_map.empty:\n                self.logger.warning(empty_msg)\n                return\n            df = data_map\n        else:\n            msg = f\"data_map must be either a dictionary or a DataFrame, got {type(data_map)}\"\n            self.logger.warning(msg)\n            raise TypeError(msg)\n\n        cache_file.parent.mkdir(parents=True, exist_ok=True)\n        self.logger.info(f\"Saving {len(data_map)} hashes to {cache_file.name}\")\n\n        try:\n            df.to_parquet(cache_file, engine=\"pyarrow\", compression=\"snappy\", index=False)\n            self.logger.info(f\"Cache saved successfully to {cache_file}.\")\n        except Exception as e:\n            self.logger.error(f\"Critical error saving cache: {e}\")\n\n\n    @classmethod\n    def generate_cache_filename(cls, source_path: Path, cache_name: Optional[Union[str, Path]], **kwargs: Any) -&gt; str:\n        \"\"\"\n        Generates a unique, versioned filename for the cache.\n\n        Args:\n            source_path (Path): The directory path being processed.\n            cache_name (Optional[Union[str, Path]]): A custom name for the file.\n            **kwargs (dict): Key-value pairs to include in the versioning (e.g., core_size=16).\n\n        Returns:\n            str: A stable and unique filename string.\n        \"\"\"\n        param_suffix = \"\".join([f\"_{key}_{value}\" for key, value in kwargs.items()])\n        full_suffix = f\"{param_suffix}{cls.SUFFIX}\"\n\n        if cache_name is None:\n\n            abs_path = str(source_path.resolve())\n            path_hash = hashlib.md5(abs_path.encode('utf-8')).hexdigest()\n            folder_name = str(source_path.name.replace(' ', '_').strip(\".\"))[:30]\n            return f\"cache_{path_hash}_{folder_name}{full_suffix}\"\n        else:\n            cache_name = str(cache_name).replace(\" \", \"_\").strip(\".\")\n            if cache_name.endswith(cls.SUFFIX):\n                cache_name = cache_name[:-len(cls.SUFFIX)]\n\n            cache_name = f\"{cache_name}_{full_suffix}\"\n            return cache_name\n</code></pre>"},{"location":"api/cache_io/#tools.cache.CacheIO.__init__","title":"<code>__init__(settings)</code>","text":"<p>Initializes CacheIO with the provided application settings.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>Application configuration for paths and logging.</p> required Source code in <code>tools/cache.py</code> <pre><code>def __init__(self, settings: AppSettings):\n    \"\"\"\n    Initializes CacheIO with the provided application settings.\n\n    Args:\n        settings (AppSettings): Application configuration for paths and logging.\n    \"\"\"\n    self.settings = settings\n    self.logger = LoggerConfigurator.setup(\n        name=self.__class__.__name__,\n        log_path=Path(self.settings.log_path) / f\"{self.__class__.__name__}.log\",\n        log_level=self.settings.log_level\n    )\n</code></pre>"},{"location":"api/cache_io/#tools.cache.CacheIO.generate_cache_filename","title":"<code>generate_cache_filename(source_path, cache_name, **kwargs)</code>  <code>classmethod</code>","text":"<p>Generates a unique, versioned filename for the cache.</p> <p>Parameters:</p> Name Type Description Default <code>source_path</code> <code>Path</code> <p>The directory path being processed.</p> required <code>cache_name</code> <code>Optional[Union[str, Path]]</code> <p>A custom name for the file.</p> required <code>**kwargs</code> <code>dict</code> <p>Key-value pairs to include in the versioning (e.g., core_size=16).</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A stable and unique filename string.</p> Source code in <code>tools/cache.py</code> <pre><code>@classmethod\ndef generate_cache_filename(cls, source_path: Path, cache_name: Optional[Union[str, Path]], **kwargs: Any) -&gt; str:\n    \"\"\"\n    Generates a unique, versioned filename for the cache.\n\n    Args:\n        source_path (Path): The directory path being processed.\n        cache_name (Optional[Union[str, Path]]): A custom name for the file.\n        **kwargs (dict): Key-value pairs to include in the versioning (e.g., core_size=16).\n\n    Returns:\n        str: A stable and unique filename string.\n    \"\"\"\n    param_suffix = \"\".join([f\"_{key}_{value}\" for key, value in kwargs.items()])\n    full_suffix = f\"{param_suffix}{cls.SUFFIX}\"\n\n    if cache_name is None:\n\n        abs_path = str(source_path.resolve())\n        path_hash = hashlib.md5(abs_path.encode('utf-8')).hexdigest()\n        folder_name = str(source_path.name.replace(' ', '_').strip(\".\"))[:30]\n        return f\"cache_{path_hash}_{folder_name}{full_suffix}\"\n    else:\n        cache_name = str(cache_name).replace(\" \", \"_\").strip(\".\")\n        if cache_name.endswith(cls.SUFFIX):\n            cache_name = cache_name[:-len(cls.SUFFIX)]\n\n        cache_name = f\"{cache_name}_{full_suffix}\"\n        return cache_name\n</code></pre>"},{"location":"api/cache_io/#tools.cache.CacheIO.load","title":"<code>load(cache_file)</code>","text":"<p>Loads data from a parquet cache file into a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>cache_file</code> <code>Path</code> <p>The path to the .parquet file.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The loaded data or an empty DataFrame if the file is missing or corrupted.</p> Source code in <code>tools/cache.py</code> <pre><code>def load(self: LoggerProtocol, cache_file: Path) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads data from a parquet cache file into a DataFrame.\n\n    Args:\n        cache_file (Path): The path to the .parquet file.\n\n    Returns:\n        pd.DataFrame: The loaded data or an empty DataFrame if the file\n            is missing or corrupted.\n    \"\"\"\n    if not cache_file.exists():\n        self.logger.warning(f\"Cache file {cache_file} does not exist\")\n        return pd.DataFrame()\n\n    try:\n        self.logger.info(f\"Loading cache file {cache_file}\")\n        df = pd.read_parquet(cache_file)\n\n        return df\n    except Exception as e:\n        self.logger.error(f\"Cache file {cache_file.name} is corrupted: {e}. Deleting.\")\n        cache_file.unlink(missing_ok=True)\n        return pd.DataFrame()\n</code></pre>"},{"location":"api/cache_io/#tools.cache.CacheIO.save","title":"<code>save(data_map, cache_file)</code>","text":"<p>Saves a dictionary of hashes or a pandas DataFrame to a parquet file.</p> <p>Parameters:</p> Name Type Description Default <code>data_map</code> <code>Union[Dict[Path, ndarray], DataFrame]</code> <p>Data to store.</p> required <code>cache_file</code> <code>Path</code> <p>Target path for the cache file.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If the data_map is not a dictionary or a DataFrame.</p> Source code in <code>tools/cache.py</code> <pre><code>def save(self: LoggerProtocol, data_map: Union[Dict[Path, np.ndarray], pd.DataFrame], cache_file: Path) -&gt; None:\n    \"\"\"\n    Saves a dictionary of hashes or a pandas DataFrame to a parquet file.\n\n    Args:\n        data_map (Union[Dict[Path, np.ndarray], pd.DataFrame]): Data to store.\n        cache_file (Path): Target path for the cache file.\n\n    Raises:\n        TypeError: If the data_map is not a dictionary or a DataFrame.\n    \"\"\"\n    empty_msg = \"data_map is empty, skipping saving cache data\"\n\n    if isinstance(data_map, dict):\n        if not data_map:\n            self.logger.warning(empty_msg)\n            return\n        data = [\n            {'path': str(p), 'hash': h.tolist()}\n            for p, h in data_map.items()\n        ]\n        df = pd.DataFrame(data)\n\n    elif isinstance(data_map, pd.DataFrame):\n        if data_map.empty:\n            self.logger.warning(empty_msg)\n            return\n        df = data_map\n    else:\n        msg = f\"data_map must be either a dictionary or a DataFrame, got {type(data_map)}\"\n        self.logger.warning(msg)\n        raise TypeError(msg)\n\n    cache_file.parent.mkdir(parents=True, exist_ok=True)\n    self.logger.info(f\"Saving {len(data_map)} hashes to {cache_file.name}\")\n\n    try:\n        df.to_parquet(cache_file, engine=\"pyarrow\", compression=\"snappy\", index=False)\n        self.logger.info(f\"Cache saved successfully to {cache_file}.\")\n    except Exception as e:\n        self.logger.error(f\"Critical error saving cache: {e}\")\n</code></pre>"},{"location":"api/data_forge/","title":"Main","text":"<p>The main entry point for the DataForge toolkit.</p> <p>This class orchestrates the Command Line Interface (CLI). It registers all available file operations, loads the global configuration, and manages the execution of specific tasks based on user input.</p> <p>Attributes:</p> Name Type Description <code>parser</code> <code>ArgumentParser</code> <p>The main CLI parser.</p> <code>subparsers</code> <code>_SubParsersAction</code> <p>A collection of command-specific parsers.</p> <code>commands</code> <code>Dict[str, Type[FileOperation]]</code> <p>A mapping of command names to their respective operation classes.</p> <code>settings</code> <code>AppSettings</code> <p>The global configuration object loaded from JSON and environment variables.</p> Source code in <code>data_forge.py</code> <pre><code>class DataForge:\n    \"\"\"\n    The main entry point for the DataForge toolkit.\n\n    This class orchestrates the Command Line Interface (CLI). It registers\n    all available file operations, loads the global configuration, and\n    manages the execution of specific tasks based on user input.\n\n    Attributes:\n        parser (argparse.ArgumentParser): The main CLI parser.\n        subparsers (argparse._SubParsersAction): A collection of command-specific parsers.\n        commands (Dict[str, Type[FileOperation]]): A mapping of command names\n            to their respective operation classes.\n        settings (AppSettings): The global configuration object loaded from\n            JSON and environment variables.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the DataForge application.\n\n        It sets up the argument parser, registers the list of supported\n        commands, and loads the initial settings from the configuration file.\n        \"\"\"\n        self.parser = argparse.ArgumentParser(description=\"FileManager\")\n        self.subparsers = self.parser.add_subparsers(dest=\"command\")\n        self.commands = {\n            Commands.move: MoveOperation,\n            Commands.slice: SliceOperation,\n            Commands.delete: DeleteOperation,\n            Commands.dedup: DedupOperation,\n            Commands.clean_annotations: CleanAnnotationsOperation,\n            Commands.convert_annotations: ConvertAnnotationsOperation,\n            Commands.stats: StatsOperation\n        }\n        self.settings = AppSettings.load_config(Constants.config_file)\n        self._setup_commands()\n\n\n    @staticmethod\n    def _add_common_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n        \"\"\"\n        Adds shared arguments to a command subparser.\n\n        These arguments are available for all operations, such as source\n        directory, file patterns, and execution loop settings.\n\n        Args:\n            settings (AppSettings): Configuration object used to set default values.\n            parser (argparse.ArgumentParser): The subparser for a specific command.\n        \"\"\"\n        parser.add_argument(arg.src, help=hs.src)\n        parser.add_argument(arg.pattern, arg.p, help=hs.pattern, nargs=\"+\", default=[settings.pattern])\n        parser.add_argument(arg.repeat, arg.r, help=hs.repeat, action='store_true')\n        parser.add_argument(arg.sleep, arg.s, help=hs.sleep, default=settings.sleep)\n        parser.add_argument(arg.log_path, help=hs.log_path, default=settings.log_path)\n        parser.add_argument(arg.log_level, help=hs.log_level, default=settings.log_level)\n\n\n    def _setup_commands(self) -&gt; None:\n        \"\"\"\n        Registers and configures all operation commands.\n\n        It iterates through the 'commands' dictionary to create subparsers\n        and adds both common and operation-specific arguments for each command.\n        \"\"\"\n        for command, operation_class in self.commands.items():\n            subparser = self.subparsers.add_parser(command)\n            self._add_common_arguments(self.settings, subparser)\n            operation_class.add_arguments(self.settings, subparser)\n            subparser.set_defaults(cls=operation_class)\n\n\n    def execute(self):\n        \"\"\"\n        Parses CLI arguments and executes the selected operation.\n\n        This method merges the input from the command line with the\n        existing settings. It ensures that CLI arguments have the highest\n        priority. Then, it creates an instance of the chosen operation\n        and calls its 'run' method.\n        \"\"\"\n        args = self.parser.parse_args()\n        cli_data = {key: value for key, value in vars(args).items() if value is not None and key != \"command\"}\n\n        if hasattr(args, \"cls\"):\n            for key, value in cli_data.items():\n                if hasattr(self.settings, key):\n                    setattr(self.settings, key, value)\n            operation = args.cls(settings=self.settings, **vars(args))\n            operation.run()\n        else:\n            self.parser.print_help()\n</code></pre>"},{"location":"api/data_forge/#data_forge.DataForge.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the DataForge application.</p> <p>It sets up the argument parser, registers the list of supported commands, and loads the initial settings from the configuration file.</p> Source code in <code>data_forge.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes the DataForge application.\n\n    It sets up the argument parser, registers the list of supported\n    commands, and loads the initial settings from the configuration file.\n    \"\"\"\n    self.parser = argparse.ArgumentParser(description=\"FileManager\")\n    self.subparsers = self.parser.add_subparsers(dest=\"command\")\n    self.commands = {\n        Commands.move: MoveOperation,\n        Commands.slice: SliceOperation,\n        Commands.delete: DeleteOperation,\n        Commands.dedup: DedupOperation,\n        Commands.clean_annotations: CleanAnnotationsOperation,\n        Commands.convert_annotations: ConvertAnnotationsOperation,\n        Commands.stats: StatsOperation\n    }\n    self.settings = AppSettings.load_config(Constants.config_file)\n    self._setup_commands()\n</code></pre>"},{"location":"api/data_forge/#data_forge.DataForge.execute","title":"<code>execute()</code>","text":"<p>Parses CLI arguments and executes the selected operation.</p> <p>This method merges the input from the command line with the existing settings. It ensures that CLI arguments have the highest priority. Then, it creates an instance of the chosen operation and calls its 'run' method.</p> Source code in <code>data_forge.py</code> <pre><code>def execute(self):\n    \"\"\"\n    Parses CLI arguments and executes the selected operation.\n\n    This method merges the input from the command line with the\n    existing settings. It ensures that CLI arguments have the highest\n    priority. Then, it creates an instance of the chosen operation\n    and calls its 'run' method.\n    \"\"\"\n    args = self.parser.parse_args()\n    cli_data = {key: value for key, value in vars(args).items() if value is not None and key != \"command\"}\n\n    if hasattr(args, \"cls\"):\n        for key, value in cli_data.items():\n            if hasattr(self.settings, key):\n                setattr(self.settings, key, value)\n        operation = args.cls(settings=self.settings, **vars(args))\n        operation.run()\n    else:\n        self.parser.print_help()\n</code></pre>"},{"location":"api/dhash/","title":"DHash","text":"<p>               Bases: <code>BaseHasher</code></p> <p>Implementation of the dHash (Difference Hashing) algorithm.</p> <p>This class provides a specific strategy for image hashing. It calculates the hash by comparing the brightness (intensity) difference between adjacent pixels in a resized version of the image. It is very effective at identifying visual similarities while ignoring minor changes in color or compression.</p> Source code in <code>tools/comparer/img_comparer/hasher/dhash.py</code> <pre><code>class DHash(BaseHasher):\n    \"\"\"\n    Implementation of the dHash (Difference Hashing) algorithm.\n\n    This class provides a specific strategy for image hashing. It calculates\n    the hash by comparing the brightness (intensity) difference between\n    adjacent pixels in a resized version of the image. It is very effective\n    at identifying visual similarities while ignoring minor changes in\n    color or compression.\n    \"\"\"\n    @staticmethod\n    def compute_hash(image_path: Path, core_size: int) -&gt; Union[np.ndarray, None]:\n        \"\"\"\n        Calculates the dHash for a single image.\n\n        The process includes:\n        1. Loading the image in grayscale.\n        2. Resizing it to (core_size + 1, core_size) to allow horizontal\n           pixel comparison.\n        3. Generating a boolean mask where each bit represents whether the\n           left pixel is brighter than the right pixel.\n\n        Args:\n            image_path (Path): The file path to the image.\n            core_size (int): The resolution used for resizing. The resulting\n                hash length will be core_size squared (e.g., 8x8 = 64 bits).\n\n        Returns:\n            Union[np.ndarray, None]: A 1D NumPy array of boolean values\n                representing the hash, or None if the image file is\n                invalid or cannot be read.\n        \"\"\"\n        image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n\n        if image is None:\n            return None\n\n        resized_image = cv2.resize(image, (core_size + 1, core_size), interpolation=cv2.INTER_AREA)\n        gradient_difference = resized_image[:, 1:] &gt; resized_image[:, :-1]\n\n        return gradient_difference.flatten()\n</code></pre>"},{"location":"api/dhash/#tools.comparer.img_comparer.hasher.dhash.DHash.compute_hash","title":"<code>compute_hash(image_path, core_size)</code>  <code>staticmethod</code>","text":"<p>Calculates the dHash for a single image.</p> <p>The process includes: 1. Loading the image in grayscale. 2. Resizing it to (core_size + 1, core_size) to allow horizontal    pixel comparison. 3. Generating a boolean mask where each bit represents whether the    left pixel is brighter than the right pixel.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>Path</code> <p>The file path to the image.</p> required <code>core_size</code> <code>int</code> <p>The resolution used for resizing. The resulting hash length will be core_size squared (e.g., 8x8 = 64 bits).</p> required <p>Returns:</p> Type Description <code>Union[ndarray, None]</code> <p>Union[np.ndarray, None]: A 1D NumPy array of boolean values representing the hash, or None if the image file is invalid or cannot be read.</p> Source code in <code>tools/comparer/img_comparer/hasher/dhash.py</code> <pre><code>@staticmethod\ndef compute_hash(image_path: Path, core_size: int) -&gt; Union[np.ndarray, None]:\n    \"\"\"\n    Calculates the dHash for a single image.\n\n    The process includes:\n    1. Loading the image in grayscale.\n    2. Resizing it to (core_size + 1, core_size) to allow horizontal\n       pixel comparison.\n    3. Generating a boolean mask where each bit represents whether the\n       left pixel is brighter than the right pixel.\n\n    Args:\n        image_path (Path): The file path to the image.\n        core_size (int): The resolution used for resizing. The resulting\n            hash length will be core_size squared (e.g., 8x8 = 64 bits).\n\n    Returns:\n        Union[np.ndarray, None]: A 1D NumPy array of boolean values\n            representing the hash, or None if the image file is\n            invalid or cannot be read.\n    \"\"\"\n    image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n\n    if image is None:\n        return None\n\n    resized_image = cv2.resize(image, (core_size + 1, core_size), interpolation=cv2.INTER_AREA)\n    gradient_difference = resized_image[:, 1:] &gt; resized_image[:, :-1]\n\n    return gradient_difference.flatten()\n</code></pre>"},{"location":"api/feature_extractor/","title":"Feature extractor","text":"<p>Extracts geometric and spatial characteristics from raw annotation data.</p> <p>This class processes bounding box coordinates to calculate technical metrics such as relative area, aspect ratio, and spatial positioning. It identifies which part of the image an object occupies and detects if an object is cut off (truncated) at the image boundaries.</p> Source code in <code>tools/stats/extractor.py</code> <pre><code>class FeatureExtractor:\n    \"\"\"\n    Extracts geometric and spatial characteristics from raw annotation data.\n\n    This class processes bounding box coordinates to calculate technical\n    metrics such as relative area, aspect ratio, and spatial positioning.\n    It identifies which part of the image an object occupies and detects\n    if an object is cut off (truncated) at the image boundaries.\n    \"\"\"\n    @staticmethod\n    def extract_features(filepath: Union[Path, str], data: dict, margin_threshold: int = 5) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Calculates geometric and spatial features for all objects in an image.\n\n        The method divides the image into sectors based on the center point\n        to determine object orientation (e.g., top-left, center, bottom-side).\n\n        Args:\n            filepath (Union[Path, str]): Path to the annotation file, used as a unique ID.\n            data (dict): Dictionary containing image dimensions and object bounding boxes.\n            margin_threshold (int): Distance in pixels from the edge to consider\n                an object as 'truncated'. Defaults to 5.\n\n        Returns:\n            List[Dict[str, Any]]: A list of dictionaries, where each dictionary\n                contains features for a single object. Returns an empty list\n                if image dimensions are invalid (&lt;= 0).\n        \"\"\"\n        if not isinstance(filepath, str):\n            filepath = str(filepath)\n        try:\n            has_neighbors = 1\n            image_data = data.get(XMLNames.size, {})\n\n            im_width = int(image_data.get(XMLNames.width, 0))\n            im_height = int(image_data.get(XMLNames.height, 0))\n\n            if any([im_width &lt;= 0, im_height &lt;= 0]):\n                return []\n\n            im_depth = int(image_data.get(XMLNames.depth, 0))\n            im_area = im_width * im_height\n            img_center_x = im_width / 2\n            img_center_y = im_height / 2\n            annotated_objects = data.get(XMLNames.object, [])\n\n            if isinstance(annotated_objects, dict):\n                annotated_objects = [annotated_objects]\n                has_neighbors = 0\n\n            result = []\n            objects_count = len(annotated_objects)\n\n            for obj in annotated_objects:\n                bbox = obj.get(XMLNames.bndbox)\n\n                xmax = int(bbox.get(XMLNames.xmax, 0))\n                ymax = int(bbox.get(XMLNames.ymax, 0))\n                xmin = int(bbox.get(XMLNames.xmin, 0))\n                ymin = int(bbox.get(XMLNames.ymin, 0))\n\n                width = xmax - xmin\n                height = ymax - ymin\n                area = width * height\n                relative_area = area / im_area\n\n                # # if bbox corners in all four image quarters\n                # in_center = 1 if all([\n                #     xmin &lt;= img_center_x &lt;= xmax,\n                #     ymin &lt;= img_center_y &lt;= ymax\n                # ]) else 0\n                # # if object on im_center_y coord but has right offset\n                # in_right_side = 1 if all([\n                #     ymin &lt; img_center_y &lt; ymax,\n                #     xmin &gt; img_center_x\n                # ]) else 0\n                # # if object on im_center_y coord but has left offset\n                # in_left_side = 1 if all([\n                #     ymin &lt; img_center_y &lt; ymax,\n                #     xmax &lt; img_center_x\n                # ]) else 0\n                # # if object on im_center_x coord but has top offset\n                # in_top_side = 1 if all([\n                #     xmin &lt; img_center_x &lt; xmax,\n                #     ymax &lt; img_center_y\n                # ]) else 0\n                # # if object on im_center_x coord but has bottom offset\n                # in_bottom_side = 1 if all([\n                #     xmin &lt; img_center_x &lt; xmax,\n                #     ymin &gt; img_center_y\n                # ]) else 0\n                # # object absolutely in top left quarter\n                # in_left_top = 1 if all([\n                #     xmax &lt; img_center_x,\n                #     ymax &lt; img_center_y\n                # ]) else 0\n                # # object absolutely in top right quarter\n                # in_right_top = 1 if all([\n                #     xmin &gt; img_center_x,\n                #     ymax &gt; img_center_y\n                # ]) else 0\n                # # object absolutely in left bottom quarter\n                # in_left_bottom = 1 if all([\n                #     xmax &lt; img_center_x,\n                #     ymin &gt; img_center_y\n                # ]) else 0\n                # # object absolutely in right bottom quarter\n                # in_right_bottom = 1 if all([\n                #     xmin &gt; img_center_x,\n                #     ymin &gt; img_center_y\n                # ]) else 0\n\n                object_center_x = (xmin + xmax) / 2\n                object_center_y = (ymin + ymax) / 2\n\n                bin_w = im_width / 3\n                bin_h = im_height / 3\n\n                col_idx = int(object_center_x // bin_w)\n                row_idx = int(object_center_y // bin_h)\n\n                col_idx = min(col_idx, 2)\n                row_idx = min(row_idx, 2)\n\n                in_left_top = 1 if (row_idx == 0 and col_idx == 0) else 0\n                in_top_side = 1 if (row_idx == 0 and col_idx == 1) else 0\n                in_right_top = 1 if (row_idx == 0 and col_idx == 2) else 0\n\n                in_left_side = 1 if (row_idx == 1 and col_idx == 0) else 0\n                in_center = 1 if (row_idx == 1 and col_idx == 1) else 0\n                in_right_side = 1 if (row_idx == 1 and col_idx == 2) else 0\n\n                in_left_bottom = 1 if (row_idx == 2 and col_idx == 0) else 0\n                in_bottom_side = 1 if (row_idx == 2 and col_idx == 1) else 0\n                in_right_bottom = 1 if (row_idx == 2 and col_idx == 2) else 0\n\n                truncated_left = 1 if xmin &lt; margin_threshold else 0\n                truncated_right = 1 if xmax &gt; (im_width - margin_threshold) else 0\n                truncated_top = 1 if ymin &lt; margin_threshold else 0\n                truncated_bottom = 1 if ymax &gt; (im_height - margin_threshold) else 0\n\n                full_size = 1 if all([\n                    truncated_left,\n                    truncated_right,\n                    truncated_top,\n                    truncated_bottom]) else 0\n\n                object_data = {\n                    ImageStatsKeys.path: filepath,\n                    ImageStatsKeys.class_name: obj.get(XMLNames.name, \"unfilled\"),\n                    ImageStatsKeys.objects_count: objects_count,\n                    ImageStatsKeys.im_width: im_width,\n                    ImageStatsKeys.im_height: im_height,\n                    ImageStatsKeys.im_depth: im_depth,\n                    ImageStatsKeys.has_neighbors: has_neighbors,\n                    ImageStatsKeys.object_width: width,\n                    ImageStatsKeys.object_height: height,\n                    ImageStatsKeys.object_aspect_ratio: width / height if height &gt; 0 else 0,\n                    ImageStatsKeys.object_area: area,\n                    ImageStatsKeys.object_relative_area: relative_area,\n                    ImageStatsKeys.object_in_center: in_center,\n                    ImageStatsKeys.object_in_right_side: in_right_side,\n                    ImageStatsKeys.object_in_left_side: in_left_side,\n                    ImageStatsKeys.object_in_top_side: in_top_side,\n                    ImageStatsKeys.object_in_bottom_side: in_bottom_side,\n                    ImageStatsKeys.object_in_left_top: in_left_top,\n                    ImageStatsKeys.object_in_right_top: in_right_top,\n                    ImageStatsKeys.object_in_left_bottom: in_left_bottom,\n                    ImageStatsKeys.object_in_right_bottom: in_right_bottom,\n                    ImageStatsKeys.full_size: full_size,\n                    ImageStatsKeys.truncated_left: truncated_left,\n                    ImageStatsKeys.truncated_right: truncated_right,\n                    ImageStatsKeys.truncated_top: truncated_top,\n                    ImageStatsKeys.truncated_bottom: truncated_bottom\n                }\n\n                result.append(object_data)\n        except ZeroDivisionError:\n            return []\n        return result\n</code></pre>"},{"location":"api/feature_extractor/#tools.stats.extractor.FeatureExtractor.extract_features","title":"<code>extract_features(filepath, data, margin_threshold=5)</code>  <code>staticmethod</code>","text":"<p>Calculates geometric and spatial features for all objects in an image.</p> <p>The method divides the image into sectors based on the center point to determine object orientation (e.g., top-left, center, bottom-side).</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[Path, str]</code> <p>Path to the annotation file, used as a unique ID.</p> required <code>data</code> <code>dict</code> <p>Dictionary containing image dimensions and object bounding boxes.</p> required <code>margin_threshold</code> <code>int</code> <p>Distance in pixels from the edge to consider an object as 'truncated'. Defaults to 5.</p> <code>5</code> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: A list of dictionaries, where each dictionary contains features for a single object. Returns an empty list if image dimensions are invalid (&lt;= 0).</p> Source code in <code>tools/stats/extractor.py</code> <pre><code>@staticmethod\ndef extract_features(filepath: Union[Path, str], data: dict, margin_threshold: int = 5) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Calculates geometric and spatial features for all objects in an image.\n\n    The method divides the image into sectors based on the center point\n    to determine object orientation (e.g., top-left, center, bottom-side).\n\n    Args:\n        filepath (Union[Path, str]): Path to the annotation file, used as a unique ID.\n        data (dict): Dictionary containing image dimensions and object bounding boxes.\n        margin_threshold (int): Distance in pixels from the edge to consider\n            an object as 'truncated'. Defaults to 5.\n\n    Returns:\n        List[Dict[str, Any]]: A list of dictionaries, where each dictionary\n            contains features for a single object. Returns an empty list\n            if image dimensions are invalid (&lt;= 0).\n    \"\"\"\n    if not isinstance(filepath, str):\n        filepath = str(filepath)\n    try:\n        has_neighbors = 1\n        image_data = data.get(XMLNames.size, {})\n\n        im_width = int(image_data.get(XMLNames.width, 0))\n        im_height = int(image_data.get(XMLNames.height, 0))\n\n        if any([im_width &lt;= 0, im_height &lt;= 0]):\n            return []\n\n        im_depth = int(image_data.get(XMLNames.depth, 0))\n        im_area = im_width * im_height\n        img_center_x = im_width / 2\n        img_center_y = im_height / 2\n        annotated_objects = data.get(XMLNames.object, [])\n\n        if isinstance(annotated_objects, dict):\n            annotated_objects = [annotated_objects]\n            has_neighbors = 0\n\n        result = []\n        objects_count = len(annotated_objects)\n\n        for obj in annotated_objects:\n            bbox = obj.get(XMLNames.bndbox)\n\n            xmax = int(bbox.get(XMLNames.xmax, 0))\n            ymax = int(bbox.get(XMLNames.ymax, 0))\n            xmin = int(bbox.get(XMLNames.xmin, 0))\n            ymin = int(bbox.get(XMLNames.ymin, 0))\n\n            width = xmax - xmin\n            height = ymax - ymin\n            area = width * height\n            relative_area = area / im_area\n\n            # # if bbox corners in all four image quarters\n            # in_center = 1 if all([\n            #     xmin &lt;= img_center_x &lt;= xmax,\n            #     ymin &lt;= img_center_y &lt;= ymax\n            # ]) else 0\n            # # if object on im_center_y coord but has right offset\n            # in_right_side = 1 if all([\n            #     ymin &lt; img_center_y &lt; ymax,\n            #     xmin &gt; img_center_x\n            # ]) else 0\n            # # if object on im_center_y coord but has left offset\n            # in_left_side = 1 if all([\n            #     ymin &lt; img_center_y &lt; ymax,\n            #     xmax &lt; img_center_x\n            # ]) else 0\n            # # if object on im_center_x coord but has top offset\n            # in_top_side = 1 if all([\n            #     xmin &lt; img_center_x &lt; xmax,\n            #     ymax &lt; img_center_y\n            # ]) else 0\n            # # if object on im_center_x coord but has bottom offset\n            # in_bottom_side = 1 if all([\n            #     xmin &lt; img_center_x &lt; xmax,\n            #     ymin &gt; img_center_y\n            # ]) else 0\n            # # object absolutely in top left quarter\n            # in_left_top = 1 if all([\n            #     xmax &lt; img_center_x,\n            #     ymax &lt; img_center_y\n            # ]) else 0\n            # # object absolutely in top right quarter\n            # in_right_top = 1 if all([\n            #     xmin &gt; img_center_x,\n            #     ymax &gt; img_center_y\n            # ]) else 0\n            # # object absolutely in left bottom quarter\n            # in_left_bottom = 1 if all([\n            #     xmax &lt; img_center_x,\n            #     ymin &gt; img_center_y\n            # ]) else 0\n            # # object absolutely in right bottom quarter\n            # in_right_bottom = 1 if all([\n            #     xmin &gt; img_center_x,\n            #     ymin &gt; img_center_y\n            # ]) else 0\n\n            object_center_x = (xmin + xmax) / 2\n            object_center_y = (ymin + ymax) / 2\n\n            bin_w = im_width / 3\n            bin_h = im_height / 3\n\n            col_idx = int(object_center_x // bin_w)\n            row_idx = int(object_center_y // bin_h)\n\n            col_idx = min(col_idx, 2)\n            row_idx = min(row_idx, 2)\n\n            in_left_top = 1 if (row_idx == 0 and col_idx == 0) else 0\n            in_top_side = 1 if (row_idx == 0 and col_idx == 1) else 0\n            in_right_top = 1 if (row_idx == 0 and col_idx == 2) else 0\n\n            in_left_side = 1 if (row_idx == 1 and col_idx == 0) else 0\n            in_center = 1 if (row_idx == 1 and col_idx == 1) else 0\n            in_right_side = 1 if (row_idx == 1 and col_idx == 2) else 0\n\n            in_left_bottom = 1 if (row_idx == 2 and col_idx == 0) else 0\n            in_bottom_side = 1 if (row_idx == 2 and col_idx == 1) else 0\n            in_right_bottom = 1 if (row_idx == 2 and col_idx == 2) else 0\n\n            truncated_left = 1 if xmin &lt; margin_threshold else 0\n            truncated_right = 1 if xmax &gt; (im_width - margin_threshold) else 0\n            truncated_top = 1 if ymin &lt; margin_threshold else 0\n            truncated_bottom = 1 if ymax &gt; (im_height - margin_threshold) else 0\n\n            full_size = 1 if all([\n                truncated_left,\n                truncated_right,\n                truncated_top,\n                truncated_bottom]) else 0\n\n            object_data = {\n                ImageStatsKeys.path: filepath,\n                ImageStatsKeys.class_name: obj.get(XMLNames.name, \"unfilled\"),\n                ImageStatsKeys.objects_count: objects_count,\n                ImageStatsKeys.im_width: im_width,\n                ImageStatsKeys.im_height: im_height,\n                ImageStatsKeys.im_depth: im_depth,\n                ImageStatsKeys.has_neighbors: has_neighbors,\n                ImageStatsKeys.object_width: width,\n                ImageStatsKeys.object_height: height,\n                ImageStatsKeys.object_aspect_ratio: width / height if height &gt; 0 else 0,\n                ImageStatsKeys.object_area: area,\n                ImageStatsKeys.object_relative_area: relative_area,\n                ImageStatsKeys.object_in_center: in_center,\n                ImageStatsKeys.object_in_right_side: in_right_side,\n                ImageStatsKeys.object_in_left_side: in_left_side,\n                ImageStatsKeys.object_in_top_side: in_top_side,\n                ImageStatsKeys.object_in_bottom_side: in_bottom_side,\n                ImageStatsKeys.object_in_left_top: in_left_top,\n                ImageStatsKeys.object_in_right_top: in_right_top,\n                ImageStatsKeys.object_in_left_bottom: in_left_bottom,\n                ImageStatsKeys.object_in_right_bottom: in_right_bottom,\n                ImageStatsKeys.full_size: full_size,\n                ImageStatsKeys.truncated_left: truncated_left,\n                ImageStatsKeys.truncated_right: truncated_right,\n                ImageStatsKeys.truncated_top: truncated_top,\n                ImageStatsKeys.truncated_bottom: truncated_bottom\n            }\n\n            result.append(object_data)\n    except ZeroDivisionError:\n        return []\n    return result\n</code></pre>"},{"location":"api/file_remover/","title":"FileRemoverMixin","text":"<p>A helper class to delete files from the system.</p> Source code in <code>tools/mixins/file_remover.py</code> <pre><code>class FileRemoverMixin:\n    \"\"\"A helper class to delete files from the system.\"\"\"\n    def remove_all(self, filepaths: Union[List[Path], Tuple[Path], Path]) -&gt; None:\n        \"\"\"Deletes all the files in the given iterable or path.\n\n        Args:\n            filepaths (Union[List[Path], Tuple[Path], Path]): A list of paths,\n                a tuple of paths, or a single path to delete.\n\n        Raises:\n            TypeError: If the input is not a list, tuple, or Path.\n        \"\"\"\n        if isinstance(filepaths, (list, tuple)):\n            for path in filepaths:\n                self.remove_file(path)\n\n        elif isinstance(filepaths, Path):\n            self.remove_file(filepaths)\n\n        else:\n            raise TypeError(f'filepaths should be a list or a tuple or a Path, not {type(filepaths)}')\n\n\n    def remove_file(self: LoggerProtocol, path: Path) -&gt; bool:\n        \"\"\"Deletes one file from the system.\n\n        Args:\n            path (Path): The path of the file to delete.\n\n        Returns:\n            bool: True if the file was deleted successfully, False otherwise.\n        \"\"\"\n        if not path.is_file():\n            self.logger.warning(f\"{path} is not a file\")\n        try:\n            path.unlink(missing_ok=True)\n            self.logger.info(f\"{path} removed\")\n            return True\n        except FileNotFoundError:\n            self.logger.warning(f\"{path} file not exists, skipping\")\n            return False\n</code></pre>"},{"location":"api/file_remover/#tools.mixins.file_remover.FileRemoverMixin.remove_all","title":"<code>remove_all(filepaths)</code>","text":"<p>Deletes all the files in the given iterable or path.</p> <p>Parameters:</p> Name Type Description Default <code>filepaths</code> <code>Union[List[Path], Tuple[Path], Path]</code> <p>A list of paths, a tuple of paths, or a single path to delete.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If the input is not a list, tuple, or Path.</p> Source code in <code>tools/mixins/file_remover.py</code> <pre><code>def remove_all(self, filepaths: Union[List[Path], Tuple[Path], Path]) -&gt; None:\n    \"\"\"Deletes all the files in the given iterable or path.\n\n    Args:\n        filepaths (Union[List[Path], Tuple[Path], Path]): A list of paths,\n            a tuple of paths, or a single path to delete.\n\n    Raises:\n        TypeError: If the input is not a list, tuple, or Path.\n    \"\"\"\n    if isinstance(filepaths, (list, tuple)):\n        for path in filepaths:\n            self.remove_file(path)\n\n    elif isinstance(filepaths, Path):\n        self.remove_file(filepaths)\n\n    else:\n        raise TypeError(f'filepaths should be a list or a tuple or a Path, not {type(filepaths)}')\n</code></pre>"},{"location":"api/file_remover/#tools.mixins.file_remover.FileRemoverMixin.remove_file","title":"<code>remove_file(path)</code>","text":"<p>Deletes one file from the system.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path of the file to delete.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the file was deleted successfully, False otherwise.</p> Source code in <code>tools/mixins/file_remover.py</code> <pre><code>def remove_file(self: LoggerProtocol, path: Path) -&gt; bool:\n    \"\"\"Deletes one file from the system.\n\n    Args:\n        path (Path): The path of the file to delete.\n\n    Returns:\n        bool: True if the file was deleted successfully, False otherwise.\n    \"\"\"\n    if not path.is_file():\n        self.logger.warning(f\"{path} is not a file\")\n    try:\n        path.unlink(missing_ok=True)\n        self.logger.info(f\"{path} removed\")\n        return True\n    except FileNotFoundError:\n        self.logger.warning(f\"{path} file not exists, skipping\")\n        return False\n</code></pre>"},{"location":"api/image_analyzer/","title":"Image Analyzer","text":"<p>Provides utility methods to analyze image quality and pixel data.</p> <p>This class extracts physical metrics from images, such as brightness, contrast, and sharpness (blur score), which are essential for understanding the quality of a computer vision dataset.</p> Source code in <code>tools/stats/image_analyzer.py</code> <pre><code>class ImageContentAnalyzer:\n    \"\"\"\n    Provides utility methods to analyze image quality and pixel data.\n\n    This class extracts physical metrics from images, such as brightness,\n    contrast, and sharpness (blur score), which are essential for\n    understanding the quality of a computer vision dataset.\n    \"\"\"\n\n    @staticmethod\n    def analyze_metrics(img_path: str) -&gt; Dict[str, float]:\n        \"\"\"\n        Calculates brightness, contrast, and blur score for an image file.\n\n        The method performs the following steps:\n        1. Reads the image from the disk in BGR format.\n        2. Converts the image to grayscale.\n        3. Computes the mean (brightness), standard deviation (contrast),\n           and Laplacian variance (blur score).\n\n        Args:\n            img_path (Path): The file system path to the image.\n\n        Returns:\n            Dict[str, float]: A dictionary containing calculated metrics.\n                Returns an empty dictionary if the image cannot be read.\n        \"\"\"\n        try:\n            image = cv2.imread(str(img_path))\n        except Exception:\n            return {}\n\n        if image is None:\n            return {}\n\n        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n        data = {\n            ImageStatsKeys.im_brightness: round(float(np.mean(image_gray)), 2),\n            ImageStatsKeys.im_contrast: round(float(np.std(image_gray)), 2),\n            ImageStatsKeys.im_blur_score: round(float(cv2.Laplacian(image_gray, cv2.CV_64F).var()), 2)\n        }\n        return data\n</code></pre>"},{"location":"api/image_analyzer/#tools.stats.image_analyzer.ImageContentAnalyzer.analyze_metrics","title":"<code>analyze_metrics(img_path)</code>  <code>staticmethod</code>","text":"<p>Calculates brightness, contrast, and blur score for an image file.</p> <p>The method performs the following steps: 1. Reads the image from the disk in BGR format. 2. Converts the image to grayscale. 3. Computes the mean (brightness), standard deviation (contrast),    and Laplacian variance (blur score).</p> <p>Parameters:</p> Name Type Description Default <code>img_path</code> <code>Path</code> <p>The file system path to the image.</p> required <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>Dict[str, float]: A dictionary containing calculated metrics. Returns an empty dictionary if the image cannot be read.</p> Source code in <code>tools/stats/image_analyzer.py</code> <pre><code>@staticmethod\ndef analyze_metrics(img_path: str) -&gt; Dict[str, float]:\n    \"\"\"\n    Calculates brightness, contrast, and blur score for an image file.\n\n    The method performs the following steps:\n    1. Reads the image from the disk in BGR format.\n    2. Converts the image to grayscale.\n    3. Computes the mean (brightness), standard deviation (contrast),\n       and Laplacian variance (blur score).\n\n    Args:\n        img_path (Path): The file system path to the image.\n\n    Returns:\n        Dict[str, float]: A dictionary containing calculated metrics.\n            Returns an empty dictionary if the image cannot be read.\n    \"\"\"\n    try:\n        image = cv2.imread(str(img_path))\n    except Exception:\n        return {}\n\n    if image is None:\n        return {}\n\n    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    data = {\n        ImageStatsKeys.im_brightness: round(float(np.mean(image_gray)), 2),\n        ImageStatsKeys.im_contrast: round(float(np.std(image_gray)), 2),\n        ImageStatsKeys.im_blur_score: round(float(cv2.Laplacian(image_gray, cv2.CV_64F).var()), 2)\n    }\n    return data\n</code></pre>"},{"location":"api/image_reporter/","title":"Image Dataset Reporter","text":"<p>               Bases: <code>BaseDatasetReporter</code></p> <p>Implementation of BaseDatasetReporter for Computer Vision datasets.</p> <p>This class orchestrates the complete reporting pipeline. It aggregates geometric and pixel-level features to generate structured console logs, spatial heatmaps, correlation matrices, and UMAP manifold projections.</p> Source code in <code>tools/stats/dataset_reporter/image_reporter.py</code> <pre><code>class ImageDatasetReporter(BaseDatasetReporter):\n    \"\"\"\n    Implementation of BaseDatasetReporter for Computer Vision datasets.\n\n    This class orchestrates the complete reporting pipeline. It aggregates\n    geometric and pixel-level features to generate structured console logs,\n    spatial heatmaps, correlation matrices, and UMAP manifold projections.\n    \"\"\"\n    def generate_visual_report(\n            self,\n            df: pd.DataFrame,\n            features: List[str],\n            destination: Union[Path, PdfPages]\n    ):\n        \"\"\"\n        Orchestrates the visual analytics pipeline to create technical plots.\n\n        The pipeline includes:\n            1. Class distribution bar charts.\n            2. Geometric analysis (Area boxplots and Aspect Ratio violin plots).\n            3. Dataset Bias Matrix (Correlation between classes and features).\n            4. Per-class Spatial Density heatmaps (3x3 grid).\n            5. Per-class internal feature correlation matrices.\n            6. Global UMAP manifold projection.\n\n        Args:\n            df (pd.DataFrame): The extracted feature matrix.\n            features (List[str]): List of numeric columns for correlation and manifold analysis.\n            destination (Union[Path, PdfPages]): Output target (directory or PDF document).\n        \"\"\"\n        self.logger.info(\"Starting visual analytics pipeline...\")\n        class_col = ImageStatsKeys.class_name\n\n        # class distribution\n        StatsPlotter.plot_class_distribution(df, destination)\n\n        # boxplots for geometric features\n        StatsPlotter.plot_geometry_analysis(df, destination)\n\n        # correlation bias between classes and features\n        class_dummies = pd.get_dummies(df[class_col], prefix='class').astype(int)\n        df_combined = pd.concat([df[features], class_dummies], axis=1)\n        full_corr = df_combined.corr()\n\n        class_cols = [c for c in full_corr.columns if c.startswith('class_')]\n        bias_matrix = full_corr.loc[class_cols, features]\n\n        StatsPlotter.plot_correlation_matrix(\n            bias_matrix, \"Dataset Bias: Classes vs Features\",\n            destination, \"corr_bias.png\", annot_size=7\n        )\n\n        # heatpaps for spatial distribution of objects\n        all_class_corrs = df.groupby(class_col)[features].corr()\n\n        for name in sorted(df[class_col].unique()):\n            class_df = df[df[ImageStatsKeys.class_name] == name]\n\n            # \u0422\u0435\u043f\u043b\u043e\u043a\u0430\u0440\u0442\u0430 3\u04453\n            grid = [\n                [class_df['object_in_left_top'].sum(), class_df['object_in_top_side'].sum(),\n                 class_df['object_in_right_top'].sum()],\n                [class_df['object_in_left_side'].sum(), class_df['object_in_center'].sum(),\n                 class_df['object_in_right_side'].sum()],\n                [class_df['object_in_left_bottom'].sum(), class_df['object_in_bottom_side'].sum(),\n                 class_df['object_in_right_bottom'].sum()]\n            ]\n            StatsPlotter.plot_spatial_heatmap(grid, f\"Spatial Density: {name.upper()}\", destination, f\"heat_{name}.png\")\n\n            # \u0412\u043d\u0443\u0442\u0440\u0456\u0448\u043d\u044f \u043a\u043e\u0440\u0435\u043b\u044f\u0446\u0456\u044f \u0444\u0456\u0447\n            c_matrix = all_class_corrs.loc[name].dropna(how='all', axis=0).dropna(how='all', axis=1)\n            if c_matrix.shape[0] &gt;= 2:\n                StatsPlotter.plot_correlation_matrix(c_matrix, f\"Feature Correlation | {name}\", destination,\n                                                     f\"corr_{name}.png\")\n\n        # UMAP manifold projection\n        StatsPlotter.plot_dataset_manifold(df=df, class_col=class_col, destination=destination)\n\n    def show_console_report(self, df: pd.DataFrame, target_format: str) -&gt; None:\n        \"\"\"\n        Aggregates dataset statistics and prints a structured technical summary.\n\n        Provides insights into object density, image quality metrics, and\n        detailed per-class geometry and spatial bias.\n\n        Args:\n            df (pd.DataFrame): The extracted feature matrix.\n            target_format (str): The annotation format (e.g., 'yolo', 'voc').\n        \"\"\"\n        total_objects = len(df)\n        total_annotations = df[ImageStatsKeys.im_path].nunique()\n        objects_per_image = df.groupby(ImageStatsKeys.im_path).size()\n        average_density = objects_per_image.mean()\n        std_density = objects_per_image.std()\n\n        report_rows = [\n            \"\\n\" + self.line,\n            f\"DATASET REPORT FOR {target_format.upper()}\",\n            self.line,\n            f\"Total images             :  {total_annotations}\",\n            f\"Total annotated objects  :  {total_objects}\",\n            f\"Objects per image (avg)  :  {average_density:.2f}\",\n            f\"Density deviation (std)  :  {std_density:.2f}\"\n        ]\n\n        for section in self.settings.img_dataset_report_schema:\n            if \"IMAGE QUALITY\" in section[\"title\"]:\n                report_rows.extend(self._render_section(df, section, total_objects))\n\n        for object_name in sorted(df['class_name'].unique()):\n            cls_df = df[df['class_name'] == object_name]\n            cls_count = len(cls_df)\n\n            report_rows.append(f\"\\n &gt;&gt;&gt; CLASS: {object_name} ({(cls_count / total_objects) * 100:.1f}%)\")\n\n            for section in self.settings.img_dataset_report_schema:\n                report_rows.extend(self._render_section(cls_df, section, cls_count))\n\n            report_rows.append(self.line + \"\\n\")\n        self.logger.info(\"\\n\".join(report_rows))\n</code></pre>"},{"location":"api/image_reporter/#tools.stats.dataset_reporter.image_reporter.ImageDatasetReporter.generate_visual_report","title":"<code>generate_visual_report(df, features, destination)</code>","text":"<p>Orchestrates the visual analytics pipeline to create technical plots.</p> The pipeline includes <ol> <li>Class distribution bar charts.</li> <li>Geometric analysis (Area boxplots and Aspect Ratio violin plots).</li> <li>Dataset Bias Matrix (Correlation between classes and features).</li> <li>Per-class Spatial Density heatmaps (3x3 grid).</li> <li>Per-class internal feature correlation matrices.</li> <li>Global UMAP manifold projection.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The extracted feature matrix.</p> required <code>features</code> <code>List[str]</code> <p>List of numeric columns for correlation and manifold analysis.</p> required <code>destination</code> <code>Union[Path, PdfPages]</code> <p>Output target (directory or PDF document).</p> required Source code in <code>tools/stats/dataset_reporter/image_reporter.py</code> <pre><code>def generate_visual_report(\n        self,\n        df: pd.DataFrame,\n        features: List[str],\n        destination: Union[Path, PdfPages]\n):\n    \"\"\"\n    Orchestrates the visual analytics pipeline to create technical plots.\n\n    The pipeline includes:\n        1. Class distribution bar charts.\n        2. Geometric analysis (Area boxplots and Aspect Ratio violin plots).\n        3. Dataset Bias Matrix (Correlation between classes and features).\n        4. Per-class Spatial Density heatmaps (3x3 grid).\n        5. Per-class internal feature correlation matrices.\n        6. Global UMAP manifold projection.\n\n    Args:\n        df (pd.DataFrame): The extracted feature matrix.\n        features (List[str]): List of numeric columns for correlation and manifold analysis.\n        destination (Union[Path, PdfPages]): Output target (directory or PDF document).\n    \"\"\"\n    self.logger.info(\"Starting visual analytics pipeline...\")\n    class_col = ImageStatsKeys.class_name\n\n    # class distribution\n    StatsPlotter.plot_class_distribution(df, destination)\n\n    # boxplots for geometric features\n    StatsPlotter.plot_geometry_analysis(df, destination)\n\n    # correlation bias between classes and features\n    class_dummies = pd.get_dummies(df[class_col], prefix='class').astype(int)\n    df_combined = pd.concat([df[features], class_dummies], axis=1)\n    full_corr = df_combined.corr()\n\n    class_cols = [c for c in full_corr.columns if c.startswith('class_')]\n    bias_matrix = full_corr.loc[class_cols, features]\n\n    StatsPlotter.plot_correlation_matrix(\n        bias_matrix, \"Dataset Bias: Classes vs Features\",\n        destination, \"corr_bias.png\", annot_size=7\n    )\n\n    # heatpaps for spatial distribution of objects\n    all_class_corrs = df.groupby(class_col)[features].corr()\n\n    for name in sorted(df[class_col].unique()):\n        class_df = df[df[ImageStatsKeys.class_name] == name]\n\n        # \u0422\u0435\u043f\u043b\u043e\u043a\u0430\u0440\u0442\u0430 3\u04453\n        grid = [\n            [class_df['object_in_left_top'].sum(), class_df['object_in_top_side'].sum(),\n             class_df['object_in_right_top'].sum()],\n            [class_df['object_in_left_side'].sum(), class_df['object_in_center'].sum(),\n             class_df['object_in_right_side'].sum()],\n            [class_df['object_in_left_bottom'].sum(), class_df['object_in_bottom_side'].sum(),\n             class_df['object_in_right_bottom'].sum()]\n        ]\n        StatsPlotter.plot_spatial_heatmap(grid, f\"Spatial Density: {name.upper()}\", destination, f\"heat_{name}.png\")\n\n        # \u0412\u043d\u0443\u0442\u0440\u0456\u0448\u043d\u044f \u043a\u043e\u0440\u0435\u043b\u044f\u0446\u0456\u044f \u0444\u0456\u0447\n        c_matrix = all_class_corrs.loc[name].dropna(how='all', axis=0).dropna(how='all', axis=1)\n        if c_matrix.shape[0] &gt;= 2:\n            StatsPlotter.plot_correlation_matrix(c_matrix, f\"Feature Correlation | {name}\", destination,\n                                                 f\"corr_{name}.png\")\n\n    # UMAP manifold projection\n    StatsPlotter.plot_dataset_manifold(df=df, class_col=class_col, destination=destination)\n</code></pre>"},{"location":"api/image_reporter/#tools.stats.dataset_reporter.image_reporter.ImageDatasetReporter.show_console_report","title":"<code>show_console_report(df, target_format)</code>","text":"<p>Aggregates dataset statistics and prints a structured technical summary.</p> <p>Provides insights into object density, image quality metrics, and detailed per-class geometry and spatial bias.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The extracted feature matrix.</p> required <code>target_format</code> <code>str</code> <p>The annotation format (e.g., 'yolo', 'voc').</p> required Source code in <code>tools/stats/dataset_reporter/image_reporter.py</code> <pre><code>def show_console_report(self, df: pd.DataFrame, target_format: str) -&gt; None:\n    \"\"\"\n    Aggregates dataset statistics and prints a structured technical summary.\n\n    Provides insights into object density, image quality metrics, and\n    detailed per-class geometry and spatial bias.\n\n    Args:\n        df (pd.DataFrame): The extracted feature matrix.\n        target_format (str): The annotation format (e.g., 'yolo', 'voc').\n    \"\"\"\n    total_objects = len(df)\n    total_annotations = df[ImageStatsKeys.im_path].nunique()\n    objects_per_image = df.groupby(ImageStatsKeys.im_path).size()\n    average_density = objects_per_image.mean()\n    std_density = objects_per_image.std()\n\n    report_rows = [\n        \"\\n\" + self.line,\n        f\"DATASET REPORT FOR {target_format.upper()}\",\n        self.line,\n        f\"Total images             :  {total_annotations}\",\n        f\"Total annotated objects  :  {total_objects}\",\n        f\"Objects per image (avg)  :  {average_density:.2f}\",\n        f\"Density deviation (std)  :  {std_density:.2f}\"\n    ]\n\n    for section in self.settings.img_dataset_report_schema:\n        if \"IMAGE QUALITY\" in section[\"title\"]:\n            report_rows.extend(self._render_section(df, section, total_objects))\n\n    for object_name in sorted(df['class_name'].unique()):\n        cls_df = df[df['class_name'] == object_name]\n        cls_count = len(cls_df)\n\n        report_rows.append(f\"\\n &gt;&gt;&gt; CLASS: {object_name} ({(cls_count / total_objects) * 100:.1f}%)\")\n\n        for section in self.settings.img_dataset_report_schema:\n            report_rows.extend(self._render_section(cls_df, section, cls_count))\n\n        report_rows.append(self.line + \"\\n\")\n    self.logger.info(\"\\n\".join(report_rows))\n</code></pre>"},{"location":"api/img_comparer/","title":"Image Comparer","text":"<p>An orchestrator for comparing images using different hashing algorithms.</p> <p>This class acts as a manager that selects a specific hashing strategy (like dHash) based on the project settings. It coordinates the process of generating hashes and identifying duplicate files.</p> <p>Attributes:</p> Name Type Description <code>settings</code> <code>AppSettings</code> <p>Global configuration object containing hashing parameters and paths.</p> <code>method_mapping</code> <code>Dict</code> <p>A map that links algorithm names to their corresponding classes.</p> <code>method</code> <code>BaseHasher</code> <p>An instance of the selected hashing algorithm.</p> <code>logger</code> <code>Logger</code> <p>Logger instance for tracking comparison tasks.</p> Source code in <code>tools/comparer/img_comparer/img_comparer.py</code> <pre><code>class ImageComparer:\n    \"\"\"\n    An orchestrator for comparing images using different hashing algorithms.\n\n    This class acts as a manager that selects a specific hashing strategy\n    (like dHash) based on the project settings. It coordinates the process\n    of generating hashes and identifying duplicate files.\n\n    Attributes:\n        settings (AppSettings): Global configuration object containing\n            hashing parameters and paths.\n        method_mapping (Dict): A map that links algorithm names to their\n            corresponding classes.\n        method (BaseHasher): An instance of the selected hashing algorithm.\n        logger (logging.Logger): Logger instance for tracking comparison tasks.\n    \"\"\"\n    def __init__(self, settings: AppSettings):\n        \"\"\"\n        Initializes the ImageComparer with settings and sets up the algorithm.\n\n        Args:\n            settings (AppSettings): Global configuration object that includes\n                default and user-defined parameters.\n        \"\"\"\n        super().__init__()\n        self.settings = settings\n\n        self.method_mapping = {\n            Constants.dhash: DHash,\n        }\n\n        self.method = self.method_mapping[self.settings.method](\n            settings=self.settings,\n        )\n\n        self.logger = LoggerConfigurator.setup(\n            name=self.__class__.__name__,\n            log_path=Path(self.settings.log_path) / f\"{self.__class__.__name__}.log\" if self.settings.log_path else None,\n            log_level=self.settings.log_level\n        )\n\n\n    def compare(self, file_paths: Tuple[Path]) -&gt; List[Path]:\n        \"\"\"\n        Compares files using the each-with-each principle to find duplicates.\n\n        The process consists of two steps:\n        1. Building a hash map for all provided files.\n        2. Analyzing the hash map to find matches that satisfy the\n           Hamming distance threshold.\n\n        Args:\n            file_paths (Tuple[Path]): A collection of paths to the image files\n                to be compared.\n\n        Returns:\n            List[Path]: A list of file paths that are identified as duplicates.\n        \"\"\"\n        hash_map = self.method.get_hashmap(file_paths)\n        matches = self.method.find_duplicates(hash_map)\n        return matches\n</code></pre>"},{"location":"api/img_comparer/#tools.comparer.img_comparer.img_comparer.ImageComparer.__init__","title":"<code>__init__(settings)</code>","text":"<p>Initializes the ImageComparer with settings and sets up the algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>Global configuration object that includes default and user-defined parameters.</p> required Source code in <code>tools/comparer/img_comparer/img_comparer.py</code> <pre><code>def __init__(self, settings: AppSettings):\n    \"\"\"\n    Initializes the ImageComparer with settings and sets up the algorithm.\n\n    Args:\n        settings (AppSettings): Global configuration object that includes\n            default and user-defined parameters.\n    \"\"\"\n    super().__init__()\n    self.settings = settings\n\n    self.method_mapping = {\n        Constants.dhash: DHash,\n    }\n\n    self.method = self.method_mapping[self.settings.method](\n        settings=self.settings,\n    )\n\n    self.logger = LoggerConfigurator.setup(\n        name=self.__class__.__name__,\n        log_path=Path(self.settings.log_path) / f\"{self.__class__.__name__}.log\" if self.settings.log_path else None,\n        log_level=self.settings.log_level\n    )\n</code></pre>"},{"location":"api/img_comparer/#tools.comparer.img_comparer.img_comparer.ImageComparer.compare","title":"<code>compare(file_paths)</code>","text":"<p>Compares files using the each-with-each principle to find duplicates.</p> <p>The process consists of two steps: 1. Building a hash map for all provided files. 2. Analyzing the hash map to find matches that satisfy the    Hamming distance threshold.</p> <p>Parameters:</p> Name Type Description Default <code>file_paths</code> <code>Tuple[Path]</code> <p>A collection of paths to the image files to be compared.</p> required <p>Returns:</p> Type Description <code>List[Path]</code> <p>List[Path]: A list of file paths that are identified as duplicates.</p> Source code in <code>tools/comparer/img_comparer/img_comparer.py</code> <pre><code>def compare(self, file_paths: Tuple[Path]) -&gt; List[Path]:\n    \"\"\"\n    Compares files using the each-with-each principle to find duplicates.\n\n    The process consists of two steps:\n    1. Building a hash map for all provided files.\n    2. Analyzing the hash map to find matches that satisfy the\n       Hamming distance threshold.\n\n    Args:\n        file_paths (Tuple[Path]): A collection of paths to the image files\n            to be compared.\n\n    Returns:\n        List[Path]: A list of file paths that are identified as duplicates.\n    \"\"\"\n    hash_map = self.method.get_hashmap(file_paths)\n    matches = self.method.find_duplicates(hash_map)\n    return matches\n</code></pre>"},{"location":"api/outlier_detector/","title":"Outlier Detector","text":"<p>Service for statistical anomaly detection in datasets.</p> <p>This class provides methods to identify outliers using the 3-sigma rule (Standard Deviation). It can process features globally or per-class to ensure high accuracy in diverse datasets.</p> Source code in <code>services/outlier_detector.py</code> <pre><code>class OutlierDetector:\n    \"\"\"\n    Service for statistical anomaly detection in datasets.\n\n    This class provides methods to identify outliers using the 3-sigma rule\n    (Standard Deviation). It can process features globally or per-class\n    to ensure high accuracy in diverse datasets.\n    \"\"\"\n    @staticmethod\n    def mark_outliers(df: pd.DataFrame, columns: List[str]) -&gt; pd.DataFrame:\n        \"\"\"\n        Identifies and marks outliers for specified columns in a DataFrame.\n\n        The method calculates iqr for each column.\n        Values outside the range [q1 - 1.5 * iqr, q3 + 1.5 * iqr] are marked as 1.\n        Columns starting with 'object_' are analyzed within each class group.\n        Other columns are analyzed globally.\n\n        Args:\n            df (pd.DataFrame): The input feature matrix.\n            columns (List[str]): List of numeric column names to analyze.\n\n        Returns:\n            pd.DataFrame: The original DataFrame with additional binary\n                columns: 'outlier_&lt;col_name&gt;' and 'outlier_any'.\n        \"\"\"\n        outlier_marker: str = \"outlier_\"\n        if df.empty:\n            return df\n\n        df = df.copy()\n\n        for col in columns:\n\n            if col not in df.columns:\n                continue\n\n            outlier_column_name = f\"{outlier_marker}{col}\"\n\n            class_group = df.groupby(ImageStatsKeys.class_name)[col]\n            stats: pd.DataFrame = class_group.quantile([0.25, 0.75]).unstack()\n            stats.columns = [\"q1\", \"q3\"]\n            stats[\"iqr\"] = stats[\"q3\"] - stats[\"q1\"]\n            stats[\"upper_limit\"] = stats[\"q3\"] + 1.5 * stats[\"iqr\"]\n            stats[\"lower_limit\"] = np.clip(stats[\"q1\"] - 1.5 * stats[\"iqr\"], a_min=0, a_max=None)\n\n            upper_bounds = df[ImageStatsKeys.class_name].map(stats[\"upper_limit\"])\n            lower_bounds = df[ImageStatsKeys.class_name].map(stats[\"lower_limit\"])\n            df[outlier_column_name] = ((df[col] &lt; lower_bounds) | (df[col] &gt; upper_bounds)).astype(\"int8\")\n\n        outlier_cols = [col for col in df.columns if col. startswith(outlier_marker)]\n        df[\"outlier_any\"] = df[outlier_cols].any(axis=1).astype(\"int8\")\n        return df\n</code></pre>"},{"location":"api/outlier_detector/#services.outlier_detector.OutlierDetector.mark_outliers","title":"<code>mark_outliers(df, columns)</code>  <code>staticmethod</code>","text":"<p>Identifies and marks outliers for specified columns in a DataFrame.</p> <p>The method calculates iqr for each column. Values outside the range [q1 - 1.5 * iqr, q3 + 1.5 * iqr] are marked as 1. Columns starting with 'object_' are analyzed within each class group. Other columns are analyzed globally.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input feature matrix.</p> required <code>columns</code> <code>List[str]</code> <p>List of numeric column names to analyze.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The original DataFrame with additional binary columns: 'outlier_' and 'outlier_any'. Source code in <code>services/outlier_detector.py</code> <pre><code>@staticmethod\ndef mark_outliers(df: pd.DataFrame, columns: List[str]) -&gt; pd.DataFrame:\n    \"\"\"\n    Identifies and marks outliers for specified columns in a DataFrame.\n\n    The method calculates iqr for each column.\n    Values outside the range [q1 - 1.5 * iqr, q3 + 1.5 * iqr] are marked as 1.\n    Columns starting with 'object_' are analyzed within each class group.\n    Other columns are analyzed globally.\n\n    Args:\n        df (pd.DataFrame): The input feature matrix.\n        columns (List[str]): List of numeric column names to analyze.\n\n    Returns:\n        pd.DataFrame: The original DataFrame with additional binary\n            columns: 'outlier_&lt;col_name&gt;' and 'outlier_any'.\n    \"\"\"\n    outlier_marker: str = \"outlier_\"\n    if df.empty:\n        return df\n\n    df = df.copy()\n\n    for col in columns:\n\n        if col not in df.columns:\n            continue\n\n        outlier_column_name = f\"{outlier_marker}{col}\"\n\n        class_group = df.groupby(ImageStatsKeys.class_name)[col]\n        stats: pd.DataFrame = class_group.quantile([0.25, 0.75]).unstack()\n        stats.columns = [\"q1\", \"q3\"]\n        stats[\"iqr\"] = stats[\"q3\"] - stats[\"q1\"]\n        stats[\"upper_limit\"] = stats[\"q3\"] + 1.5 * stats[\"iqr\"]\n        stats[\"lower_limit\"] = np.clip(stats[\"q1\"] - 1.5 * stats[\"iqr\"], a_min=0, a_max=None)\n\n        upper_bounds = df[ImageStatsKeys.class_name].map(stats[\"upper_limit\"])\n        lower_bounds = df[ImageStatsKeys.class_name].map(stats[\"lower_limit\"])\n        df[outlier_column_name] = ((df[col] &lt; lower_bounds) | (df[col] &gt; upper_bounds)).astype(\"int8\")\n\n    outlier_cols = [col for col in df.columns if col. startswith(outlier_marker)]\n    df[\"outlier_any\"] = df[outlier_cols].any(axis=1).astype(\"int8\")\n    return df\n</code></pre>"},{"location":"api/txt_reader/","title":"TXT reader","text":"<p>               Bases: <code>BaseReader</code></p> <p>A reader class for parsing YOLO-style text files (.txt).</p> <p>This class reads raw text data from YOLO annotations or class list files and transforms the content into a dictionary format suitable for DataForge processing.</p> Source code in <code>tools/annotation_converter/reader/yolo.py</code> <pre><code>class TXTReader(BaseReader):\n    \"\"\"\n    A reader class for parsing YOLO-style text files (.txt).\n\n    This class reads raw text data from YOLO annotations or class list files\n    and transforms the content into a dictionary format suitable for\n    DataForge processing.\n    \"\"\"\n\n    def read(self, file_path: Path) -&gt; dict:\n        \"\"\"\n        Reads a YOLO text file and converts its lines into a dictionary.\n\n        Each non-empty line in the file becomes a key in the dictionary,\n        and its line position (index as a string) becomes the corresponding value.\n\n        Args:\n            file_path (Path): The path to the source .txt annotation file.\n\n        Returns:\n            dict: A dictionary where keys are text lines and values are their\n                string indices.\n\n        Raises:\n            FileNotFoundError: If the .txt file cannot be found at the given path.\n        \"\"\"\n        with open(file_path, \"r\") as file:\n            text = file.read()\n\n        data = {key: str(value) for value, key in enumerate(text.split(\"\\n\")) if key}\n        return data\n</code></pre>"},{"location":"api/txt_reader/#tools.annotation_converter.reader.yolo.TXTReader.read","title":"<code>read(file_path)</code>","text":"<p>Reads a YOLO text file and converts its lines into a dictionary.</p> <p>Each non-empty line in the file becomes a key in the dictionary, and its line position (index as a string) becomes the corresponding value.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>The path to the source .txt annotation file.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary where keys are text lines and values are their string indices.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the .txt file cannot be found at the given path.</p> Source code in <code>tools/annotation_converter/reader/yolo.py</code> <pre><code>def read(self, file_path: Path) -&gt; dict:\n    \"\"\"\n    Reads a YOLO text file and converts its lines into a dictionary.\n\n    Each non-empty line in the file becomes a key in the dictionary,\n    and its line position (index as a string) becomes the corresponding value.\n\n    Args:\n        file_path (Path): The path to the source .txt annotation file.\n\n    Returns:\n        dict: A dictionary where keys are text lines and values are their\n            string indices.\n\n    Raises:\n        FileNotFoundError: If the .txt file cannot be found at the given path.\n    \"\"\"\n    with open(file_path, \"r\") as file:\n        text = file.read()\n\n    data = {key: str(value) for value, key in enumerate(text.split(\"\\n\")) if key}\n    return data\n</code></pre>"},{"location":"api/video_slicer/","title":"Video slicer","text":"<p>A class to cut a video into many images.</p> <p>This class takes a video file and saves its frames as separate image files in a folder.</p> Source code in <code>tools/video_slicer.py</code> <pre><code>class VideoSlicer:\n    \"\"\"A class to cut a video into many images.\n\n    This class takes a video file and saves its frames as separate image files in a folder.\n    \"\"\"\n    def __init__(self):\n        \"\"\"Initializes the VideoSlicer.\n\n        It sets the initial state of the slicer.\n        \"\"\"\n        self.__sliced: bool = False\n\n\n    def slice(self, source_file: Path, target_dir: Path, suffix: str = \".jpg\", step: float = 1) -&gt; tuple:\n        \"\"\"Cuts the video into images and saves them to a folder.\n\n        Args:\n            source_file (Path): The path to the video file you want to cut.\n            target_dir (Path): The folder where you want to save the images.\n            suffix (str): The file extension for the images (for example, '.jpg'). Defaults to '.jpg'.\n            step (float): How many seconds to wait between saving images. Defaults to 1.\n\n        Returns:\n            tuple: A tuple containing:\n                - bool: True if the video was sliced successfully, False otherwise.\n                - int: The total number of images saved.\n        \"\"\"\n        cap = cv2.VideoCapture(str(source_file))\n\n        if not cap.isOpened():\n            return self.sliced, 0\n\n        fps = cap.get(cv2.CAP_PROP_FPS)\n        step_frames = int(fps * step)\n        img_counter = 0\n        frame_id = 0\n\n        while True:\n            ret, frame = cap.read()\n\n            if not ret:\n                break\n\n            if frame_id % step_frames == 0:\n                new_filename = f\"{source_file.stem}_{img_counter}{suffix}\"\n                file_path = target_dir / new_filename\n                cv2.imwrite(str(file_path), frame)\n                img_counter += 1\n\n            frame_id += 1\n\n        cap.release()\n        self.__sliced = True\n        return self.sliced, img_counter\n\n\n    @property\n    def sliced(self) -&gt; bool:\n        \"\"\"Checks if the video has been sliced.\n\n        Returns:\n            bool: True if the slice method was called and finished, False otherwise.\n        \"\"\"\n        return self.__sliced\n</code></pre>"},{"location":"api/video_slicer/#tools.video_slicer.VideoSlicer.sliced","title":"<code>sliced</code>  <code>property</code>","text":"<p>Checks if the video has been sliced.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the slice method was called and finished, False otherwise.</p>"},{"location":"api/video_slicer/#tools.video_slicer.VideoSlicer.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the VideoSlicer.</p> <p>It sets the initial state of the slicer.</p> Source code in <code>tools/video_slicer.py</code> <pre><code>def __init__(self):\n    \"\"\"Initializes the VideoSlicer.\n\n    It sets the initial state of the slicer.\n    \"\"\"\n    self.__sliced: bool = False\n</code></pre>"},{"location":"api/video_slicer/#tools.video_slicer.VideoSlicer.slice","title":"<code>slice(source_file, target_dir, suffix='.jpg', step=1)</code>","text":"<p>Cuts the video into images and saves them to a folder.</p> <p>Parameters:</p> Name Type Description Default <code>source_file</code> <code>Path</code> <p>The path to the video file you want to cut.</p> required <code>target_dir</code> <code>Path</code> <p>The folder where you want to save the images.</p> required <code>suffix</code> <code>str</code> <p>The file extension for the images (for example, '.jpg'). Defaults to '.jpg'.</p> <code>'.jpg'</code> <code>step</code> <code>float</code> <p>How many seconds to wait between saving images. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>A tuple containing: - bool: True if the video was sliced successfully, False otherwise. - int: The total number of images saved.</p> Source code in <code>tools/video_slicer.py</code> <pre><code>def slice(self, source_file: Path, target_dir: Path, suffix: str = \".jpg\", step: float = 1) -&gt; tuple:\n    \"\"\"Cuts the video into images and saves them to a folder.\n\n    Args:\n        source_file (Path): The path to the video file you want to cut.\n        target_dir (Path): The folder where you want to save the images.\n        suffix (str): The file extension for the images (for example, '.jpg'). Defaults to '.jpg'.\n        step (float): How many seconds to wait between saving images. Defaults to 1.\n\n    Returns:\n        tuple: A tuple containing:\n            - bool: True if the video was sliced successfully, False otherwise.\n            - int: The total number of images saved.\n    \"\"\"\n    cap = cv2.VideoCapture(str(source_file))\n\n    if not cap.isOpened():\n        return self.sliced, 0\n\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    step_frames = int(fps * step)\n    img_counter = 0\n    frame_id = 0\n\n    while True:\n        ret, frame = cap.read()\n\n        if not ret:\n            break\n\n        if frame_id % step_frames == 0:\n            new_filename = f\"{source_file.stem}_{img_counter}{suffix}\"\n            file_path = target_dir / new_filename\n            cv2.imwrite(str(file_path), frame)\n            img_counter += 1\n\n        frame_id += 1\n\n    cap.release()\n    self.__sliced = True\n    return self.sliced, img_counter\n</code></pre>"},{"location":"api/voc_stats/","title":"VOC Stats","text":"<p>               Bases: <code>BaseStats</code></p> <p>Concrete analyzer for datasets in Pascal VOC (XML) format.</p> <p>This class implements the processing logic for XML annotation files. It coordinates data reading, geometric feature extraction, and pixel-level image analysis to build a comprehensive feature matrix.</p> Source code in <code>tools/stats/voc_stats.py</code> <pre><code>class VOCStats(BaseStats):\n    \"\"\"\n    Concrete analyzer for datasets in Pascal VOC (XML) format.\n\n    This class implements the processing logic for XML annotation files.\n    It coordinates data reading, geometric feature extraction, and\n    pixel-level image analysis to build a comprehensive feature matrix.\n    \"\"\"\n    _worker_image_map = {}\n\n    @staticmethod\n    def get_umap_features(df: pd.DataFrame) -&gt; List[str]:\n        \"\"\"\n        Selects relevant numeric columns for dimensionality reduction (UMAP).\n\n        Filters out metadata (paths, timestamps), categorical data,\n        and outlier flags to ensure UMAP focuses on geometric and\n        content-based manifold analysis.\n\n        Args:\n            df (pd.DataFrame): The complete feature matrix.\n\n        Returns:\n            List[str]: A list of numeric column names suitable for projection.\n        \"\"\"\n        exclude = {\n            ImageStatsKeys.class_name,\n            ImageStatsKeys.path,\n            ImageStatsKeys.mtime,\n            ImageStatsKeys.has_neighbors,\n            ImageStatsKeys.full_size,\n            ImageStatsKeys.objects_count\n        }\n\n        numeric_features = [c for c in df.select_dtypes(include=[np.number]).columns\n                            if c not in exclude and not c.startswith('outlier')]\n\n        return numeric_features\n\n    @classmethod\n    def _init_worker(cls, image_dict: Dict[str, str]):\n        \"\"\"\n        Initializes a worker process with a shared image lookup map.\n\n        This method is called once per worker process during the startup\n        of the ProcessPoolExecutor to provide fast access to image paths.\n\n        Args:\n            image_dict (Dict[str, str]): Map of image stems to their absolute paths.\n        \"\"\"\n        cls._worker_image_map = image_dict\n\n    @staticmethod\n    def _analyze_worker(\n            file_path: Path,\n            reader: BaseReader,\n            margin_threshold: int = 5,\n            class_mapping: Optional[Dict[str, str]] = None\n\n    ) -&gt; List[Dict[str, str]]:\n        \"\"\"\n         Parses a single VOC XML file and merges geometric data with pixel metrics.\n\n         The workflow includes:\n             1. Parsing XML to get object coordinates.\n             2. Calculating geometric features (area, aspect ratio, etc.).\n             3. Analyzing image content (brightness, contrast, blur).\n             4. Fusing both data sources into a single record.\n\n         Args:\n             file_path (Path): Path to the .xml annotation file.\n             reader (BaseReader): XML parser instance.\n             margin_threshold (int): Margin for truncation detection.\n             class_mapping (Optional[Dict[str, str]]): ID-to-name mapping.\n\n         Returns:\n             List[Dict[str, str]]: A list of fused feature dictionaries\n                 for each object. Returns an empty list on failure.\n         \"\"\"\n        try:\n            annotation_data = reader.read(file_path).get(\"annotation\")\n\n            if not annotation_data:\n                return []\n            correspond_img_str = VOCStats._worker_image_map.get(file_path.stem)\n            stat_data = FeatureExtractor.extract_features(file_path, annotation_data, margin_threshold)\n            pixel_data = ImageContentAnalyzer.analyze_metrics(correspond_img_str)\n\n            for obj in stat_data:\n                obj.update(pixel_data)\n                obj.update({ImageStatsKeys.im_path: correspond_img_str})\n\n            return stat_data\n        except Exception as e:\n            return []\n</code></pre>"},{"location":"api/voc_stats/#tools.stats.voc_stats.VOCStats.get_umap_features","title":"<code>get_umap_features(df)</code>  <code>staticmethod</code>","text":"<p>Selects relevant numeric columns for dimensionality reduction (UMAP).</p> <p>Filters out metadata (paths, timestamps), categorical data, and outlier flags to ensure UMAP focuses on geometric and content-based manifold analysis.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The complete feature matrix.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of numeric column names suitable for projection.</p> Source code in <code>tools/stats/voc_stats.py</code> <pre><code>@staticmethod\ndef get_umap_features(df: pd.DataFrame) -&gt; List[str]:\n    \"\"\"\n    Selects relevant numeric columns for dimensionality reduction (UMAP).\n\n    Filters out metadata (paths, timestamps), categorical data,\n    and outlier flags to ensure UMAP focuses on geometric and\n    content-based manifold analysis.\n\n    Args:\n        df (pd.DataFrame): The complete feature matrix.\n\n    Returns:\n        List[str]: A list of numeric column names suitable for projection.\n    \"\"\"\n    exclude = {\n        ImageStatsKeys.class_name,\n        ImageStatsKeys.path,\n        ImageStatsKeys.mtime,\n        ImageStatsKeys.has_neighbors,\n        ImageStatsKeys.full_size,\n        ImageStatsKeys.objects_count\n    }\n\n    numeric_features = [c for c in df.select_dtypes(include=[np.number]).columns\n                        if c not in exclude and not c.startswith('outlier')]\n\n    return numeric_features\n</code></pre>"},{"location":"api/voc_yolo_converter/","title":"VOC to YOLO converter","text":"<p>               Bases: <code>BaseConverter</code></p> <p>A high-performance converter for dataset annotations from Pascal VOC (.xml) to YOLO (.txt).</p> <p>This class implements a two-phase parallel processing pipeline: 1. Discovery Phase: Scans all files to build a consistent class mapping. 2. Execution Phase: Performs the actual coordinate normalization and saves the files.</p> <p>Attributes:</p> Name Type Description <code>CLASSES_FILE</code> <code>str</code> <p>The name of the output file containing the list of YOLO classes.</p> <code>tolerance</code> <code>int</code> <p>Precision of the coordinates in the resulting YOLO files.</p> <code>objects</code> <code>list</code> <p>A list of unique class names found during the discovery phase.</p> <code>class_mapping</code> <code>Dict[str, int]</code> <p>A dictionary mapping class names to their YOLO IDs.</p> Source code in <code>tools/annotation_converter/converter/voc_yolo_converter.py</code> <pre><code>class VocYOLOConverter(BaseConverter):\n    \"\"\"\n        A high-performance converter for dataset annotations from Pascal VOC (.xml) to YOLO (.txt).\n\n        This class implements a two-phase parallel processing pipeline:\n        1. Discovery Phase: Scans all files to build a consistent class mapping.\n        2. Execution Phase: Performs the actual coordinate normalization and saves the files.\n\n        Attributes:\n            CLASSES_FILE (str): The name of the output file containing the list of YOLO classes.\n            tolerance (int): Precision of the coordinates in the resulting YOLO files.\n            objects (list): A list of unique class names found during the discovery phase.\n            class_mapping (Dict[str, int]): A dictionary mapping class names to their YOLO IDs.\n        \"\"\"\n    CLASSES_FILE = \"classes.txt\"\n    def __init__(self, source_format, dest_format, tolerance: int = 6, **kwargs):\n        \"\"\"\n        Initializes the VOC to YOLO converter.\n\n        Args:\n            source_format (str): The extension of source files (e.g., '.xml').\n            dest_format (str): The extension of destination files (e.g., '.txt').\n            tolerance (int): Number of decimal places for coordinates. Defaults to 6.\n            **kwargs (dict): Additional parameters passed to the BaseConverter.\n        \"\"\"\n        super().__init__(source_format, dest_format, **kwargs)\n\n        self.tolerance = tolerance\n        self.objects: list = list()\n        self.class_mapping: Dict[str, int] = dict()\n\n\n    @staticmethod\n    def _get_classes_worker(annotation_paths: Path, reader: BaseReader) -&gt; Set[str]:\n        \"\"\"\n        Multiprocessing worker for the Discovery Phase.\n\n        Reads a single annotation file and extracts all unique object names.\n\n        Args:\n           annotation_paths (Path): Path to the XML annotation file.\n           reader (BaseReader): The reader instance used to parse XML data.\n\n        Returns:\n           Set[str]: A set of unique class names found in the file.\n        \"\"\"\n        try:\n            data = reader.read(annotation_paths)\n            annotation = data.get(\"annotation\", {})\n            objects = annotation.get(\"object\", list())\n            if not isinstance(objects, list):\n                objects = [objects]\n            return {obj[\"name\"] for obj in objects}\n        except Exception:\n            return set()\n\n\n    @staticmethod\n    def _convert_worker(\n            file_path: Path,\n            destination_path: Path,\n            reader: BaseReader,\n            writer: BaseWriter,\n            class_mapping: Dict[str, int],\n            tolerance: int,\n            suffix: str\n    ) -&gt; bool:\n        \"\"\"\n        Multiprocessing worker for the Execution Phase.\n\n        Performs the core logic: reads XML, calculates YOLO-normalized coordinates\n        (center_x, center_y, width, height), and saves the resulting text file.\n\n        Args:\n           file_path (Path): Path to the source XML file.\n           destination_path (Path): Directory where the output file will be saved.\n           reader (BaseReader): Reader instance for XML parsing.\n           writer (BaseWriter): Writer instance for saving YOLO data.\n           class_mapping (Dict[str, int]): Map of class names to their integer IDs.\n           tolerance (int): Precision for rounding coordinates.\n           suffix (str): The file extension for the output file.\n\n        Returns:\n           bool: True if the file was successfully processed and saved.\n        \"\"\"\n        data = reader.read(file_path)\n\n        if data.get(\"annotation\") is None:\n            return False\n\n        annotation = data[\"annotation\"]\n\n        try:\n            img_width = int(annotation[\"size\"][\"width\"])\n            img_height = int(annotation[\"size\"][\"height\"])\n\n            if img_width == 0 or img_height == 0:\n                raise ValueError(f\"Image size is zero in annotation {file_path}!\")\n        except (KeyError, ValueError, TypeError):\n            return False\n\n        annotated_objects = annotation.get(\"object\", list())\n\n        # reader using xmltodict that returns a dict if there is just one object, if more - returns a list\n        if not isinstance(annotated_objects, list):\n            annotated_objects = [annotated_objects]\n\n        converted_objects: List[str] = list()\n\n        for obj in annotated_objects:\n            try:\n                # saving objectnames for classes.txt\n                name = obj[\"name\"]\n\n                if name not in class_mapping:\n                    continue\n                class_id = class_mapping[name]\n\n                # calculate yolo format cords\n                bbox = obj[\"bndbox\"]\n                xmin, ymin, xmax, ymax = (\n                    float(bbox[\"xmin\"]), float(bbox[\"ymin\"]),\n                    float(bbox[\"xmax\"]), float(bbox[\"ymax\"])\n                )\n\n                width = ((xmax - xmin) / img_width)\n                height = (ymax - ymin) / img_height\n                x_center = (xmin + xmax) / 2 / img_width\n                y_center = (ymin + ymax) / 2 / img_height\n\n                x_center, y_center, width, height = map(lambda x: np.clip(x, 0, 1),\n                                                        [x_center, y_center, width, height])\n\n                row = (f\"{class_id} \"\n                       f\"{x_center:.{tolerance}f} \"\n                       f\"{y_center:.{tolerance}f} \"\n                       f\"{width:.{tolerance}f} \"\n                       f\"{height:.{tolerance}f}\")\n                converted_objects.append(row)\n\n            except (KeyError, ValueError, TypeError):\n                continue\n\n        converted_path = destination_path / f\"{file_path.stem}{suffix}\"\n        writer.write(converted_objects, converted_path)\n        return True\n\n\n    def convert(self, file_paths: Tuple[Path], target_path: Path, n_jobs: int = 1) -&gt; None:\n        \"\"\"\n        Orchestrates the batch conversion process using multiple processes.\n\n        Phase 1: Scans all files in parallel to create a unified 'classes.txt'.\n        Phase 2: Converts coordinates and saves files in parallel.\n\n        Args:\n            file_paths (Tuple[Path, ...]): Collection of source annotation files.\n            target_path (Path): Directory path for the converted output.\n            n_jobs (int): Number of parallel workers to use. Defaults to 1.\n        \"\"\"\n        count_to_convert = len(file_paths)\n\n        if count_to_convert &gt; 0:\n            target_path.mkdir(parents=True, exist_ok=True)\n\n        self.logger.info(f\"Start converting {count_to_convert} annotations with {n_jobs} workers...\")\n\n        classes_func = partial(self._get_classes_worker, reader=self.reader)\n\n        with ProcessPoolExecutor(max_workers=n_jobs) as executor:\n            classes = list(executor.map(classes_func, file_paths))\n\n        self.objects = sorted(set().union(*classes))\n        class_mapping = {name: i for i, name in enumerate(self.objects)}\n        self.logger.info(f\"Unified class mapping created: {len(self.objects)} classes\")\n\n        worker_func = partial(\n            self._convert_worker,\n            destination_path=target_path,\n            reader=self.reader,\n            writer=self.writer,\n            class_mapping=class_mapping,\n            tolerance=self.tolerance,\n            suffix=self.dest_suffix\n        )\n\n        self.logger.info(f\"converting {count_to_convert} annotations with {n_jobs} workers...\")\n        converted_count = 0\n        with ProcessPoolExecutor(max_workers=n_jobs) as executor:\n            converted_results = executor.map(worker_func, file_paths)\n            converted_count = sum(converted_results)\n\n        self.logger.info(f\"Converted {converted_count}/{count_to_convert} annotations and saved in {target_path}\")\n\n        self.writer.write(self.objects, target_path / self.CLASSES_FILE)\n        self.logger.info(f\"Saved {self.CLASSES_FILE} in {target_path}\")\n\n\n    @property\n    def tolerance(self) -&gt; int:\n        \"\"\"int: The number of decimal places for YOLO coordinates.\"\"\"\n        return self._tolerance\n\n    @tolerance.setter\n    def tolerance(self, value: Union[int, float, str]) -&gt; None:\n        \"\"\"\n        Sets the coordinate precision. Handles conversion from float or string if needed.\n\n        Args:\n            value Union[int, float, str]: The precision value.\n\n        Raises:\n            TypeError: If the value cannot be converted to an integer.\n        \"\"\"\n        if isinstance(value, int):\n            self._tolerance = value\n        else:\n            try:\n                self._tolerance = int(float(value))\n            except TypeError as e:\n                msg = f\"Can`t convert {value} to int from type {type(value)})\\n{e}\"\n                self.logger.warning(msg)\n                raise TypeError(msg)\n</code></pre>"},{"location":"api/voc_yolo_converter/#tools.annotation_converter.converter.voc_yolo_converter.VocYOLOConverter.tolerance","title":"<code>tolerance</code>  <code>property</code> <code>writable</code>","text":"<p>int: The number of decimal places for YOLO coordinates.</p>"},{"location":"api/voc_yolo_converter/#tools.annotation_converter.converter.voc_yolo_converter.VocYOLOConverter.__init__","title":"<code>__init__(source_format, dest_format, tolerance=6, **kwargs)</code>","text":"<p>Initializes the VOC to YOLO converter.</p> <p>Parameters:</p> Name Type Description Default <code>source_format</code> <code>str</code> <p>The extension of source files (e.g., '.xml').</p> required <code>dest_format</code> <code>str</code> <p>The extension of destination files (e.g., '.txt').</p> required <code>tolerance</code> <code>int</code> <p>Number of decimal places for coordinates. Defaults to 6.</p> <code>6</code> <code>**kwargs</code> <code>dict</code> <p>Additional parameters passed to the BaseConverter.</p> <code>{}</code> Source code in <code>tools/annotation_converter/converter/voc_yolo_converter.py</code> <pre><code>def __init__(self, source_format, dest_format, tolerance: int = 6, **kwargs):\n    \"\"\"\n    Initializes the VOC to YOLO converter.\n\n    Args:\n        source_format (str): The extension of source files (e.g., '.xml').\n        dest_format (str): The extension of destination files (e.g., '.txt').\n        tolerance (int): Number of decimal places for coordinates. Defaults to 6.\n        **kwargs (dict): Additional parameters passed to the BaseConverter.\n    \"\"\"\n    super().__init__(source_format, dest_format, **kwargs)\n\n    self.tolerance = tolerance\n    self.objects: list = list()\n    self.class_mapping: Dict[str, int] = dict()\n</code></pre>"},{"location":"api/voc_yolo_converter/#tools.annotation_converter.converter.voc_yolo_converter.VocYOLOConverter.convert","title":"<code>convert(file_paths, target_path, n_jobs=1)</code>","text":"<p>Orchestrates the batch conversion process using multiple processes.</p> <p>Phase 1: Scans all files in parallel to create a unified 'classes.txt'. Phase 2: Converts coordinates and saves files in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>file_paths</code> <code>Tuple[Path, ...]</code> <p>Collection of source annotation files.</p> required <code>target_path</code> <code>Path</code> <p>Directory path for the converted output.</p> required <code>n_jobs</code> <code>int</code> <p>Number of parallel workers to use. Defaults to 1.</p> <code>1</code> Source code in <code>tools/annotation_converter/converter/voc_yolo_converter.py</code> <pre><code>def convert(self, file_paths: Tuple[Path], target_path: Path, n_jobs: int = 1) -&gt; None:\n    \"\"\"\n    Orchestrates the batch conversion process using multiple processes.\n\n    Phase 1: Scans all files in parallel to create a unified 'classes.txt'.\n    Phase 2: Converts coordinates and saves files in parallel.\n\n    Args:\n        file_paths (Tuple[Path, ...]): Collection of source annotation files.\n        target_path (Path): Directory path for the converted output.\n        n_jobs (int): Number of parallel workers to use. Defaults to 1.\n    \"\"\"\n    count_to_convert = len(file_paths)\n\n    if count_to_convert &gt; 0:\n        target_path.mkdir(parents=True, exist_ok=True)\n\n    self.logger.info(f\"Start converting {count_to_convert} annotations with {n_jobs} workers...\")\n\n    classes_func = partial(self._get_classes_worker, reader=self.reader)\n\n    with ProcessPoolExecutor(max_workers=n_jobs) as executor:\n        classes = list(executor.map(classes_func, file_paths))\n\n    self.objects = sorted(set().union(*classes))\n    class_mapping = {name: i for i, name in enumerate(self.objects)}\n    self.logger.info(f\"Unified class mapping created: {len(self.objects)} classes\")\n\n    worker_func = partial(\n        self._convert_worker,\n        destination_path=target_path,\n        reader=self.reader,\n        writer=self.writer,\n        class_mapping=class_mapping,\n        tolerance=self.tolerance,\n        suffix=self.dest_suffix\n    )\n\n    self.logger.info(f\"converting {count_to_convert} annotations with {n_jobs} workers...\")\n    converted_count = 0\n    with ProcessPoolExecutor(max_workers=n_jobs) as executor:\n        converted_results = executor.map(worker_func, file_paths)\n        converted_count = sum(converted_results)\n\n    self.logger.info(f\"Converted {converted_count}/{count_to_convert} annotations and saved in {target_path}\")\n\n    self.writer.write(self.objects, target_path / self.CLASSES_FILE)\n    self.logger.info(f\"Saved {self.CLASSES_FILE} in {target_path}\")\n</code></pre>"},{"location":"api/xml_reader/","title":"XML reader","text":"<p>               Bases: <code>BaseReader</code></p> <p>A reader class designed to parse Pascal VOC XML annotation files into Python dictionaries.</p> <p>This class uses the 'xmltodict' library to handle XML data efficiently. It is specifically optimized and tested for stability with XML files generated by the 'labelImg' annotation tool.</p> Source code in <code>tools/annotation_converter/reader/voc.py</code> <pre><code>class XMLReader(BaseReader):\n    \"\"\"\n    A reader class designed to parse Pascal VOC XML annotation files into Python dictionaries.\n\n    This class uses the 'xmltodict' library to handle XML data efficiently. It is\n    specifically optimized and tested for stability with XML files generated by\n    the 'labelImg' annotation tool.\n    \"\"\"\n    def read(self, file_path: Path) -&gt; dict:\n        \"\"\"\n        Reads the content of an XML file and converts it into a structured dictionary.\n\n        Args:\n            file_path (Path): The path to the source XML file.\n\n        Returns:\n            dict: A Python dictionary containing the parsed XML data.\n\n        Raises:\n            FileNotFoundError: If the XML file is not found at the given path.\n            xmltodict.ParsingInterrupted: If the XML content is not valid or corrupted.\n        \"\"\"\n        data = xmltodict.parse(file_path.read_text())\n        return data\n</code></pre>"},{"location":"api/xml_reader/#tools.annotation_converter.reader.voc.XMLReader.read","title":"<code>read(file_path)</code>","text":"<p>Reads the content of an XML file and converts it into a structured dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>The path to the source XML file.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A Python dictionary containing the parsed XML data.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the XML file is not found at the given path.</p> <code>ParsingInterrupted</code> <p>If the XML content is not valid or corrupted.</p> Source code in <code>tools/annotation_converter/reader/voc.py</code> <pre><code>def read(self, file_path: Path) -&gt; dict:\n    \"\"\"\n    Reads the content of an XML file and converts it into a structured dictionary.\n\n    Args:\n        file_path (Path): The path to the source XML file.\n\n    Returns:\n        dict: A Python dictionary containing the parsed XML data.\n\n    Raises:\n        FileNotFoundError: If the XML file is not found at the given path.\n        xmltodict.ParsingInterrupted: If the XML content is not valid or corrupted.\n    \"\"\"\n    data = xmltodict.parse(file_path.read_text())\n    return data\n</code></pre>"},{"location":"api/xml_writer/","title":"XML writer","text":"<p>               Bases: <code>BaseWriter</code></p> <p>A writer class for saving annotations in the Pascal VOC XML format.</p> <p>This class takes processed XML strings (typically generated by a converter) and writes them to the file system as standard .xml files for object detection datasets. It handles the creation of necessary directories.</p> Source code in <code>tools/annotation_converter/writer/voc.py</code> <pre><code>class XMLWriter(BaseWriter):\n    \"\"\"\n    A writer class for saving annotations in the Pascal VOC XML format.\n\n    This class takes processed XML strings (typically generated by a converter)\n    and writes them to the file system as standard .xml files for object\n    detection datasets. It handles the creation of necessary directories.\n    \"\"\"\n    def write(self, data: str, file_path: Path) -&gt; None:\n        \"\"\"\n        Writes an XML annotation string to the specified file path.\n        This method automatically creates any missing parent directories.\n\n        Args:\n            data (str): A string containing the formatted XML data.\n            file_path (Path): The target destination where the file will be saved.\n\n        Raises:\n            IOError: If the file cannot be opened or written to the disk.\n        \"\"\"\n        file_path.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(file_path, \"w\") as file:\n            file.write(data)\n</code></pre>"},{"location":"api/xml_writer/#tools.annotation_converter.writer.voc.XMLWriter.write","title":"<code>write(data, file_path)</code>","text":"<p>Writes an XML annotation string to the specified file path. This method automatically creates any missing parent directories.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>A string containing the formatted XML data.</p> required <code>file_path</code> <code>Path</code> <p>The target destination where the file will be saved.</p> required <p>Raises:</p> Type Description <code>IOError</code> <p>If the file cannot be opened or written to the disk.</p> Source code in <code>tools/annotation_converter/writer/voc.py</code> <pre><code>def write(self, data: str, file_path: Path) -&gt; None:\n    \"\"\"\n    Writes an XML annotation string to the specified file path.\n    This method automatically creates any missing parent directories.\n\n    Args:\n        data (str): A string containing the formatted XML data.\n        file_path (Path): The target destination where the file will be saved.\n\n    Raises:\n        IOError: If the file cannot be opened or written to the disk.\n    \"\"\"\n    file_path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(file_path, \"w\") as file:\n        file.write(data)\n</code></pre>"},{"location":"api/yolo_stats/","title":"Yolo Stats","text":"<p>               Bases: <code>BaseStats</code></p> <p>Concrete analyzer for datasets in YOLO (.txt) format.</p> <p>This class processes YOLO annotations by converting them into a temporary dictionary format compatible with the common FeatureExtractor. It handles multiprocessing logic and fuses geometric data with pixel-level metrics.</p> Source code in <code>tools/stats/yolo_stats.py</code> <pre><code>class YoloStats(BaseStats):\n    \"\"\"\n    Concrete analyzer for datasets in YOLO (.txt) format.\n\n    This class processes YOLO annotations by converting them into a temporary\n    dictionary format compatible with the common FeatureExtractor. It handles\n    multiprocessing logic and fuses geometric data with pixel-level metrics.\n    \"\"\"\n\n    # Shared lookup map for image paths across worker processes\n    _worker_image_map = {}\n\n\n    @classmethod\n    def _init_worker(cls, image_dict: Dict[str, str]):\n        \"\"\"\n        Initializes a worker process with a shared image map.\n\n        This method ensures each parallel worker has access to the full\n        list of image paths during the analysis.\n\n        Args:\n            image_dict (Dict[str, str]): Map of image stems to their absolute paths.\n        \"\"\"\n        cls._worker_image_map = image_dict\n\n\n    @staticmethod\n    def get_umap_features(df: pd.DataFrame) -&gt; List[str]:\n        \"\"\"\n        Identifies numeric columns suitable for UMAP dimensionality reduction.\n\n        Filters out non-numeric data, identifiers, and outlier-specific columns\n        to prepare a clean input for the UMAP manifold generator.\n\n        Args:\n            df (pd.DataFrame): The main dataset feature matrix.\n\n        Returns:\n            List[str]: A list of selected column names for UMAP processing.\n        \"\"\"\n        exclude = {\n            ImageStatsKeys.class_name,\n            ImageStatsKeys.path,\n            ImageStatsKeys.mtime,\n            ImageStatsKeys.has_neighbors,\n            ImageStatsKeys.full_size,\n            ImageStatsKeys.objects_count\n        }\n\n        numeric_features = [c for c in df.select_dtypes(include=[np.number]).columns\n                            if c not in exclude and not c.startswith('outlier')]\n\n        return numeric_features\n\n\n    @staticmethod\n    def _analyze_worker(\n            file_path: Path,\n            reader: BaseReader,\n            margin_threshold: int = 5,\n            class_mapping: Optional[Dict[str, str]] = None\n\n    ) -&gt; List[Dict[str, str]]:\n        \"\"\"\n        Processes a single YOLO text file and extracts combined features.\n\n        The worker follows these steps:\n            1. Reads the raw YOLO annotation file.\n            2. Converts normalized YOLO coordinates into an internal dictionary.\n            3. Extracts geometric features (area, sectors, truncation).\n            4. Performs image content analysis (brightness, contrast, etc.).\n            5. Merges all metrics into a final feature list.\n\n        Args:\n            file_path (Path): Path to the .txt YOLO annotation file.\n            reader (BaseReader): TXT reader instance to parse YOLO data.\n            margin_threshold (int): Distance from edges to detect object truncation.\n            class_mapping (Optional[Dict[str, str]]): Map to translate class IDs to names.\n\n        Returns:\n            List[Dict[str, Any]]: A list of feature dictionaries for all objects\n                in the file. Returns an empty list if any step fails.\n        \"\"\"\n        try:\n            annotation_data = reader.read(file_path)\n\n\n            if not annotation_data:\n                return []\n            correspond_img_str = YoloStats._worker_image_map.get(file_path.stem)\n\n            if correspond_img_str is None:\n                return []\n\n\n            converted_dict = to_voc_dict(\n                annotations=annotation_data,\n                class_mapping=class_mapping,\n                correspond_img=correspond_img_str\n            )\n\n            annotation = converted_dict.get(\"annotation\", {})\n            stat_data = FeatureExtractor.extract_features(file_path, annotation, margin_threshold)\n            pixel_data = ImageContentAnalyzer.analyze_metrics(correspond_img_str)\n\n            for obj in stat_data:\n                obj.update(pixel_data)\n                obj.update({ImageStatsKeys.im_path: correspond_img_str})\n\n            return stat_data\n        except Exception as e:\n            return []\n</code></pre>"},{"location":"api/yolo_stats/#tools.stats.yolo_stats.YoloStats.get_umap_features","title":"<code>get_umap_features(df)</code>  <code>staticmethod</code>","text":"<p>Identifies numeric columns suitable for UMAP dimensionality reduction.</p> <p>Filters out non-numeric data, identifiers, and outlier-specific columns to prepare a clean input for the UMAP manifold generator.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The main dataset feature matrix.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of selected column names for UMAP processing.</p> Source code in <code>tools/stats/yolo_stats.py</code> <pre><code>@staticmethod\ndef get_umap_features(df: pd.DataFrame) -&gt; List[str]:\n    \"\"\"\n    Identifies numeric columns suitable for UMAP dimensionality reduction.\n\n    Filters out non-numeric data, identifiers, and outlier-specific columns\n    to prepare a clean input for the UMAP manifold generator.\n\n    Args:\n        df (pd.DataFrame): The main dataset feature matrix.\n\n    Returns:\n        List[str]: A list of selected column names for UMAP processing.\n    \"\"\"\n    exclude = {\n        ImageStatsKeys.class_name,\n        ImageStatsKeys.path,\n        ImageStatsKeys.mtime,\n        ImageStatsKeys.has_neighbors,\n        ImageStatsKeys.full_size,\n        ImageStatsKeys.objects_count\n    }\n\n    numeric_features = [c for c in df.select_dtypes(include=[np.number]).columns\n                        if c not in exclude and not c.startswith('outlier')]\n\n    return numeric_features\n</code></pre>"},{"location":"api/yolo_voc_converter/","title":"YOLO to VOC converter","text":"<p>               Bases: <code>BaseConverter</code></p> <p>A converter that transforms dataset annotations from YOLO (.txt) to Pascal VOC (.xml).</p> <p>This class uses multiprocessing to handle large datasets efficiently. It links text labels with their corresponding images to calculate absolute pixel coordinates.</p> <p>Attributes:</p> Name Type Description <code>CLASSES_FILE</code> <code>str</code> <p>Standard name for the file containing class names.</p> <code>_worker_image_map</code> <code>dict</code> <p>A class-level dictionary used to store image paths for worker processes.</p> Source code in <code>tools/annotation_converter/converter/yolo_voc_converter.py</code> <pre><code>class YoloVocConverter(BaseConverter):\n    \"\"\"\n    A converter that transforms dataset annotations from YOLO (.txt) to Pascal VOC (.xml).\n\n    This class uses multiprocessing to handle large datasets efficiently. It links\n    text labels with their corresponding images to calculate absolute pixel coordinates.\n\n    Attributes:\n        CLASSES_FILE (str): Standard name for the file containing class names.\n        _worker_image_map (dict): A class-level dictionary used to store image paths for worker processes.\n    \"\"\"\n    CLASSES_FILE = \"classes.txt\"\n    _worker_image_map = {}\n    def __init__(\n            self,\n            source_format: str,\n            dest_format: str,\n            extensions: Tuple[str, ...],\n            **kwargs\n    ):\n        \"\"\"\n        Initializes the converter with specific formats and directory paths.\n\n        Args:\n            source_format (str): The format of source annotation (e.g., 'yolo').\n            dest_format (str): The format of output annotations (e.g., 'voc').\n            extensions (Tuple[str, ...]): Supported image extensions (e.g., '.jpg', '.png').\n            **kwargs (dict): Additional parameters like 'img_path' or 'labels_path'.\n        \"\"\"\n        super().__init__(source_format, dest_format, **kwargs)\n        self.extensions: Tuple[str, ...] = extensions\n        self.labels_path: Optional[Path] = kwargs.get(\"labels_path\", None)\n        self.img_path: Optional[Path] = kwargs.get(\"img_path\", None)\n        self.objects: list = list()\n        self.object_mapping: Dict[str, str] = dict()\n\n    @classmethod\n    def _init_worker(cls, image_dict: Dict[str, str]):\n        \"\"\"\n        Prepares a worker process by storing a shared image map in the class memory.\n\n        Args:\n            image_dict (Dict[str, str]): A dictionary mapping image names to their paths.\n        \"\"\"\n        cls._worker_image_map = image_dict\n\n    @staticmethod\n    def _convert_worker(\n            file_path: Path,\n            destination_path: Path,\n            reader: BaseReader,\n            writer: BaseWriter,\n            class_mapping: Dict[str, str],\n            suffix: str\n    ) -&gt; bool:\n        \"\"\"\n        The main logic for converting one YOLO file to one VOC XML file.\n\n        It reads the YOLO data, finds the matching image to get its dimensions,\n        recalculates coordinates into pixel values, and saves the final XML.\n\n        Args:\n            file_path (Path): Path to the source YOLO annotation file.\n            destination_path (Path): Directory where the .xml file will be saved.\n            reader (BaseReader): Tool to read the source file data.\n            writer (BaseWriter): Tool to write the resulting XML data.\n            class_mapping (Dict[str, str]): Mapping of class IDs to string names.\n            suffix (str): Extension for the output file.\n\n        Returns:\n            bool: True if the conversion was successful, False otherwise.\n        \"\"\"\n\n        yolo_annotations = reader.read(file_path).keys()\n\n        if not yolo_annotations:\n            return False\n\n        correspond_img_str = YoloVocConverter._worker_image_map.get(file_path.stem)\n\n        if correspond_img_str is None:\n            return False\n\n        converted_dict = to_voc_dict(\n            annotations=yolo_annotations,\n            class_mapping=class_mapping,\n            correspond_img=correspond_img_str\n        )\n\n        try:\n            xml = xmltodict.unparse(converted_dict, pretty=True)\n            annotation_path = Path(destination_path / f\"{file_path.stem}{suffix}\")\n            writer.write(data=xml, file_path=annotation_path)\n        except Exception:\n            return False\n        return True\n\n    def convert(self, file_paths: Tuple[Path], target_path: Path, n_jobs: int = 1) -&gt; None:\n        \"\"\"\n        Batch converts multiple YOLO files into VOC format using parallel processing.\n\n        This method prepares the class names, builds a fast image lookup table,\n        and manages the process pool for the conversion task.\n\n        Args:\n            file_paths (Tuple[Path]): List of paths to the annotation files.\n            target_path (Path): Directory where converted files will be stored.\n            n_jobs (int): Number of parallel workers to use. Defaults to 1.\n        \"\"\"\n        target_path.mkdir(exist_ok=True, parents=True)\n        classes_file = next((path for path in file_paths if path.name == self.CLASSES_FILE), None)\n        if classes_file is None:\n            self.logger.error(\n                f\"No classes file found at {target_path}, all classes will be annotated as 'object_&lt;id&gt;'\"\n            )\n        file_paths = tuple(f for f in file_paths if f.name != self.CLASSES_FILE)\n        count_to_convert = len(file_paths)\n        self.logger.info(\n            f\"Starting converting from YOLO format to VOC format for {count_to_convert} files, with {n_jobs} workers\"\n        )\n        self.object_mapping = self.reader.read(classes_file)\n        self.object_mapping = {value: key for key, value in self.object_mapping.items()}\n        images = {img.stem: str(img.resolve()) for img in self.img_path.iterdir() if img.suffix.lower() in self.extensions}\n\n        convert_func = partial(\n            self.__class__._convert_worker,\n            destination_path=target_path,\n            reader=self.reader,\n            writer=self.writer,\n            class_mapping=self.object_mapping,\n            suffix=self.dest_suffix\n        )\n\n        with ProcessPoolExecutor(\n                max_workers=n_jobs,\n                initializer=self.__class__._init_worker,\n                initargs=(images,)\n        ) as executor:\n            converted_results = executor.map(convert_func, file_paths)\n            converted_count = sum(converted_results)\n\n        self.logger.info(f\"Converted {converted_count}/{count_to_convert} annotations from YOLO to VOC\")\n\n\n    @property\n    def img_path(self) -&gt; Path:\n        \"\"\"Path: Returns the directory path where images are stored.\"\"\"\n        return self._img_path\n\n    @img_path.setter\n    def img_path(self, img_path: Union[Path, str, None]) -&gt; None:\n        \"\"\"\n        Sets the directory for images and validates the input.\n\n        Args:\n        img_path (Union[Path, str, None]): Path to annotated images folder.\n            If None, it uses YOLO annotations same path .\n\n        Raises:\n        TypeError: If the provided path is not a string or Path object.\n        \"\"\"\n        if isinstance(img_path, Path):\n            self._img_path = img_path\n        elif isinstance(img_path, str):\n            self._img_path = Path(img_path)\n        elif img_path is None :\n            self._img_path = self.labels_path\n            self.logger.warning(f\"Dataset images path is not defined. Set same annotations path: {self.labels_path}\")\n        else:\n            msg = f\"img_path must be Path or str, not {type(img_path)}\"\n            self.logger.error(msg)\n            raise TypeError(msg)\n\n    @property\n    def extensions(self) -&gt; Tuple[str, ...]:\n        \"\"\"Tuple[str, ...]: Returns the supported image file extensions.\"\"\"\n        return self._extensions\n\n    @extensions.setter\n    def extensions(self, value: Tuple[str, ...]) -&gt; None:\n        \"\"\"\n        Sets the valid image extensions for the converter.\n\n        Args:\n            value (Tuple[str, ...]): A tuple of extension strings (e.g., ('.jpg',)).\n\n        Raises:\n            TypeError: If the input cannot be converted into a tuple.\n        \"\"\"\n        if isinstance(value, tuple):\n            self._extensions = value\n        else:\n            try:\n                self._extensions = tuple(value)\n            except TypeError as e:\n                msg = f\"extensions must be convertable into tuple, got {type(value)}\"\n                self.logger.error(msg)\n                raise TypeError(msg)\n</code></pre>"},{"location":"api/yolo_voc_converter/#tools.annotation_converter.converter.yolo_voc_converter.YoloVocConverter.extensions","title":"<code>extensions</code>  <code>property</code> <code>writable</code>","text":"<p>Tuple[str, ...]: Returns the supported image file extensions.</p>"},{"location":"api/yolo_voc_converter/#tools.annotation_converter.converter.yolo_voc_converter.YoloVocConverter.img_path","title":"<code>img_path</code>  <code>property</code> <code>writable</code>","text":"<p>Path: Returns the directory path where images are stored.</p>"},{"location":"api/yolo_voc_converter/#tools.annotation_converter.converter.yolo_voc_converter.YoloVocConverter.__init__","title":"<code>__init__(source_format, dest_format, extensions, **kwargs)</code>","text":"<p>Initializes the converter with specific formats and directory paths.</p> <p>Parameters:</p> Name Type Description Default <code>source_format</code> <code>str</code> <p>The format of source annotation (e.g., 'yolo').</p> required <code>dest_format</code> <code>str</code> <p>The format of output annotations (e.g., 'voc').</p> required <code>extensions</code> <code>Tuple[str, ...]</code> <p>Supported image extensions (e.g., '.jpg', '.png').</p> required <code>**kwargs</code> <code>dict</code> <p>Additional parameters like 'img_path' or 'labels_path'.</p> <code>{}</code> Source code in <code>tools/annotation_converter/converter/yolo_voc_converter.py</code> <pre><code>def __init__(\n        self,\n        source_format: str,\n        dest_format: str,\n        extensions: Tuple[str, ...],\n        **kwargs\n):\n    \"\"\"\n    Initializes the converter with specific formats and directory paths.\n\n    Args:\n        source_format (str): The format of source annotation (e.g., 'yolo').\n        dest_format (str): The format of output annotations (e.g., 'voc').\n        extensions (Tuple[str, ...]): Supported image extensions (e.g., '.jpg', '.png').\n        **kwargs (dict): Additional parameters like 'img_path' or 'labels_path'.\n    \"\"\"\n    super().__init__(source_format, dest_format, **kwargs)\n    self.extensions: Tuple[str, ...] = extensions\n    self.labels_path: Optional[Path] = kwargs.get(\"labels_path\", None)\n    self.img_path: Optional[Path] = kwargs.get(\"img_path\", None)\n    self.objects: list = list()\n    self.object_mapping: Dict[str, str] = dict()\n</code></pre>"},{"location":"api/yolo_voc_converter/#tools.annotation_converter.converter.yolo_voc_converter.YoloVocConverter.convert","title":"<code>convert(file_paths, target_path, n_jobs=1)</code>","text":"<p>Batch converts multiple YOLO files into VOC format using parallel processing.</p> <p>This method prepares the class names, builds a fast image lookup table, and manages the process pool for the conversion task.</p> <p>Parameters:</p> Name Type Description Default <code>file_paths</code> <code>Tuple[Path]</code> <p>List of paths to the annotation files.</p> required <code>target_path</code> <code>Path</code> <p>Directory where converted files will be stored.</p> required <code>n_jobs</code> <code>int</code> <p>Number of parallel workers to use. Defaults to 1.</p> <code>1</code> Source code in <code>tools/annotation_converter/converter/yolo_voc_converter.py</code> <pre><code>def convert(self, file_paths: Tuple[Path], target_path: Path, n_jobs: int = 1) -&gt; None:\n    \"\"\"\n    Batch converts multiple YOLO files into VOC format using parallel processing.\n\n    This method prepares the class names, builds a fast image lookup table,\n    and manages the process pool for the conversion task.\n\n    Args:\n        file_paths (Tuple[Path]): List of paths to the annotation files.\n        target_path (Path): Directory where converted files will be stored.\n        n_jobs (int): Number of parallel workers to use. Defaults to 1.\n    \"\"\"\n    target_path.mkdir(exist_ok=True, parents=True)\n    classes_file = next((path for path in file_paths if path.name == self.CLASSES_FILE), None)\n    if classes_file is None:\n        self.logger.error(\n            f\"No classes file found at {target_path}, all classes will be annotated as 'object_&lt;id&gt;'\"\n        )\n    file_paths = tuple(f for f in file_paths if f.name != self.CLASSES_FILE)\n    count_to_convert = len(file_paths)\n    self.logger.info(\n        f\"Starting converting from YOLO format to VOC format for {count_to_convert} files, with {n_jobs} workers\"\n    )\n    self.object_mapping = self.reader.read(classes_file)\n    self.object_mapping = {value: key for key, value in self.object_mapping.items()}\n    images = {img.stem: str(img.resolve()) for img in self.img_path.iterdir() if img.suffix.lower() in self.extensions}\n\n    convert_func = partial(\n        self.__class__._convert_worker,\n        destination_path=target_path,\n        reader=self.reader,\n        writer=self.writer,\n        class_mapping=self.object_mapping,\n        suffix=self.dest_suffix\n    )\n\n    with ProcessPoolExecutor(\n            max_workers=n_jobs,\n            initializer=self.__class__._init_worker,\n            initargs=(images,)\n    ) as executor:\n        converted_results = executor.map(convert_func, file_paths)\n        converted_count = sum(converted_results)\n\n    self.logger.info(f\"Converted {converted_count}/{count_to_convert} annotations from YOLO to VOC\")\n</code></pre>"},{"location":"api/yolo_writer/","title":"TXT writer","text":"<p>               Bases: <code>BaseWriter</code></p> <p>A writer class for saving annotations in the YOLO text format (.txt).</p> <p>This class takes a list of processed annotation strings and saves them into a text file. It ensures that each object is written on a new line and handles the creation of necessary directories.</p> Source code in <code>tools/annotation_converter/writer/yolo.py</code> <pre><code>class YoloWriter(BaseWriter):\n    \"\"\"\n    A writer class for saving annotations in the YOLO text format (.txt).\n\n    This class takes a list of processed annotation strings and saves them\n    into a text file. It ensures that each object is written on a new line\n    and handles the creation of necessary directories.\n    \"\"\"\n    def write(self, data: List[str], file_path: Path) -&gt; None:\n        \"\"\"\n        Writes a list of strings to a YOLO-formatted text file.\n\n        This method automatically creates any missing parent directories.\n        It filters out empty lines and adds a newline character after\n        each record.\n\n        Args:\n            data (List[str]): A list of strings, where each string represents\n                an object (class_id, x_center, y_center, width, height).\n            file_path (Path): The target file path where the annotation\n                will be saved.\n\n        Returns:\n            None: This method does not return any value.\n\n        Raises:\n            IOError: If there is a problem creating the directory or writing\n                the file.\n        \"\"\"\n        file_path.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(file_path, \"w\") as file:\n            file.writelines(f\"{line}\\n\" for line in data if line)\n</code></pre>"},{"location":"api/yolo_writer/#tools.annotation_converter.writer.yolo.YoloWriter.write","title":"<code>write(data, file_path)</code>","text":"<p>Writes a list of strings to a YOLO-formatted text file.</p> <p>This method automatically creates any missing parent directories. It filters out empty lines and adds a newline character after each record.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[str]</code> <p>A list of strings, where each string represents an object (class_id, x_center, y_center, width, height).</p> required <code>file_path</code> <code>Path</code> <p>The target file path where the annotation will be saved.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This method does not return any value.</p> <p>Raises:</p> Type Description <code>IOError</code> <p>If there is a problem creating the directory or writing the file.</p> Source code in <code>tools/annotation_converter/writer/yolo.py</code> <pre><code>def write(self, data: List[str], file_path: Path) -&gt; None:\n    \"\"\"\n    Writes a list of strings to a YOLO-formatted text file.\n\n    This method automatically creates any missing parent directories.\n    It filters out empty lines and adds a newline character after\n    each record.\n\n    Args:\n        data (List[str]): A list of strings, where each string represents\n            an object (class_id, x_center, y_center, width, height).\n        file_path (Path): The target file path where the annotation\n            will be saved.\n\n    Returns:\n        None: This method does not return any value.\n\n    Raises:\n        IOError: If there is a problem creating the directory or writing\n            the file.\n    \"\"\"\n    file_path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(file_path, \"w\") as file:\n        file.writelines(f\"{line}\\n\" for line in data if line)\n</code></pre>"},{"location":"cli/data_forge/","title":"CLI launching","text":"<p>The main entry point for the DataForge toolkit.</p> <p>This class orchestrates the Command Line Interface (CLI). It registers all available file operations, loads the global configuration, and manages the execution of specific tasks based on user input.</p> <p>Attributes:</p> Name Type Description <code>parser</code> <code>ArgumentParser</code> <p>The main CLI parser.</p> <code>subparsers</code> <code>_SubParsersAction</code> <p>A collection of command-specific parsers.</p> <code>commands</code> <code>Dict[str, Type[FileOperation]]</code> <p>A mapping of command names to their respective operation classes.</p> <code>settings</code> <code>AppSettings</code> <p>The global configuration object loaded from JSON and environment variables.</p> Source code in <code>data_forge.py</code> <pre><code>class DataForge:\n    \"\"\"\n    The main entry point for the DataForge toolkit.\n\n    This class orchestrates the Command Line Interface (CLI). It registers\n    all available file operations, loads the global configuration, and\n    manages the execution of specific tasks based on user input.\n\n    Attributes:\n        parser (argparse.ArgumentParser): The main CLI parser.\n        subparsers (argparse._SubParsersAction): A collection of command-specific parsers.\n        commands (Dict[str, Type[FileOperation]]): A mapping of command names\n            to their respective operation classes.\n        settings (AppSettings): The global configuration object loaded from\n            JSON and environment variables.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the DataForge application.\n\n        It sets up the argument parser, registers the list of supported\n        commands, and loads the initial settings from the configuration file.\n        \"\"\"\n        self.parser = argparse.ArgumentParser(description=\"FileManager\")\n        self.subparsers = self.parser.add_subparsers(dest=\"command\")\n        self.commands = {\n            Commands.move: MoveOperation,\n            Commands.slice: SliceOperation,\n            Commands.delete: DeleteOperation,\n            Commands.dedup: DedupOperation,\n            Commands.clean_annotations: CleanAnnotationsOperation,\n            Commands.convert_annotations: ConvertAnnotationsOperation,\n            Commands.stats: StatsOperation\n        }\n        self.settings = AppSettings.load_config(Constants.config_file)\n        self._setup_commands()\n\n\n    @staticmethod\n    def _add_common_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n        \"\"\"\n        Adds shared arguments to a command subparser.\n\n        These arguments are available for all operations, such as source\n        directory, file patterns, and execution loop settings.\n\n        Args:\n            settings (AppSettings): Configuration object used to set default values.\n            parser (argparse.ArgumentParser): The subparser for a specific command.\n        \"\"\"\n        parser.add_argument(arg.src, help=hs.src)\n        parser.add_argument(arg.pattern, arg.p, help=hs.pattern, nargs=\"+\", default=[settings.pattern])\n        parser.add_argument(arg.repeat, arg.r, help=hs.repeat, action='store_true')\n        parser.add_argument(arg.sleep, arg.s, help=hs.sleep, default=settings.sleep)\n        parser.add_argument(arg.log_path, help=hs.log_path, default=settings.log_path)\n        parser.add_argument(arg.log_level, help=hs.log_level, default=settings.log_level)\n\n\n    def _setup_commands(self) -&gt; None:\n        \"\"\"\n        Registers and configures all operation commands.\n\n        It iterates through the 'commands' dictionary to create subparsers\n        and adds both common and operation-specific arguments for each command.\n        \"\"\"\n        for command, operation_class in self.commands.items():\n            subparser = self.subparsers.add_parser(command)\n            self._add_common_arguments(self.settings, subparser)\n            operation_class.add_arguments(self.settings, subparser)\n            subparser.set_defaults(cls=operation_class)\n\n\n    def execute(self):\n        \"\"\"\n        Parses CLI arguments and executes the selected operation.\n\n        This method merges the input from the command line with the\n        existing settings. It ensures that CLI arguments have the highest\n        priority. Then, it creates an instance of the chosen operation\n        and calls its 'run' method.\n        \"\"\"\n        args = self.parser.parse_args()\n        cli_data = {key: value for key, value in vars(args).items() if value is not None and key != \"command\"}\n\n        if hasattr(args, \"cls\"):\n            for key, value in cli_data.items():\n                if hasattr(self.settings, key):\n                    setattr(self.settings, key, value)\n            operation = args.cls(settings=self.settings, **vars(args))\n            operation.run()\n        else:\n            self.parser.print_help()\n</code></pre>"},{"location":"cli/data_forge/#data_forge.DataForge.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the DataForge application.</p> <p>It sets up the argument parser, registers the list of supported commands, and loads the initial settings from the configuration file.</p> Source code in <code>data_forge.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes the DataForge application.\n\n    It sets up the argument parser, registers the list of supported\n    commands, and loads the initial settings from the configuration file.\n    \"\"\"\n    self.parser = argparse.ArgumentParser(description=\"FileManager\")\n    self.subparsers = self.parser.add_subparsers(dest=\"command\")\n    self.commands = {\n        Commands.move: MoveOperation,\n        Commands.slice: SliceOperation,\n        Commands.delete: DeleteOperation,\n        Commands.dedup: DedupOperation,\n        Commands.clean_annotations: CleanAnnotationsOperation,\n        Commands.convert_annotations: ConvertAnnotationsOperation,\n        Commands.stats: StatsOperation\n    }\n    self.settings = AppSettings.load_config(Constants.config_file)\n    self._setup_commands()\n</code></pre>"},{"location":"cli/data_forge/#data_forge.DataForge.execute","title":"<code>execute()</code>","text":"<p>Parses CLI arguments and executes the selected operation.</p> <p>This method merges the input from the command line with the existing settings. It ensures that CLI arguments have the highest priority. Then, it creates an instance of the chosen operation and calls its 'run' method.</p> Source code in <code>data_forge.py</code> <pre><code>def execute(self):\n    \"\"\"\n    Parses CLI arguments and executes the selected operation.\n\n    This method merges the input from the command line with the\n    existing settings. It ensures that CLI arguments have the highest\n    priority. Then, it creates an instance of the chosen operation\n    and calls its 'run' method.\n    \"\"\"\n    args = self.parser.parse_args()\n    cli_data = {key: value for key, value in vars(args).items() if value is not None and key != \"command\"}\n\n    if hasattr(args, \"cls\"):\n        for key, value in cli_data.items():\n            if hasattr(self.settings, key):\n                setattr(self.settings, key, value)\n        operation = args.cls(settings=self.settings, **vars(args))\n        operation.run()\n    else:\n        self.parser.print_help()\n</code></pre>"},{"location":"cli/default_values/","title":"Default Settings","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Centralized configuration management for the DataForge toolkit.</p> <p>This class defines all the parameters used by the application, including file paths, hashing settings, and execution intervals. It uses Pydantic v2 to automatically validate types, enforce value limits, and load configuration from JSON files or environment variables.</p> <p>Attributes:</p> Name Type Description <code>max_percentage</code> <code>int</code> <p>Constant used for percentage calculations (default: 100).</p> <code>remove</code> <code>bool</code> <p>If True, source files will be deleted after processing.</p> <code>pattern</code> <code>Tuple[str, ...]</code> <p>Patterns used to find specific files.</p> <code>repeat</code> <code>bool</code> <p>If True, the operation runs in a continuous loop.</p> <code>sleep</code> <code>Union[int, bool]</code> <p>Seconds to wait between operation cycles.</p> <code>suffix</code> <code>str</code> <p>The file extension used for output files.</p> <code>step_sec</code> <code>float</code> <p>Time interval in seconds for video slicing.</p> <code>log_path</code> <code>Path</code> <p>Directory where log files are stored.</p> <code>log_level</code> <code>str</code> <p>Verbosity level of the logger (e.g., INFO, DEBUG).</p> <code>datatype</code> <code>str</code> <p>The category of files being processed (e.g., image).</p> <code>method</code> <code>str</code> <p>The algorithm name for hashing or comparison.</p> <code>hash_threshold</code> <code>int</code> <p>Distance threshold for identifying duplicates (0-100).</p> <code>confirm_choice</code> <code>tuple</code> <p>Keywords used to confirm interactive deletion.</p> <code>core_size</code> <code>int</code> <p>Resolution for hashing; must be a power of 2.</p> <code>n_jobs</code> <code>int</code> <p>Number of parallel workers; capped by system CPU count.</p> <code>cache_file_path</code> <code>Path</code> <p>Directory for storing persistent hash caches.</p> <code>cache_name</code> <code>Optional[Path]</code> <p>Custom name for the cache file.</p> <code>a_suffix</code> <code>Tuple[str, ...]</code> <p>File patterns specific to annotations.</p> <code>a_source</code> <code>Optional[Path]</code> <p>Directory where annotation files are located.</p> <code>destination_type</code> <code>Optional[str]</code> <p>Target format for annotations.</p> <code>extensions</code> <code>Tuple[str, ...]</code> <p>Supported image file extensions.</p> Source code in <code>const_utils/default_values.py</code> <pre><code>class AppSettings(BaseSettings):\n    \"\"\"\n    Centralized configuration management for the DataForge toolkit.\n\n    This class defines all the parameters used by the application, including\n    file paths, hashing settings, and execution intervals. It uses Pydantic v2\n    to automatically validate types, enforce value limits, and load\n    configuration from JSON files or environment variables.\n\n    Attributes:\n        max_percentage (int): Constant used for percentage calculations (default: 100).\n        remove (bool): If True, source files will be deleted after processing.\n        pattern (Tuple[str, ...]): Patterns used to find specific files.\n        repeat (bool): If True, the operation runs in a continuous loop.\n        sleep (Union[int, bool]): Seconds to wait between operation cycles.\n        suffix (str): The file extension used for output files.\n        step_sec (float): Time interval in seconds for video slicing.\n        log_path (Path): Directory where log files are stored.\n        log_level (str): Verbosity level of the logger (e.g., INFO, DEBUG).\n        datatype (str): The category of files being processed (e.g., image).\n        method (str): The algorithm name for hashing or comparison.\n        hash_threshold (int): Distance threshold for identifying duplicates (0-100).\n        confirm_choice (tuple): Keywords used to confirm interactive deletion.\n        core_size (int): Resolution for hashing; must be a power of 2.\n        n_jobs (int): Number of parallel workers; capped by system CPU count.\n        cache_file_path (Path): Directory for storing persistent hash caches.\n        cache_name (Optional[Path]): Custom name for the cache file.\n        a_suffix (Tuple[str, ...]): File patterns specific to annotations.\n        a_source (Optional[Path]): Directory where annotation files are located.\n        destination_type (Optional[str]): Target format for annotations.\n        extensions (Tuple[str, ...]): Supported image file extensions.\n    \"\"\"\n    max_percentage: int = 100\n    model_config = SettingsConfigDict(\n        env_prefix=\"APP_\",\n        extra=\"ignore\",\n        validate_assignment=True\n    )\n\n    remove: bool = Field(default=False)\n    pattern: Tuple[str, ...] = Field(default_factory=tuple)\n    repeat: bool = Field(default=False)\n    sleep: Union[int, bool] = Field(default=60, ge=0)\n    suffix: str = Field(default=\".jpg\")\n    step_sec: float = Field(default=1.0, ge=0.1)\n    log_path: Path = Field(default=Path(\"./log\"))\n    log_level: str = Field(default=LevelMapping.info)\n    datatype: str = Field(default=Constants.image)\n    method: str = Field(default=Constants.dhash)\n    hash_threshold: int = Field(default=10, ge=0, le=100)\n    confirm_choice: tuple = Field(default=(\"yes\",))\n    core_size: int = Field(default=8, ge=8)\n    n_jobs: int = Field(default=2, ge=1, le=multiprocessing.cpu_count())\n    cache_file_path: Path = Field(default=Path(\"./cache\"))\n    cache_name: Optional[Path] = Field(default=None)\n    a_suffix: Tuple[str, ...] = Field(default_factory=tuple)\n    a_source: Optional[Path] = Field(default=None)\n    destination_type: Optional[str] = Field(default=None)\n    extensions: Tuple[str, ...] = Field(default=(\".jpg\", \".jpeg,\", \".png\"))\n    margin_threshold: int = Field(default=5, ge=0, le=100)\n    report_path: Path = Field(default=Path(\"./reports\"))\n    img_dataset_report_schema: List[Dict[str, Any]] = Field(default=[\n        {\n            \"title\": \"GEOMETRY\",\n            \"type\": \"numeric\",\n            \"columns\": [\n                ImageStatsKeys.object_area,\n                ImageStatsKeys.object_relative_area,\n                ImageStatsKeys.object_width,\n                ImageStatsKeys.object_height,\n                ImageStatsKeys.object_aspect_ratio\n            ]\n        },\n        {\n            \"title\": \"SPATIAL BIAS\",\n            \"type\": \"binary\",\n            \"columns\": [\n                ImageStatsKeys.object_in_center,\n                ImageStatsKeys.object_in_top_side,\n                ImageStatsKeys.object_in_bottom_side,\n                ImageStatsKeys.object_in_left_side,\n                ImageStatsKeys.object_in_right_side,\n                ImageStatsKeys.object_in_left_top,\n                ImageStatsKeys.object_in_right_top,\n                ImageStatsKeys.object_in_left_bottom,\n                ImageStatsKeys.object_in_right_bottom\n            ]\n        },\n        {\n            \"title\": \"TRUNCATION\",\n            \"type\": \"binary\",\n            \"columns\": [\n                ImageStatsKeys.truncated_top,\n                ImageStatsKeys.truncated_bottom,\n                ImageStatsKeys.truncated_left,\n                ImageStatsKeys.truncated_right\n            ]\n        },\n        {\n            \"title\": \"IMAGE QUALITY\",\n            \"type\": \"numeric\",\n            \"columns\": [\n                ImageStatsKeys.im_brightness,\n                ImageStatsKeys.im_contrast,\n                ImageStatsKeys.im_blur_score\n            ]\n        }\n    ])\n\n\n    @field_validator('core_size')\n    @classmethod\n    def check_power_of_two(cls, value: int) -&gt; int:\n        \"\"\"\n        Validates that the core_size is a power of 2.\n\n        Args:\n            value (int): The value to check.\n\n        Returns:\n            int: The validated value.\n\n        Raises:\n            ValueError: If the value is not a power of 2 (e.g., 8, 16, 32).\n        \"\"\"\n        if value &lt;= 0 or (value &amp; (value - 1) != 0):\n            raise ValueError(f\"core_size must be a power of 2 (e.g., 8, 16, 32, 64...), got {value}\")\n        return value\n\n\n    @field_validator(\"report_path\", \"log_path\", \"cache_file_path\", \"a_source\", mode='before')\n    @classmethod\n    def ensure_path(cls, value: Union[str, Path]) -&gt; Path:\n        \"\"\"\n        Converts string input into a Path object before type validation.\n\n        Args:\n            value (Union[str, Path]): The raw path input.\n\n        Returns:\n            Path: An initialized Path object.\n        \"\"\"\n        if isinstance(value, str):\n            return Path(value)\n        return value\n\n\n    @field_validator(\"n_jobs\")\n    @classmethod\n    def ensure_n_jobs(cls, value: Union[int, str]) -&gt; int:\n        \"\"\"\n        Ensures the number of parallel jobs is within safe system limits.\n\n        It prevents setting n_jobs to 0 and caps it at (CPU count - 1) to\n        keep the operating system responsive.\n\n        Args:\n            value (Union[int, str]): Requested number of workers.\n\n        Returns:\n            int: A safe, adjusted number of workers.\n        \"\"\"\n        if not isinstance(value, int):\n            return int(float(value))\n        elif value &gt;= multiprocessing.cpu_count():\n            return multiprocessing.cpu_count() - 1\n        elif value &lt; 1:\n            return 1\n        else:\n            return value\n\n\n    @field_validator(\"extensions\")\n    @classmethod\n    def ensure_extensions(cls, value: Union[str, List[str]]) -&gt; Tuple[str, ...]:\n        \"\"\"\n        Ensures that file extensions are stored as a tuple of strings.\n\n        Args:\n            value (Union[str, List[str]]): Input extension data.\n\n        Returns:\n            Tuple[str, ...]: A tuple of extension strings.\n\n        Raises:\n            TypeError: If the input cannot be converted to a tuple.\n        \"\"\"\n        if isinstance(value, tuple):\n            return value\n        else:\n            try:\n                return tuple(value)\n            except TypeError as e:\n                raise TypeError(e)\n\n\n    @classmethod\n    def load_config(cls, config_path: Path = Constants.config_file) -&gt; \"AppSettings\":\n        \"\"\"\n        Factory method to create a settings object from a JSON file.\n\n        It attempts to read the specified JSON file. If the file is missing\n        or corrupted, it falls back to the default values defined in the class.\n\n        Args:\n            config_path (Path): Path to the config.json file.\n\n        Returns:\n            AppSettings: An initialized and validated settings instance.\n        \"\"\"\n        data = {}\n\n        if config_path.exists():\n            try:\n                with open(config_path, \"r\", encoding=\"utf-8\") as file:\n                    data = json.load(file)\n            except json.JSONDecodeError:\n                print(f\"Warning: {config_path} is corrupted. Using defaults.\")\n\n        return cls(**data)\n</code></pre>"},{"location":"cli/default_values/#const_utils.default_values.AppSettings.check_power_of_two","title":"<code>check_power_of_two(value)</code>  <code>classmethod</code>","text":"<p>Validates that the core_size is a power of 2.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int</code> <p>The value to check.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The validated value.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the value is not a power of 2 (e.g., 8, 16, 32).</p> Source code in <code>const_utils/default_values.py</code> <pre><code>@field_validator('core_size')\n@classmethod\ndef check_power_of_two(cls, value: int) -&gt; int:\n    \"\"\"\n    Validates that the core_size is a power of 2.\n\n    Args:\n        value (int): The value to check.\n\n    Returns:\n        int: The validated value.\n\n    Raises:\n        ValueError: If the value is not a power of 2 (e.g., 8, 16, 32).\n    \"\"\"\n    if value &lt;= 0 or (value &amp; (value - 1) != 0):\n        raise ValueError(f\"core_size must be a power of 2 (e.g., 8, 16, 32, 64...), got {value}\")\n    return value\n</code></pre>"},{"location":"cli/default_values/#const_utils.default_values.AppSettings.ensure_extensions","title":"<code>ensure_extensions(value)</code>  <code>classmethod</code>","text":"<p>Ensures that file extensions are stored as a tuple of strings.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Union[str, List[str]]</code> <p>Input extension data.</p> required <p>Returns:</p> Type Description <code>Tuple[str, ...]</code> <p>Tuple[str, ...]: A tuple of extension strings.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the input cannot be converted to a tuple.</p> Source code in <code>const_utils/default_values.py</code> <pre><code>@field_validator(\"extensions\")\n@classmethod\ndef ensure_extensions(cls, value: Union[str, List[str]]) -&gt; Tuple[str, ...]:\n    \"\"\"\n    Ensures that file extensions are stored as a tuple of strings.\n\n    Args:\n        value (Union[str, List[str]]): Input extension data.\n\n    Returns:\n        Tuple[str, ...]: A tuple of extension strings.\n\n    Raises:\n        TypeError: If the input cannot be converted to a tuple.\n    \"\"\"\n    if isinstance(value, tuple):\n        return value\n    else:\n        try:\n            return tuple(value)\n        except TypeError as e:\n            raise TypeError(e)\n</code></pre>"},{"location":"cli/default_values/#const_utils.default_values.AppSettings.ensure_n_jobs","title":"<code>ensure_n_jobs(value)</code>  <code>classmethod</code>","text":"<p>Ensures the number of parallel jobs is within safe system limits.</p> <p>It prevents setting n_jobs to 0 and caps it at (CPU count - 1) to keep the operating system responsive.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Union[int, str]</code> <p>Requested number of workers.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>A safe, adjusted number of workers.</p> Source code in <code>const_utils/default_values.py</code> <pre><code>@field_validator(\"n_jobs\")\n@classmethod\ndef ensure_n_jobs(cls, value: Union[int, str]) -&gt; int:\n    \"\"\"\n    Ensures the number of parallel jobs is within safe system limits.\n\n    It prevents setting n_jobs to 0 and caps it at (CPU count - 1) to\n    keep the operating system responsive.\n\n    Args:\n        value (Union[int, str]): Requested number of workers.\n\n    Returns:\n        int: A safe, adjusted number of workers.\n    \"\"\"\n    if not isinstance(value, int):\n        return int(float(value))\n    elif value &gt;= multiprocessing.cpu_count():\n        return multiprocessing.cpu_count() - 1\n    elif value &lt; 1:\n        return 1\n    else:\n        return value\n</code></pre>"},{"location":"cli/default_values/#const_utils.default_values.AppSettings.ensure_path","title":"<code>ensure_path(value)</code>  <code>classmethod</code>","text":"<p>Converts string input into a Path object before type validation.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Union[str, Path]</code> <p>The raw path input.</p> required <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>An initialized Path object.</p> Source code in <code>const_utils/default_values.py</code> <pre><code>@field_validator(\"report_path\", \"log_path\", \"cache_file_path\", \"a_source\", mode='before')\n@classmethod\ndef ensure_path(cls, value: Union[str, Path]) -&gt; Path:\n    \"\"\"\n    Converts string input into a Path object before type validation.\n\n    Args:\n        value (Union[str, Path]): The raw path input.\n\n    Returns:\n        Path: An initialized Path object.\n    \"\"\"\n    if isinstance(value, str):\n        return Path(value)\n    return value\n</code></pre>"},{"location":"cli/default_values/#const_utils.default_values.AppSettings.load_config","title":"<code>load_config(config_path=Constants.config_file)</code>  <code>classmethod</code>","text":"<p>Factory method to create a settings object from a JSON file.</p> <p>It attempts to read the specified JSON file. If the file is missing or corrupted, it falls back to the default values defined in the class.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>Path</code> <p>Path to the config.json file.</p> <code>config_file</code> <p>Returns:</p> Name Type Description <code>AppSettings</code> <code>AppSettings</code> <p>An initialized and validated settings instance.</p> Source code in <code>const_utils/default_values.py</code> <pre><code>@classmethod\ndef load_config(cls, config_path: Path = Constants.config_file) -&gt; \"AppSettings\":\n    \"\"\"\n    Factory method to create a settings object from a JSON file.\n\n    It attempts to read the specified JSON file. If the file is missing\n    or corrupted, it falls back to the default values defined in the class.\n\n    Args:\n        config_path (Path): Path to the config.json file.\n\n    Returns:\n        AppSettings: An initialized and validated settings instance.\n    \"\"\"\n    data = {}\n\n    if config_path.exists():\n        try:\n            with open(config_path, \"r\", encoding=\"utf-8\") as file:\n                data = json.load(file)\n        except json.JSONDecodeError:\n            print(f\"Warning: {config_path} is corrupted. Using defaults.\")\n\n    return cls(**data)\n</code></pre>"},{"location":"operations/clean_annotations/","title":"clean-annotations","text":"<p>               Bases: <code>FileOperation</code>, <code>FileRemoverMixin</code></p> <p>An operation to remove 'orphan' annotation files.</p> <p>This class identifies annotation files (like .xml or .txt) that do not have a corresponding image file in the source directory. It helps to maintain dataset integrity by cleaning up labels that are no longer needed.</p> <p>Attributes:</p> Name Type Description <code>a_source</code> <code>Path</code> <p>The directory path where annotation files are stored.</p> Source code in <code>file_operations/clean_annotations.py</code> <pre><code>class CleanAnnotationsOperation(FileOperation, FileRemoverMixin):\n    \"\"\"\n    An operation to remove 'orphan' annotation files.\n\n    This class identifies annotation files (like .xml or .txt) that do not have\n    a corresponding image file in the source directory. It helps to maintain\n    dataset integrity by cleaning up labels that are no longer needed.\n\n    Attributes:\n        a_source (Path): The directory path where annotation files are stored.\n    \"\"\"\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the cleanup operation for annotations.\n\n        Args:\n            **kwargs (dict): Arguments from the command line or settings,\n                specifically looking for 'a_source' and 'a_suffix'.\n        \"\"\"\n        super().__init__(**kwargs)\n        self.a_source = self.settings.a_source\n\n\n    @staticmethod\n    def add_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n        \"\"\"\n        Adds specific CLI arguments for annotation cleaning.\n\n        Args:\n            settings (AppSettings): Global configuration for default values.\n            parser (argparse.ArgumentParser): The parser to which 'a_suffix'\n                and 'a_source' arguments are added.\n        \"\"\"\n        parser.add_argument(\n            Arguments.a_suffix,\n            nargs=\"+\",\n            help=HelpStrings.a_suffix,\n            default=settings.a_suffix,\n        )\n        parser.add_argument(\n            Arguments.a_source,\n            help=HelpStrings.a_source,\n            default=settings.a_source,\n        )\n\n\n    def do_task(self) -&gt; None:\n        \"\"\"\n        Executes the synchronization and removal process.\n\n        It collects all image names (stems) from the source directory and\n        compares them with annotation files. If an annotation stem is not\n        found in the image stems, the file is deleted using FileRemoverMixin.\n        \"\"\"\n        self.logger.info(f\"Checking for orphan annotations in {self.settings.a_source}\")\n        annotation_paths = self.get_files(\n            source_directory=self.a_source,\n            pattern=self.settings.a_suffix\n        )\n\n        image_stems = set(image.stem for image in self.files_for_task)\n        orphans_removed = 0\n\n        for a_path in annotation_paths:\n            if a_path.stem not in image_stems:\n                if self.remove_file(a_path):\n                    orphans_removed += 1\n                    self.logger.info(f\"Removed {a_path.stem}\")\n\n        self.logger.info(f\"Removed {orphans_removed} orphan annotations\")\n\n        wait(logger=self.logger, timeout=self.sleep)\n\n\n    @property\n    def a_source(self) -&gt; Path:\n        \"\"\"Path: Returns the directory path for annotations.\"\"\"\n        return self._a_source\n\n\n    @a_source.setter\n    def a_source(self, value: Union[Path, str, None]) -&gt; None:\n        \"\"\"\n        Sets the annotation source path with type validation.\n\n        If the provided value is None, it defaults to the main source_directory.\n        It converts string inputs into Path objects.\n\n        Args:\n            value (Union[Path, str, None]): The path to the annotations folder.\n\n        Raises:\n            TypeError: If the value is not a Path, string, or None.\n        \"\"\"\n        if isinstance(value, Path):\n            self._a_source = value\n        elif isinstance(value, str):\n            self._a_source = Path(value)\n        elif value is None:\n            self._a_source = self.source_directory\n        else:\n            msg = f\"Invalid value for a_source, can be Union[Path, str, None], got {type(value)}\"\n            self.logger.error(msg)\n            raise TypeError(msg)\n</code></pre>"},{"location":"operations/clean_annotations/#file_operations.clean_annotations.CleanAnnotationsOperation.a_source","title":"<code>a_source</code>  <code>property</code> <code>writable</code>","text":"<p>Path: Returns the directory path for annotations.</p>"},{"location":"operations/clean_annotations/#file_operations.clean_annotations.CleanAnnotationsOperation.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the cleanup operation for annotations.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Arguments from the command line or settings, specifically looking for 'a_source' and 'a_suffix'.</p> <code>{}</code> Source code in <code>file_operations/clean_annotations.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the cleanup operation for annotations.\n\n    Args:\n        **kwargs (dict): Arguments from the command line or settings,\n            specifically looking for 'a_source' and 'a_suffix'.\n    \"\"\"\n    super().__init__(**kwargs)\n    self.a_source = self.settings.a_source\n</code></pre>"},{"location":"operations/clean_annotations/#file_operations.clean_annotations.CleanAnnotationsOperation.add_arguments","title":"<code>add_arguments(settings, parser)</code>  <code>staticmethod</code>","text":"<p>Adds specific CLI arguments for annotation cleaning.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>Global configuration for default values.</p> required <code>parser</code> <code>ArgumentParser</code> <p>The parser to which 'a_suffix' and 'a_source' arguments are added.</p> required Source code in <code>file_operations/clean_annotations.py</code> <pre><code>@staticmethod\ndef add_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n    \"\"\"\n    Adds specific CLI arguments for annotation cleaning.\n\n    Args:\n        settings (AppSettings): Global configuration for default values.\n        parser (argparse.ArgumentParser): The parser to which 'a_suffix'\n            and 'a_source' arguments are added.\n    \"\"\"\n    parser.add_argument(\n        Arguments.a_suffix,\n        nargs=\"+\",\n        help=HelpStrings.a_suffix,\n        default=settings.a_suffix,\n    )\n    parser.add_argument(\n        Arguments.a_source,\n        help=HelpStrings.a_source,\n        default=settings.a_source,\n    )\n</code></pre>"},{"location":"operations/clean_annotations/#file_operations.clean_annotations.CleanAnnotationsOperation.do_task","title":"<code>do_task()</code>","text":"<p>Executes the synchronization and removal process.</p> <p>It collects all image names (stems) from the source directory and compares them with annotation files. If an annotation stem is not found in the image stems, the file is deleted using FileRemoverMixin.</p> Source code in <code>file_operations/clean_annotations.py</code> <pre><code>def do_task(self) -&gt; None:\n    \"\"\"\n    Executes the synchronization and removal process.\n\n    It collects all image names (stems) from the source directory and\n    compares them with annotation files. If an annotation stem is not\n    found in the image stems, the file is deleted using FileRemoverMixin.\n    \"\"\"\n    self.logger.info(f\"Checking for orphan annotations in {self.settings.a_source}\")\n    annotation_paths = self.get_files(\n        source_directory=self.a_source,\n        pattern=self.settings.a_suffix\n    )\n\n    image_stems = set(image.stem for image in self.files_for_task)\n    orphans_removed = 0\n\n    for a_path in annotation_paths:\n        if a_path.stem not in image_stems:\n            if self.remove_file(a_path):\n                orphans_removed += 1\n                self.logger.info(f\"Removed {a_path.stem}\")\n\n    self.logger.info(f\"Removed {orphans_removed} orphan annotations\")\n\n    wait(logger=self.logger, timeout=self.sleep)\n</code></pre>"},{"location":"operations/convert_annotations/","title":"convert-annotations","text":"<p>               Bases: <code>FileOperation</code></p> Source code in <code>file_operations/convert_annotations.py</code> <pre><code>class ConvertAnnotationsOperation(FileOperation):\n    def __init__(self, settings: AppSettings, **kwargs):\n        \"\"\"Sets up the tool to change annotation formats.\n\n        Args:\n            settings (AppSettings): The default settings for the app.\n            **kwargs (dict): Extra options for the task. It includes:\n                pattern: The starting format (like 'voc' or 'yolo').\n                destination_type: The new format you want.\n                img_path: Where the images are located.\n                n_jobs: How many tasks to run at the same time.\n        \"\"\"\n        super().__init__(settings, **kwargs)\n        self.destination_type = kwargs.get('destination_type')\n        self.img_path = kwargs.get('img_path')\n        self.converter_mapping = {\n            (\"voc\", \"yolo\") : VocYOLOConverter,\n            (\"yolo\", \"voc\"): YoloVocConverter\n        }\n\n        mapping_key = (self.pattern[0], self.destination_type)\n        self.converter: Union[BaseConverter.__subclasses__()] = self.converter_mapping[mapping_key](\n            source_format=mapping_key[0],\n            dest_format=mapping_key[1],\n            extensions=kwargs.get('ext', self.settings.extensions),\n            img_path=self.img_path,\n            labels_path=self.source_directory\n        )\n        self.pattern = self.converter.source_suffix\n        self.n_jobs = kwargs.get('n_jobs', 1)\n\n\n    @staticmethod\n    def add_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n        \"\"\"Adds the necessary options to the command line tool.\n\n        Args:\n            settings (AppSettings): The main settings for the app.\n            parser (argparse.ArgumentParser): The tool that reads command line options.\n        \"\"\"\n        parser.add_argument(\n            Arguments.dst,\n            default=None,\n            help=HelpStrings.dst\n        )\n        parser.add_argument(\n            Arguments.img_path,\n            default=None,\n            help=HelpStrings.img_path\n        )\n        parser.add_argument(\n            Arguments.destination_type,\n            help=HelpStrings.destination_type\n        )\n        parser.add_argument(\n            Arguments.n_jobs,\n            default=settings.n_jobs,\n            help=HelpStrings.n_jobs\n        )\n        parser.add_argument(\n            Arguments.extensions,\n            nargs=\"+\",\n            help=HelpStrings.extensions,\n            default=settings.extensions\n        )\n\n\n    def do_task(self):\n        \"\"\"Starts the conversion of the annotation files\"\"\"\n        self.converter.convert(self.files_for_task, self.target_directory, self.n_jobs)\n</code></pre>"},{"location":"operations/convert_annotations/#file_operations.convert_annotations.ConvertAnnotationsOperation.__init__","title":"<code>__init__(settings, **kwargs)</code>","text":"<p>Sets up the tool to change annotation formats.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>The default settings for the app.</p> required <code>**kwargs</code> <code>dict</code> <p>Extra options for the task. It includes: pattern: The starting format (like 'voc' or 'yolo'). destination_type: The new format you want. img_path: Where the images are located. n_jobs: How many tasks to run at the same time.</p> <code>{}</code> Source code in <code>file_operations/convert_annotations.py</code> <pre><code>def __init__(self, settings: AppSettings, **kwargs):\n    \"\"\"Sets up the tool to change annotation formats.\n\n    Args:\n        settings (AppSettings): The default settings for the app.\n        **kwargs (dict): Extra options for the task. It includes:\n            pattern: The starting format (like 'voc' or 'yolo').\n            destination_type: The new format you want.\n            img_path: Where the images are located.\n            n_jobs: How many tasks to run at the same time.\n    \"\"\"\n    super().__init__(settings, **kwargs)\n    self.destination_type = kwargs.get('destination_type')\n    self.img_path = kwargs.get('img_path')\n    self.converter_mapping = {\n        (\"voc\", \"yolo\") : VocYOLOConverter,\n        (\"yolo\", \"voc\"): YoloVocConverter\n    }\n\n    mapping_key = (self.pattern[0], self.destination_type)\n    self.converter: Union[BaseConverter.__subclasses__()] = self.converter_mapping[mapping_key](\n        source_format=mapping_key[0],\n        dest_format=mapping_key[1],\n        extensions=kwargs.get('ext', self.settings.extensions),\n        img_path=self.img_path,\n        labels_path=self.source_directory\n    )\n    self.pattern = self.converter.source_suffix\n    self.n_jobs = kwargs.get('n_jobs', 1)\n</code></pre>"},{"location":"operations/convert_annotations/#file_operations.convert_annotations.ConvertAnnotationsOperation.add_arguments","title":"<code>add_arguments(settings, parser)</code>  <code>staticmethod</code>","text":"<p>Adds the necessary options to the command line tool.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>The main settings for the app.</p> required <code>parser</code> <code>ArgumentParser</code> <p>The tool that reads command line options.</p> required Source code in <code>file_operations/convert_annotations.py</code> <pre><code>@staticmethod\ndef add_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n    \"\"\"Adds the necessary options to the command line tool.\n\n    Args:\n        settings (AppSettings): The main settings for the app.\n        parser (argparse.ArgumentParser): The tool that reads command line options.\n    \"\"\"\n    parser.add_argument(\n        Arguments.dst,\n        default=None,\n        help=HelpStrings.dst\n    )\n    parser.add_argument(\n        Arguments.img_path,\n        default=None,\n        help=HelpStrings.img_path\n    )\n    parser.add_argument(\n        Arguments.destination_type,\n        help=HelpStrings.destination_type\n    )\n    parser.add_argument(\n        Arguments.n_jobs,\n        default=settings.n_jobs,\n        help=HelpStrings.n_jobs\n    )\n    parser.add_argument(\n        Arguments.extensions,\n        nargs=\"+\",\n        help=HelpStrings.extensions,\n        default=settings.extensions\n    )\n</code></pre>"},{"location":"operations/convert_annotations/#file_operations.convert_annotations.ConvertAnnotationsOperation.do_task","title":"<code>do_task()</code>","text":"<p>Starts the conversion of the annotation files</p> Source code in <code>file_operations/convert_annotations.py</code> <pre><code>def do_task(self):\n    \"\"\"Starts the conversion of the annotation files\"\"\"\n    self.converter.convert(self.files_for_task, self.target_directory, self.n_jobs)\n</code></pre>"},{"location":"operations/deduplicate/","title":"dedup","text":"<p>               Bases: <code>FileOperation</code>, <code>FileRemoverMixin</code></p> <p>An operation to find and remove visual duplicates in a dataset.</p> <p>This class compares images in the source folder using hashing algorithms (like dHash). It identifies similar images based on a similarity threshold and can either delete them automatically or ask the user for confirmation.</p> <p>Attributes:</p> Name Type Description <code>filetype</code> <code>str</code> <p>The type of files to process (e.g., 'image').</p> <code>method</code> <code>str</code> <p>The hashing method used for comparison (e.g., 'dhash').</p> <code>remove</code> <code>bool</code> <p>If True, duplicates are deleted automatically without asking.</p> <code>comparer</code> <code>ImageComparer</code> <p>The engine that performs the actual image comparison.</p> Source code in <code>file_operations/deduplicate.py</code> <pre><code>class DedupOperation(FileOperation, FileRemoverMixin):\n    \"\"\"\n    An operation to find and remove visual duplicates in a dataset.\n\n    This class compares images in the source folder using hashing algorithms\n    (like dHash). It identifies similar images based on a similarity threshold\n    and can either delete them automatically or ask the user for confirmation.\n\n    Attributes:\n        filetype (str): The type of files to process (e.g., 'image').\n        method (str): The hashing method used for comparison (e.g., 'dhash').\n        remove (bool): If True, duplicates are deleted automatically without asking.\n        comparer (ImageComparer): The engine that performs the actual image comparison.\n    \"\"\"\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the deduplication operation.\n\n        Args:\n            **kwargs (dict): Parameters from the command line or settings, including\n                'filetype', 'method', 'threshold', and 'core_size'.\n        \"\"\"\n        super().__init__(**kwargs)\n        self.mapping = {\n            Constants.image: ImageComparer\n        }\n\n        self.filetype = kwargs.get(\"filetype\", self.settings.datatype)\n        self.method = kwargs.get(\"method\", self.settings.method)\n        self.remove = kwargs.get(\"remove\", self.settings.remove)\n        self.comparer: ImageComparer = self.mapping[self.filetype](self.settings)\n\n    @staticmethod\n    def add_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n        \"\"\"\n        Defines CLI arguments for the deduplication task.\n\n        Args:\n            settings (AppSettings): Global configuration for default values.\n            parser (argparse.ArgumentParser): The parser to which arguments are added.\n        \"\"\"\n        parser.add_argument(\n            Arguments.threshold,\n            help=HelpStrings.threshold,\n            default=settings.hash_threshold\n        )\n        parser.add_argument(\n            Arguments.datatype,\n            help=HelpStrings.datatype,\n            default=settings.datatype\n        )\n        parser.add_argument(\n            Arguments.method, Arguments.m,\n            help=HelpStrings.method,\n            default=settings.method\n        )\n        parser.add_argument(\n            Arguments.remove, Arguments.rm,\n            help=HelpStrings.remove,\n            action=\"store_true\"\n        )\n        parser.add_argument(\n            Arguments.core_size,\n            help=HelpStrings.core_size,\n            default=settings.core_size\n        )\n        parser.add_argument(\n            Arguments.n_jobs,\n            help=HelpStrings.n_jobs,\n            default=settings.n_jobs\n        )\n        parser.add_argument(\n            Arguments.cache_name,\n            help=HelpStrings.cache_name,\n            default=None\n        )\n\n    def do_task(self):\n        \"\"\"\n        Executes the deduplication process.\n\n        This method uses the 'ImageComparer' to find duplicates among the\n        collected files. If duplicates are found, it checks for user\n        confirmation (or uses the 'remove' flag) and deletes the files\n        using 'FileRemoverMixin'.\n        \"\"\"\n        duplicates = self.comparer.compare(self.files_for_task)\n        duplicates_count = len(duplicates)\n        self.logger.info(f\"Found {duplicates_count} duplicates in {len(self.files_for_task)} files\")\n\n        if duplicates_count &gt; 0 and self.confirm_removing():\n            self.remove_all(duplicates)\n\n        wait(logger=self.logger, timeout=self.sleep)\n\n    def confirm_removing(self) -&gt; bool:\n        \"\"\"\n        Checks if the operation has permission to delete the found duplicates.\n\n        If the 'remove' flag is not set, the method asks the user to type\n        'delete' in the console to proceed.\n\n        Returns:\n            bool: True if deletion is confirmed, False otherwise.\n        \"\"\"\n        if not self.remove:\n            user_choice = input(\"for deleting founded duplicate files type 'yes': \")\n            return user_choice.lower() in self.settings.confirm_choice\n        return True\n</code></pre>"},{"location":"operations/deduplicate/#file_operations.deduplicate.DedupOperation.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the deduplication operation.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Parameters from the command line or settings, including 'filetype', 'method', 'threshold', and 'core_size'.</p> <code>{}</code> Source code in <code>file_operations/deduplicate.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the deduplication operation.\n\n    Args:\n        **kwargs (dict): Parameters from the command line or settings, including\n            'filetype', 'method', 'threshold', and 'core_size'.\n    \"\"\"\n    super().__init__(**kwargs)\n    self.mapping = {\n        Constants.image: ImageComparer\n    }\n\n    self.filetype = kwargs.get(\"filetype\", self.settings.datatype)\n    self.method = kwargs.get(\"method\", self.settings.method)\n    self.remove = kwargs.get(\"remove\", self.settings.remove)\n    self.comparer: ImageComparer = self.mapping[self.filetype](self.settings)\n</code></pre>"},{"location":"operations/deduplicate/#file_operations.deduplicate.DedupOperation.add_arguments","title":"<code>add_arguments(settings, parser)</code>  <code>staticmethod</code>","text":"<p>Defines CLI arguments for the deduplication task.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>Global configuration for default values.</p> required <code>parser</code> <code>ArgumentParser</code> <p>The parser to which arguments are added.</p> required Source code in <code>file_operations/deduplicate.py</code> <pre><code>@staticmethod\ndef add_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n    \"\"\"\n    Defines CLI arguments for the deduplication task.\n\n    Args:\n        settings (AppSettings): Global configuration for default values.\n        parser (argparse.ArgumentParser): The parser to which arguments are added.\n    \"\"\"\n    parser.add_argument(\n        Arguments.threshold,\n        help=HelpStrings.threshold,\n        default=settings.hash_threshold\n    )\n    parser.add_argument(\n        Arguments.datatype,\n        help=HelpStrings.datatype,\n        default=settings.datatype\n    )\n    parser.add_argument(\n        Arguments.method, Arguments.m,\n        help=HelpStrings.method,\n        default=settings.method\n    )\n    parser.add_argument(\n        Arguments.remove, Arguments.rm,\n        help=HelpStrings.remove,\n        action=\"store_true\"\n    )\n    parser.add_argument(\n        Arguments.core_size,\n        help=HelpStrings.core_size,\n        default=settings.core_size\n    )\n    parser.add_argument(\n        Arguments.n_jobs,\n        help=HelpStrings.n_jobs,\n        default=settings.n_jobs\n    )\n    parser.add_argument(\n        Arguments.cache_name,\n        help=HelpStrings.cache_name,\n        default=None\n    )\n</code></pre>"},{"location":"operations/deduplicate/#file_operations.deduplicate.DedupOperation.confirm_removing","title":"<code>confirm_removing()</code>","text":"<p>Checks if the operation has permission to delete the found duplicates.</p> <p>If the 'remove' flag is not set, the method asks the user to type 'delete' in the console to proceed.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if deletion is confirmed, False otherwise.</p> Source code in <code>file_operations/deduplicate.py</code> <pre><code>def confirm_removing(self) -&gt; bool:\n    \"\"\"\n    Checks if the operation has permission to delete the found duplicates.\n\n    If the 'remove' flag is not set, the method asks the user to type\n    'delete' in the console to proceed.\n\n    Returns:\n        bool: True if deletion is confirmed, False otherwise.\n    \"\"\"\n    if not self.remove:\n        user_choice = input(\"for deleting founded duplicate files type 'yes': \")\n        return user_choice.lower() in self.settings.confirm_choice\n    return True\n</code></pre>"},{"location":"operations/deduplicate/#file_operations.deduplicate.DedupOperation.do_task","title":"<code>do_task()</code>","text":"<p>Executes the deduplication process.</p> <p>This method uses the 'ImageComparer' to find duplicates among the collected files. If duplicates are found, it checks for user confirmation (or uses the 'remove' flag) and deletes the files using 'FileRemoverMixin'.</p> Source code in <code>file_operations/deduplicate.py</code> <pre><code>def do_task(self):\n    \"\"\"\n    Executes the deduplication process.\n\n    This method uses the 'ImageComparer' to find duplicates among the\n    collected files. If duplicates are found, it checks for user\n    confirmation (or uses the 'remove' flag) and deletes the files\n    using 'FileRemoverMixin'.\n    \"\"\"\n    duplicates = self.comparer.compare(self.files_for_task)\n    duplicates_count = len(duplicates)\n    self.logger.info(f\"Found {duplicates_count} duplicates in {len(self.files_for_task)} files\")\n\n    if duplicates_count &gt; 0 and self.confirm_removing():\n        self.remove_all(duplicates)\n\n    wait(logger=self.logger, timeout=self.sleep)\n</code></pre>"},{"location":"operations/delete/","title":"delete","text":"<p>               Bases: <code>FileOperation</code>, <code>FileRemoverMixin</code></p> <p>An operation to delete files from source directory that match specific patterns.</p> <p>This class identifies files in the source directory and removes them permanently. It uses the FileRemoverMixin to ensure that each deletion is handled safely and logged correctly.</p> Source code in <code>file_operations/delete.py</code> <pre><code>class DeleteOperation(FileOperation, FileRemoverMixin):\n    \"\"\"\n    An operation to delete files from source directory that match specific patterns.\n\n    This class identifies files in the source directory and removes them\n    permanently. It uses the FileRemoverMixin to ensure that each deletion\n    is handled safely and logged correctly.\n    \"\"\"\n    @staticmethod\n    def add_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n        \"\"\"\n        Defines command-line arguments for the delete operation.\n\n        This specific operation does not require unique arguments beyond\n        the standard source and pattern parameters.\n\n        Args:\n            settings (AppSettings): The global settings object for default values.\n            parser (argparse.ArgumentParser): The CLI parser to which arguments are added.\n        \"\"\"\n        pass\n\n\n    def do_task(self):\n        \"\"\"\n        Executes the deletion task for all collected files.\n\n        This method calls the '_remove_all' helper from FileRemoverMixin\n        to process the list of files found in the source directory.\n        \"\"\"\n        self.remove_all(self.files_for_task)\n</code></pre>"},{"location":"operations/delete/#file_operations.delete.DeleteOperation.add_arguments","title":"<code>add_arguments(settings, parser)</code>  <code>staticmethod</code>","text":"<p>Defines command-line arguments for the delete operation.</p> <p>This specific operation does not require unique arguments beyond the standard source and pattern parameters.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>The global settings object for default values.</p> required <code>parser</code> <code>ArgumentParser</code> <p>The CLI parser to which arguments are added.</p> required Source code in <code>file_operations/delete.py</code> <pre><code>@staticmethod\ndef add_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n    \"\"\"\n    Defines command-line arguments for the delete operation.\n\n    This specific operation does not require unique arguments beyond\n    the standard source and pattern parameters.\n\n    Args:\n        settings (AppSettings): The global settings object for default values.\n        parser (argparse.ArgumentParser): The CLI parser to which arguments are added.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"operations/delete/#file_operations.delete.DeleteOperation.do_task","title":"<code>do_task()</code>","text":"<p>Executes the deletion task for all collected files.</p> <p>This method calls the '_remove_all' helper from FileRemoverMixin to process the list of files found in the source directory.</p> Source code in <code>file_operations/delete.py</code> <pre><code>def do_task(self):\n    \"\"\"\n    Executes the deletion task for all collected files.\n\n    This method calls the '_remove_all' helper from FileRemoverMixin\n    to process the list of files found in the source directory.\n    \"\"\"\n    self.remove_all(self.files_for_task)\n</code></pre>"},{"location":"operations/file_operation/","title":"base operation","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for all file operations.</p> <p>This class provides a common structure for tasks like moving, deleting, or processing files. It manages configuration, directory validation, logging, and the main execution loop.</p> <p>Attributes:</p> Name Type Description <code>settings</code> <code>AppSettings</code> <p>The global settings object with default values.</p> <code>command</code> <code>str</code> <p>Name of the operation being executed.</p> <code>sleep</code> <code>float</code> <p>Time in seconds to wait between cycles if 'repeat' is True.</p> <code>repeat</code> <code>bool</code> <p>If True, the operation runs in a continuous loop.</p> <code>files_for_task</code> <code>Tuple[Path]</code> <p>A collection of files found for processing.</p> <code>pattern</code> <code>tuple</code> <p>File extensions or keywords to match files for processing.</p> <code>source_directory</code> <code>Path</code> <p>The directory to search for files for processing.</p> <code>target_directory</code> <code>Path</code> <p>The directory where results are saved.</p> <code>stop</code> <code>bool</code> <p>A flag to stop the execution loop.</p> <code>logger</code> <code>Logger</code> <p>Logger instance for the specific operation.</p> Source code in <code>file_operations/file_operation.py</code> <pre><code>class FileOperation(ABC):\n    \"\"\"\n    Abstract base class for all file operations.\n\n    This class provides a common structure for tasks like moving, deleting,\n    or processing files. It manages configuration, directory validation,\n    logging, and the main execution loop.\n\n    Attributes:\n        settings (AppSettings): The global settings object with default values.\n        command (str): Name of the operation being executed.\n        sleep (float): Time in seconds to wait between cycles if 'repeat' is True.\n        repeat (bool): If True, the operation runs in a continuous loop.\n        files_for_task (Tuple[Path]): A collection of files found for processing.\n        pattern (tuple): File extensions or keywords to match files for processing.\n        source_directory (Path): The directory to search for files for processing.\n        target_directory (Path): The directory where results are saved.\n        stop (bool): A flag to stop the execution loop.\n        logger (logging.Logger): Logger instance for the specific operation.\n    \"\"\"\n    def __init__(self, settings: AppSettings, **kwargs):\n        \"\"\"\n        Initializes the operation with settings and specific arguments.\n\n        Args:\n            settings (AppSettings): Global configuration instance.\n            **kwargs (dict): Arguments from the command line, such as 'src', 'dst',\n                'command', and 'log_path'.\n        \"\"\"\n        self.settings: AppSettings = settings\n        self.command: str = kwargs.get(\"command\", \"operation\")\n        self.sleep: float = kwargs.get('sleep', settings.sleep)\n        self.repeat: bool = kwargs.get('repeat', settings.repeat)\n        self.files_for_task: Tuple[Union[Path]] = tuple()\n        self.pattern: tuple = kwargs.get('pattern', settings.pattern)\n        self.src: str = kwargs.get('src', '')\n        self.dst: str = kwargs.get('dst', '')\n        self.source_directory = Path(self.src)\n        self.target_directory = self.dst\n        self.stop: bool = False\n\n        log_file = self.command\n        log_level = kwargs.get(\"log_level\", settings.log_level)\n        self.log_path = kwargs.get(\"log_path\", settings.log_path)\n\n        self.logger = LoggerConfigurator.setup(\n            name=self.__class__.__name__,\n            log_level=log_level,\n            log_path=Path(self.log_path) / f\"{log_file}.log\" if self.log_path else None\n        )\n        self.logger.info(f\"Started with parameters: {kwargs}\")\n\n\n    def get_files(self, source_directory: Path, pattern: Union[Tuple[str], Tuple[str, ...]]) -&gt; Tuple[Path]:\n        \"\"\"\n        Scans the source directory for files that match the given patterns.\n\n        Args:\n            source_directory (Path): The folder to search in.\n            pattern (Union[Tuple[str], Tuple[str, ...]]): A tuple of strings\n                to match filenames (e.g., ('.jpg', '.png')).\n\n        Returns:\n            Tuple[Path]: A tuple containing Path objects of the found files.\n        \"\"\"\n        files = set()\n\n        for p in pattern:\n            current_pattern_files = source_directory.glob(f\"*{p}*\")\n            files.update(current_pattern_files)\n\n        files_for_task = tuple(file.resolve() for file in files)\n        self.logger.debug(f\"Total files_for_task: {len(files_for_task)}\")\n        return files_for_task\n\n\n    def check_source_directory(self) -&gt; None:\n        \"\"\"\n        Validates that the source directory exists on the file system.\n\n        Raises:\n            FileNotFoundError: If the source path does not exist.\n        \"\"\"\n        if not self.source_directory.exists():\n            msg = f\"Source path '{self.src}' does not exist.\"\n            self.logger.error(msg)\n            raise FileNotFoundError(msg)\n\n\n    def check_directories(self) -&gt; None:\n        \"\"\"\n        Checks the source directory and ensures the target directory exists.\n\n        If the target directory is missing, it creates it automatically with all parents.\n        \"\"\"\n        self.check_source_directory()\n        self.target_directory.mkdir(parents=True, exist_ok=True)\n\n\n    def run(self) -&gt; None:\n        \"\"\"\n        Starts the main execution lifecycle of the operation.\n\n        This method handles the directory checks and enters a loop if 'repeat'\n        is enabled. It calls 'do_task' for the actual work and handles\n        KeyboardInterrupt for safe stopping.\n        \"\"\"\n        self.check_directories()\n        while True:\n            try:\n                self.files_for_task = self.get_files(source_directory=self.source_directory, pattern=self.pattern)\n\n                if len(self.files_for_task) == 0 and self.repeat:\n                    self.logger.info(f\"No files found for task'{self.pattern}'. Wait for {self.sleep} seconds...\")\n                    time.sleep(self.sleep)\n                    continue\n\n                self.do_task()\n\n            except KeyboardInterrupt:\n                self.stop = True\n                self.logger.info(f\"Ctrl+C pressed, stopping...\")\n\n            if self.stop or not self.repeat:\n                self.logger.info(f\"Finished\\n{'-' * 10}\\n\")\n                break\n\n\n    @staticmethod\n    @abstractmethod\n    def add_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n        \"\"\"\n        Abstract method to define specific CLI arguments for the operation.\n\n        Args:\n            settings (AppSettings): To provide default values for arguments.\n            parser (argparse.ArgumentParser): The subparser for the command.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def do_task(self):\n        \"\"\"Abstract method where the main logic of the operation is implemented.\"\"\"\n        pass\n\n    @property\n    def sleep(self):\n        \"\"\"float: Returns the sleep interval in seconds.\"\"\"\n        return self._sleep\n\n    @sleep.setter\n    def sleep(self, value):\n        \"\"\"Sets the sleep interval and ensures it is an integer.\"\"\"\n        self._sleep = int(float(value))\n\n    @property\n    def pattern(self):\n        \"\"\"tuple: Returns the file matching patterns.\"\"\"\n        return self._pattern\n\n    @pattern.setter\n    def pattern(self, value):\n        \"\"\"Sets the pattern. Converts a single string into a tuple if necessary.\"\"\"\n        if isinstance(value, str):\n            self._pattern = (value, )\n        else:\n            self._pattern = value\n\n    @property\n    def stop(self) -&gt; bool:\n        \"\"\"bool: Returns the status of the stop flag.\"\"\"\n        return self.__stop\n\n    @stop.setter\n    def stop(self, value):\n        \"\"\"Sets the stop flag status.\"\"\"\n        self.__stop = value\n\n    @property\n    def target_directory(self):\n        \"\"\"Path: Returns the directory where results are processed.\"\"\"\n        return self._target_directory\n\n    @target_directory.setter\n    def target_directory(self, value: Union[Path, str, None]) -&gt; None:\n        \"\"\"\n        Sets the target directory and converts strings to Path objects.\n\n        If no value is provided (None), the source directory is used as the target.\n\n        Args:\n            value (Union[Path, str, None]): The path to the target folder.\n\n        Raises:\n            TypeError: If the value type is not Path, str, or None.\n        \"\"\"\n        if value is None:\n            self._target_directory = self.source_directory\n        elif isinstance(value, Path):\n            self._target_directory = value\n        elif isinstance(value, str):\n            self._target_directory = Path(value)\n        else:\n            msg = f\"Target directory '{value}' is not valid. Got type '{type(value)}'\"\n            self.logger.error(msg)\n            raise TypeError(msg)\n</code></pre>"},{"location":"operations/file_operation/#file_operations.file_operation.FileOperation.pattern","title":"<code>pattern</code>  <code>property</code> <code>writable</code>","text":"<p>tuple: Returns the file matching patterns.</p>"},{"location":"operations/file_operation/#file_operations.file_operation.FileOperation.sleep","title":"<code>sleep</code>  <code>property</code> <code>writable</code>","text":"<p>float: Returns the sleep interval in seconds.</p>"},{"location":"operations/file_operation/#file_operations.file_operation.FileOperation.stop","title":"<code>stop</code>  <code>property</code> <code>writable</code>","text":"<p>bool: Returns the status of the stop flag.</p>"},{"location":"operations/file_operation/#file_operations.file_operation.FileOperation.target_directory","title":"<code>target_directory</code>  <code>property</code> <code>writable</code>","text":"<p>Path: Returns the directory where results are processed.</p>"},{"location":"operations/file_operation/#file_operations.file_operation.FileOperation.__init__","title":"<code>__init__(settings, **kwargs)</code>","text":"<p>Initializes the operation with settings and specific arguments.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>Global configuration instance.</p> required <code>**kwargs</code> <code>dict</code> <p>Arguments from the command line, such as 'src', 'dst', 'command', and 'log_path'.</p> <code>{}</code> Source code in <code>file_operations/file_operation.py</code> <pre><code>def __init__(self, settings: AppSettings, **kwargs):\n    \"\"\"\n    Initializes the operation with settings and specific arguments.\n\n    Args:\n        settings (AppSettings): Global configuration instance.\n        **kwargs (dict): Arguments from the command line, such as 'src', 'dst',\n            'command', and 'log_path'.\n    \"\"\"\n    self.settings: AppSettings = settings\n    self.command: str = kwargs.get(\"command\", \"operation\")\n    self.sleep: float = kwargs.get('sleep', settings.sleep)\n    self.repeat: bool = kwargs.get('repeat', settings.repeat)\n    self.files_for_task: Tuple[Union[Path]] = tuple()\n    self.pattern: tuple = kwargs.get('pattern', settings.pattern)\n    self.src: str = kwargs.get('src', '')\n    self.dst: str = kwargs.get('dst', '')\n    self.source_directory = Path(self.src)\n    self.target_directory = self.dst\n    self.stop: bool = False\n\n    log_file = self.command\n    log_level = kwargs.get(\"log_level\", settings.log_level)\n    self.log_path = kwargs.get(\"log_path\", settings.log_path)\n\n    self.logger = LoggerConfigurator.setup(\n        name=self.__class__.__name__,\n        log_level=log_level,\n        log_path=Path(self.log_path) / f\"{log_file}.log\" if self.log_path else None\n    )\n    self.logger.info(f\"Started with parameters: {kwargs}\")\n</code></pre>"},{"location":"operations/file_operation/#file_operations.file_operation.FileOperation.add_arguments","title":"<code>add_arguments(settings, parser)</code>  <code>abstractmethod</code> <code>staticmethod</code>","text":"<p>Abstract method to define specific CLI arguments for the operation.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>To provide default values for arguments.</p> required <code>parser</code> <code>ArgumentParser</code> <p>The subparser for the command.</p> required Source code in <code>file_operations/file_operation.py</code> <pre><code>@staticmethod\n@abstractmethod\ndef add_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n    \"\"\"\n    Abstract method to define specific CLI arguments for the operation.\n\n    Args:\n        settings (AppSettings): To provide default values for arguments.\n        parser (argparse.ArgumentParser): The subparser for the command.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"operations/file_operation/#file_operations.file_operation.FileOperation.check_directories","title":"<code>check_directories()</code>","text":"<p>Checks the source directory and ensures the target directory exists.</p> <p>If the target directory is missing, it creates it automatically with all parents.</p> Source code in <code>file_operations/file_operation.py</code> <pre><code>def check_directories(self) -&gt; None:\n    \"\"\"\n    Checks the source directory and ensures the target directory exists.\n\n    If the target directory is missing, it creates it automatically with all parents.\n    \"\"\"\n    self.check_source_directory()\n    self.target_directory.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"operations/file_operation/#file_operations.file_operation.FileOperation.check_source_directory","title":"<code>check_source_directory()</code>","text":"<p>Validates that the source directory exists on the file system.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the source path does not exist.</p> Source code in <code>file_operations/file_operation.py</code> <pre><code>def check_source_directory(self) -&gt; None:\n    \"\"\"\n    Validates that the source directory exists on the file system.\n\n    Raises:\n        FileNotFoundError: If the source path does not exist.\n    \"\"\"\n    if not self.source_directory.exists():\n        msg = f\"Source path '{self.src}' does not exist.\"\n        self.logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"operations/file_operation/#file_operations.file_operation.FileOperation.do_task","title":"<code>do_task()</code>  <code>abstractmethod</code>","text":"<p>Abstract method where the main logic of the operation is implemented.</p> Source code in <code>file_operations/file_operation.py</code> <pre><code>@abstractmethod\ndef do_task(self):\n    \"\"\"Abstract method where the main logic of the operation is implemented.\"\"\"\n    pass\n</code></pre>"},{"location":"operations/file_operation/#file_operations.file_operation.FileOperation.get_files","title":"<code>get_files(source_directory, pattern)</code>","text":"<p>Scans the source directory for files that match the given patterns.</p> <p>Parameters:</p> Name Type Description Default <code>source_directory</code> <code>Path</code> <p>The folder to search in.</p> required <code>pattern</code> <code>Union[Tuple[str], Tuple[str, ...]]</code> <p>A tuple of strings to match filenames (e.g., ('.jpg', '.png')).</p> required <p>Returns:</p> Type Description <code>Tuple[Path]</code> <p>Tuple[Path]: A tuple containing Path objects of the found files.</p> Source code in <code>file_operations/file_operation.py</code> <pre><code>def get_files(self, source_directory: Path, pattern: Union[Tuple[str], Tuple[str, ...]]) -&gt; Tuple[Path]:\n    \"\"\"\n    Scans the source directory for files that match the given patterns.\n\n    Args:\n        source_directory (Path): The folder to search in.\n        pattern (Union[Tuple[str], Tuple[str, ...]]): A tuple of strings\n            to match filenames (e.g., ('.jpg', '.png')).\n\n    Returns:\n        Tuple[Path]: A tuple containing Path objects of the found files.\n    \"\"\"\n    files = set()\n\n    for p in pattern:\n        current_pattern_files = source_directory.glob(f\"*{p}*\")\n        files.update(current_pattern_files)\n\n    files_for_task = tuple(file.resolve() for file in files)\n    self.logger.debug(f\"Total files_for_task: {len(files_for_task)}\")\n    return files_for_task\n</code></pre>"},{"location":"operations/file_operation/#file_operations.file_operation.FileOperation.run","title":"<code>run()</code>","text":"<p>Starts the main execution lifecycle of the operation.</p> <p>This method handles the directory checks and enters a loop if 'repeat' is enabled. It calls 'do_task' for the actual work and handles KeyboardInterrupt for safe stopping.</p> Source code in <code>file_operations/file_operation.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"\n    Starts the main execution lifecycle of the operation.\n\n    This method handles the directory checks and enters a loop if 'repeat'\n    is enabled. It calls 'do_task' for the actual work and handles\n    KeyboardInterrupt for safe stopping.\n    \"\"\"\n    self.check_directories()\n    while True:\n        try:\n            self.files_for_task = self.get_files(source_directory=self.source_directory, pattern=self.pattern)\n\n            if len(self.files_for_task) == 0 and self.repeat:\n                self.logger.info(f\"No files found for task'{self.pattern}'. Wait for {self.sleep} seconds...\")\n                time.sleep(self.sleep)\n                continue\n\n            self.do_task()\n\n        except KeyboardInterrupt:\n            self.stop = True\n            self.logger.info(f\"Ctrl+C pressed, stopping...\")\n\n        if self.stop or not self.repeat:\n            self.logger.info(f\"Finished\\n{'-' * 10}\\n\")\n            break\n</code></pre>"},{"location":"operations/move/","title":"move","text":"<p>               Bases: <code>FileOperation</code></p> <p>An operation to move files from a source directory to a target directory.</p> <p>This class identifies files that match specific patterns and relocates them to the destination directory. It includes a safety check to prevent moving a file into the same directory where it is already located.</p> Source code in <code>file_operations/move.py</code> <pre><code>class MoveOperation(FileOperation):\n    \"\"\"\n    An operation to move files from a source directory to a target directory.\n\n    This class identifies files that match specific patterns and relocates them\n    to the destination directory. It includes a safety check to prevent moving a file\n    into the same directory where it is already located.\n    \"\"\"\n    @staticmethod\n    def add_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n        \"\"\"\n        Adds the destination argument to the command-line interface.\n\n        Args:\n            settings (AppSettings): The global settings object for default values.\n            parser (argparse.ArgumentParser): The CLI parser to which arguments are added.\n        \"\"\"\n        parser.add_argument(Arguments.dst, help=HelpStrings.dst)\n\n\n    def do_task(self):\n        \"\"\"\n        Iterates through the collected files and moves them to the target directory.\n\n        The method checks if each item is a file and ensures the target path is\n        different from the source path. It uses 'shutil.move' for the operation\n        and logs the results or any errors that occur.\n        \"\"\"\n        for file_path in self.files_for_task:\n            if file_path.is_file() and file_path.parent.resolve() != self.target_directory.resolve():\n                target_file_path = self.target_directory / file_path.name\n                self.logger.info(f\"{file_path} -&gt; {self.target_directory}\")\n\n                try:\n                    shutil.move(file_path, target_file_path)\n                except Exception as e:\n                    self.logger.error(e)\n</code></pre>"},{"location":"operations/move/#file_operations.move.MoveOperation.add_arguments","title":"<code>add_arguments(settings, parser)</code>  <code>staticmethod</code>","text":"<p>Adds the destination argument to the command-line interface.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>The global settings object for default values.</p> required <code>parser</code> <code>ArgumentParser</code> <p>The CLI parser to which arguments are added.</p> required Source code in <code>file_operations/move.py</code> <pre><code>@staticmethod\ndef add_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n    \"\"\"\n    Adds the destination argument to the command-line interface.\n\n    Args:\n        settings (AppSettings): The global settings object for default values.\n        parser (argparse.ArgumentParser): The CLI parser to which arguments are added.\n    \"\"\"\n    parser.add_argument(Arguments.dst, help=HelpStrings.dst)\n</code></pre>"},{"location":"operations/move/#file_operations.move.MoveOperation.do_task","title":"<code>do_task()</code>","text":"<p>Iterates through the collected files and moves them to the target directory.</p> <p>The method checks if each item is a file and ensures the target path is different from the source path. It uses 'shutil.move' for the operation and logs the results or any errors that occur.</p> Source code in <code>file_operations/move.py</code> <pre><code>def do_task(self):\n    \"\"\"\n    Iterates through the collected files and moves them to the target directory.\n\n    The method checks if each item is a file and ensures the target path is\n    different from the source path. It uses 'shutil.move' for the operation\n    and logs the results or any errors that occur.\n    \"\"\"\n    for file_path in self.files_for_task:\n        if file_path.is_file() and file_path.parent.resolve() != self.target_directory.resolve():\n            target_file_path = self.target_directory / file_path.name\n            self.logger.info(f\"{file_path} -&gt; {self.target_directory}\")\n\n            try:\n                shutil.move(file_path, target_file_path)\n            except Exception as e:\n                self.logger.error(e)\n</code></pre>"},{"location":"operations/slice/","title":"slice","text":"<p>               Bases: <code>FileOperation</code>, <code>FileRemoverMixin</code></p> <p>An operation to extract images (frames) from video files.</p> <p>This class processes video files in source directory that match a specific pattern and saves their frames into the target directory. It can also automatically delete the source video file after the slicing process is finished.</p> <p>Attributes:</p> Name Type Description <code>step_sec</code> <code>float</code> <p>The time interval in seconds between extracted frames.</p> <code>suffix</code> <code>str</code> <p>The file extension for the output images (e.g., '.jpg').</p> <code>remove</code> <code>bool</code> <p>If True, the source video is deleted after processing.</p> <code>slicer</code> <code>VideoSlicer</code> <p>The tool used to perform the actual video slicing.</p> Source code in <code>file_operations/slice.py</code> <pre><code>class SliceOperation(FileOperation, FileRemoverMixin):\n    \"\"\"\n    An operation to extract images (frames) from video files.\n\n    This class processes video files in source directory that match a specific\n    pattern and saves their frames into the target directory. It can also\n    automatically delete the source video file after the slicing process is finished.\n\n    Attributes:\n        step_sec (float): The time interval in seconds between extracted frames.\n        suffix (str): The file extension for the output images (e.g., '.jpg').\n        remove (bool): If True, the source video is deleted after processing.\n        slicer (VideoSlicer): The tool used to perform the actual video slicing.\n    \"\"\"\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the slice operation with the required parameters.\n\n        Args:\n            **kwargs (dict): Arguments including 'step_sec', 'type', and 'remove'\n                flags, usually passed from the command line or settings.\n        \"\"\"\n        super().__init__(**kwargs)\n        self.step_sec: float = kwargs.get(\"step_sec\", self.settings.step_sec)\n        self.suffix: str = kwargs.get('type', self.settings.suffix)\n        self.remove: bool = kwargs.get('remove', self.settings.remove)\n        self.slicer: VideoSlicer = VideoSlicer()\n\n\n    @staticmethod\n    def add_arguments(settings, parser: argparse.ArgumentParser) -&gt; None:\n        \"\"\"\n        Defines CLI arguments for the video slicing task.\n\n        Args:\n            settings (AppSettings): Global configuration for default values.\n            parser (argparse.ArgumentParser): The parser to which arguments are added.\n        \"\"\"\n        parser.add_argument(Arguments.dst, help=HelpStrings.dst)\n        parser.add_argument(\n            Arguments.remove, Arguments.rm,\n            help=HelpStrings.remove,\n            action='store_true'\n        )\n        parser.add_argument(\n            Arguments.type, Arguments.t,\n            help=HelpStrings.type,\n            default=settings.suffix\n        )\n        parser.add_argument(\n            Arguments.step_sec, Arguments.step,\n            help=HelpStrings.step_sec,\n            default=settings.step_sec\n        )\n\n\n    def do_task(self):\n        \"\"\"\n        Processes the collected video files one by one.\n\n        This method uses the 'VideoSlicer' tool to extract frames. It logs\n        how many images were created for each video. If the 'remove' flag\n        is enabled, it deletes the source video using 'FileRemoverMixin'.\n        \"\"\"\n        for file_path in self.files_for_task:\n            if file_path.is_file():\n                ret, sliced_count = self.slicer.slice(\n                    source_file=file_path,\n                    target_dir=self.target_directory,\n                    suffix=self.suffix,\n                    step=self.step_sec\n                )\n\n                if ret:\n                    self.logger.info(f\"{file_path} sliced to {sliced_count} images\")\n                else:\n                    self.logger.warning(f\"Unable to read {file_path}. Not sliced.\")\n                    continue\n\n                if self.remove:\n                    self.remove_all(file_path)\n\n\n    @property\n    def step_sec(self) -&gt; float:\n        \"\"\"float: Returns the time interval between frames.\"\"\"\n        return self._step_sec\n\n\n    @step_sec.setter\n    def step_sec(self, value: Union[float, int, str]) -&gt; None:\n        \"\"\"\n        Sets the time interval and ensures it is a float value.\n\n        Args:\n            value (Union[int, float, str]): The interval value to be converted.\n        \"\"\"\n        if not isinstance(value, float):\n            value = float(value)\n\n        self._step_sec = value\n</code></pre>"},{"location":"operations/slice/#file_operations.slice.SliceOperation.step_sec","title":"<code>step_sec</code>  <code>property</code> <code>writable</code>","text":"<p>float: Returns the time interval between frames.</p>"},{"location":"operations/slice/#file_operations.slice.SliceOperation.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the slice operation with the required parameters.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Arguments including 'step_sec', 'type', and 'remove' flags, usually passed from the command line or settings.</p> <code>{}</code> Source code in <code>file_operations/slice.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the slice operation with the required parameters.\n\n    Args:\n        **kwargs (dict): Arguments including 'step_sec', 'type', and 'remove'\n            flags, usually passed from the command line or settings.\n    \"\"\"\n    super().__init__(**kwargs)\n    self.step_sec: float = kwargs.get(\"step_sec\", self.settings.step_sec)\n    self.suffix: str = kwargs.get('type', self.settings.suffix)\n    self.remove: bool = kwargs.get('remove', self.settings.remove)\n    self.slicer: VideoSlicer = VideoSlicer()\n</code></pre>"},{"location":"operations/slice/#file_operations.slice.SliceOperation.add_arguments","title":"<code>add_arguments(settings, parser)</code>  <code>staticmethod</code>","text":"<p>Defines CLI arguments for the video slicing task.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>Global configuration for default values.</p> required <code>parser</code> <code>ArgumentParser</code> <p>The parser to which arguments are added.</p> required Source code in <code>file_operations/slice.py</code> <pre><code>@staticmethod\ndef add_arguments(settings, parser: argparse.ArgumentParser) -&gt; None:\n    \"\"\"\n    Defines CLI arguments for the video slicing task.\n\n    Args:\n        settings (AppSettings): Global configuration for default values.\n        parser (argparse.ArgumentParser): The parser to which arguments are added.\n    \"\"\"\n    parser.add_argument(Arguments.dst, help=HelpStrings.dst)\n    parser.add_argument(\n        Arguments.remove, Arguments.rm,\n        help=HelpStrings.remove,\n        action='store_true'\n    )\n    parser.add_argument(\n        Arguments.type, Arguments.t,\n        help=HelpStrings.type,\n        default=settings.suffix\n    )\n    parser.add_argument(\n        Arguments.step_sec, Arguments.step,\n        help=HelpStrings.step_sec,\n        default=settings.step_sec\n    )\n</code></pre>"},{"location":"operations/slice/#file_operations.slice.SliceOperation.do_task","title":"<code>do_task()</code>","text":"<p>Processes the collected video files one by one.</p> <p>This method uses the 'VideoSlicer' tool to extract frames. It logs how many images were created for each video. If the 'remove' flag is enabled, it deletes the source video using 'FileRemoverMixin'.</p> Source code in <code>file_operations/slice.py</code> <pre><code>def do_task(self):\n    \"\"\"\n    Processes the collected video files one by one.\n\n    This method uses the 'VideoSlicer' tool to extract frames. It logs\n    how many images were created for each video. If the 'remove' flag\n    is enabled, it deletes the source video using 'FileRemoverMixin'.\n    \"\"\"\n    for file_path in self.files_for_task:\n        if file_path.is_file():\n            ret, sliced_count = self.slicer.slice(\n                source_file=file_path,\n                target_dir=self.target_directory,\n                suffix=self.suffix,\n                step=self.step_sec\n            )\n\n            if ret:\n                self.logger.info(f\"{file_path} sliced to {sliced_count} images\")\n            else:\n                self.logger.warning(f\"Unable to read {file_path}. Not sliced.\")\n                continue\n\n            if self.remove:\n                self.remove_all(file_path)\n</code></pre>"},{"location":"operations/stats/","title":"stats","text":"<p>               Bases: <code>FileOperation</code></p> <p>Orchestrates dataset analysis to extract geometric, spatial, and quality features.</p> <p>This class processes annotations to provide insights into object distribution, area variance, and potential dataset biases. It helps identify issues like class imbalance or feature outliers before the model training phase.</p> Source code in <code>file_operations/stats_operation.py</code> <pre><code>class StatsOperation(FileOperation):\n    \"\"\"\n    Orchestrates dataset analysis to extract geometric, spatial, and quality features.\n\n    This class processes annotations to provide insights into object distribution,\n    area variance, and potential dataset biases. It helps identify issues like\n    class imbalance or feature outliers before the model training phase.\n    \"\"\"\n\n    def __init__(self, settings: AppSettings, **kwargs):\n        \"\"\"\n        Initializes the StatsOperation with analytical engines and reporters.\n\n        Args:\n            settings (AppSettings): Global application configuration object.\n            **kwargs (dict): Additional parameters such as 'img_path', 'target_format',\n                and file extensions.\n        \"\"\"\n        super().__init__(settings, **kwargs)\n        self.extensions = kwargs.get(\"ext\", self.settings.extensions)\n        self.img_path = kwargs.get('img_path')\n        self.target_format: Union[str, None] = kwargs.get('target_format', self.settings.destination_type)\n        self.stats_mapping: Dict[str, BaseStats.__subclasses__()] = {\n            \"yolo\": YoloStats,\n            \"voc\": VOCStats\n        }\n\n        self.reporter_mapping: Dict[str, Union[BaseDatasetReporter.__subclasses__()]] = {\n            \"image\": ImageDatasetReporter\n        }\n\n        self.reporter: BaseDatasetReporter = self.reporter_mapping.get(self.settings.datatype)(\n            settings=self.settings\n        )\n        self.stats_method: BaseStats = self.stats_mapping[self.target_format](\n            settings=self.settings,\n            source_format =self.target_format,\n            img_path=self.img_path,\n            extensions=self.extensions\n        )\n\n\n    @staticmethod\n    def add_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n        \"\"\"\n        Defines CLI arguments required for dataset statistics calculation.\n\n        Args:\n            settings (AppSettings): Global settings for default values.\n            parser (argparse.ArgumentParser): CLI argument parser instance.\n        \"\"\"\n        parser.add_argument(\n            Arguments.destination_type,\n            help=HelpStrings.destination_type,\n        )\n        parser.add_argument(\n            Arguments.img_path,\n            help=HelpStrings.img_path,\n            default=None,\n        )\n        parser.add_argument(\n            Arguments.n_jobs,\n            help=HelpStrings.n_jobs,\n            default=settings.n_jobs\n        )\n        parser.add_argument(\n            Arguments.margin,\n            help=HelpStrings.margin,\n            default=settings.margin_threshold,\n        )\n        parser.add_argument(\n            Arguments.report_path,\n            help=HelpStrings.report_path,\n            default=settings.report_path\n        )\n\n\n    def do_task(self):\n        \"\"\"\n        Executes the main analytical pipeline for the dataset.\n\n        The process includes:\n            1. Loading annotations and setting up class mappings.\n            2. Extracting a feature matrix (geometry, brightness, etc.).\n            3. Logging a summary report to the console.\n            4. Generating visual analytics (Plots, Heatmaps, and UMAP projections).\n        \"\"\"\n        if self.target_format == \"yolo\":\n            classes_mapping  = self.stats_method.set_class_mapping(file_paths=self.files_for_task)\n            self.files_for_task = tuple(f for f in self.files_for_task if f.name != \"classes.txt\")\n        else:\n            classes_mapping = None\n        df = self.stats_method.get_features(file_paths=self.files_for_task, class_mapping=classes_mapping)\n\n        if df.empty:\n            self.logger.warning(f\"No annotations found in {self.src}\")\n            return\n\n        self.logger.info(f\"Found {len(self.files_for_task)} annotations in {self.src}\")\n\n        self.reporter.show_console_report(df=df, target_format=self.target_format)\n\n        report_path = generate_directory_name(src=self.settings.report_path)\n        features = self.stats_method.get_umap_features(df=df)\n        self.reporter.generate_visual_report(df=df, destination=report_path, features=features)\n\n\n    @property\n    def img_path(self) -&gt; Path:\n        \"\"\"Path: The directory where source images are located.\"\"\"\n        return self._img_path\n\n\n    @img_path.setter\n    def img_path(self, img_path: Union[Path, str, None]) -&gt; None:\n        \"\"\"\n        Sets and validates the path to images folder.\n\n        Args:\n            img_path (Union[Path, str, None]): Path to the images.\n                If None, defaults to the source directory (common for YOLO).\n\n        Raises:\n            TypeError: If the provided path is not a string, Path, or None.\n        \"\"\"\n        if isinstance(img_path, Path):\n            self._img_path = img_path\n        elif isinstance(img_path, str):\n            self._img_path = Path(img_path)\n        elif img_path is None:\n            self._img_path = self.source_directory\n            self.logger.warning(f\"Dataset images path is not defined. Set same annotations path: {self.source_directory}\")\n        else:\n            msg = f\"img_path must be Path or str, not {type(img_path)}\"\n            self.logger.error(msg)\n            raise TypeError(msg)\n\n\n    @property\n    def extensions(self) -&gt; Tuple[str, ...]:\n        \"\"\"Tuple[str, ...]: Returns the supported image file extensions.\"\"\"\n        return self._extensions\n\n\n    @extensions.setter\n    def extensions(self, value: Tuple[str, ...]) -&gt; None:\n        \"\"\"\n        Sets the valid image extensions for the converter.\n\n        Args:\n            value (Tuple[str, ...]): A tuple of extension strings (e.g., ('.jpg',)).\n\n        Raises:\n            TypeError: If the input cannot be converted into a tuple.\n        \"\"\"\n        if isinstance(value, tuple):\n            self._extensions = value\n        else:\n            try:\n                self._extensions = tuple(value)\n            except TypeError as e:\n                msg = f\"extensions must be convertable into tuple, got {type(value)}\"\n                self.logger.error(msg)\n                raise TypeError(msg)\n</code></pre>"},{"location":"operations/stats/#file_operations.stats_operation.StatsOperation.extensions","title":"<code>extensions</code>  <code>property</code> <code>writable</code>","text":"<p>Tuple[str, ...]: Returns the supported image file extensions.</p>"},{"location":"operations/stats/#file_operations.stats_operation.StatsOperation.img_path","title":"<code>img_path</code>  <code>property</code> <code>writable</code>","text":"<p>Path: The directory where source images are located.</p>"},{"location":"operations/stats/#file_operations.stats_operation.StatsOperation.__init__","title":"<code>__init__(settings, **kwargs)</code>","text":"<p>Initializes the StatsOperation with analytical engines and reporters.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>Global application configuration object.</p> required <code>**kwargs</code> <code>dict</code> <p>Additional parameters such as 'img_path', 'target_format', and file extensions.</p> <code>{}</code> Source code in <code>file_operations/stats_operation.py</code> <pre><code>def __init__(self, settings: AppSettings, **kwargs):\n    \"\"\"\n    Initializes the StatsOperation with analytical engines and reporters.\n\n    Args:\n        settings (AppSettings): Global application configuration object.\n        **kwargs (dict): Additional parameters such as 'img_path', 'target_format',\n            and file extensions.\n    \"\"\"\n    super().__init__(settings, **kwargs)\n    self.extensions = kwargs.get(\"ext\", self.settings.extensions)\n    self.img_path = kwargs.get('img_path')\n    self.target_format: Union[str, None] = kwargs.get('target_format', self.settings.destination_type)\n    self.stats_mapping: Dict[str, BaseStats.__subclasses__()] = {\n        \"yolo\": YoloStats,\n        \"voc\": VOCStats\n    }\n\n    self.reporter_mapping: Dict[str, Union[BaseDatasetReporter.__subclasses__()]] = {\n        \"image\": ImageDatasetReporter\n    }\n\n    self.reporter: BaseDatasetReporter = self.reporter_mapping.get(self.settings.datatype)(\n        settings=self.settings\n    )\n    self.stats_method: BaseStats = self.stats_mapping[self.target_format](\n        settings=self.settings,\n        source_format =self.target_format,\n        img_path=self.img_path,\n        extensions=self.extensions\n    )\n</code></pre>"},{"location":"operations/stats/#file_operations.stats_operation.StatsOperation.add_arguments","title":"<code>add_arguments(settings, parser)</code>  <code>staticmethod</code>","text":"<p>Defines CLI arguments required for dataset statistics calculation.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>AppSettings</code> <p>Global settings for default values.</p> required <code>parser</code> <code>ArgumentParser</code> <p>CLI argument parser instance.</p> required Source code in <code>file_operations/stats_operation.py</code> <pre><code>@staticmethod\ndef add_arguments(settings: AppSettings, parser: argparse.ArgumentParser) -&gt; None:\n    \"\"\"\n    Defines CLI arguments required for dataset statistics calculation.\n\n    Args:\n        settings (AppSettings): Global settings for default values.\n        parser (argparse.ArgumentParser): CLI argument parser instance.\n    \"\"\"\n    parser.add_argument(\n        Arguments.destination_type,\n        help=HelpStrings.destination_type,\n    )\n    parser.add_argument(\n        Arguments.img_path,\n        help=HelpStrings.img_path,\n        default=None,\n    )\n    parser.add_argument(\n        Arguments.n_jobs,\n        help=HelpStrings.n_jobs,\n        default=settings.n_jobs\n    )\n    parser.add_argument(\n        Arguments.margin,\n        help=HelpStrings.margin,\n        default=settings.margin_threshold,\n    )\n    parser.add_argument(\n        Arguments.report_path,\n        help=HelpStrings.report_path,\n        default=settings.report_path\n    )\n</code></pre>"},{"location":"operations/stats/#file_operations.stats_operation.StatsOperation.do_task","title":"<code>do_task()</code>","text":"<p>Executes the main analytical pipeline for the dataset.</p> The process includes <ol> <li>Loading annotations and setting up class mappings.</li> <li>Extracting a feature matrix (geometry, brightness, etc.).</li> <li>Logging a summary report to the console.</li> <li>Generating visual analytics (Plots, Heatmaps, and UMAP projections).</li> </ol> Source code in <code>file_operations/stats_operation.py</code> <pre><code>def do_task(self):\n    \"\"\"\n    Executes the main analytical pipeline for the dataset.\n\n    The process includes:\n        1. Loading annotations and setting up class mappings.\n        2. Extracting a feature matrix (geometry, brightness, etc.).\n        3. Logging a summary report to the console.\n        4. Generating visual analytics (Plots, Heatmaps, and UMAP projections).\n    \"\"\"\n    if self.target_format == \"yolo\":\n        classes_mapping  = self.stats_method.set_class_mapping(file_paths=self.files_for_task)\n        self.files_for_task = tuple(f for f in self.files_for_task if f.name != \"classes.txt\")\n    else:\n        classes_mapping = None\n    df = self.stats_method.get_features(file_paths=self.files_for_task, class_mapping=classes_mapping)\n\n    if df.empty:\n        self.logger.warning(f\"No annotations found in {self.src}\")\n        return\n\n    self.logger.info(f\"Found {len(self.files_for_task)} annotations in {self.src}\")\n\n    self.reporter.show_console_report(df=df, target_format=self.target_format)\n\n    report_path = generate_directory_name(src=self.settings.report_path)\n    features = self.stats_method.get_umap_features(df=df)\n    self.reporter.generate_visual_report(df=df, destination=report_path, features=features)\n</code></pre>"}]}